{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Docprompt - Getting Started","text":""},{"location":"#supercharged-document-analysis","title":"Supercharged Document Analysis","text":"<ul> <li>Common utilities for interacting with PDFs</li> <li>PDF loading and serialization</li> <li>PDF byte compression using Ghostscript </li> <li>Fast rasterization  </li> <li>Page splitting, re-export with PDFium</li> <li>Support for most OCR providers with batched inference</li> <li>Google </li> <li>Azure Document Intelligence </li> <li>Amazon Textract </li> <li>Tesseract </li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Base installation</p> <pre><code>pip install docprompt\n</code></pre> <p>With an OCR provider</p> <pre><code>pip install \"docprompt[google]\n</code></pre>"},{"location":"#usage","title":"Usage","text":""},{"location":"#simple-operations","title":"Simple Operations","text":"<pre><code>from docprompt import load_document\n\n# Load a document\ndocument = load_document(\"path/to/my.pdf\")\n\n# Rasterize a single page using Ghostscript\npage_number = 5\nrastered = document.rasterize_page(page_number, dpi=120)\n\n# Split a pdf based on a page range\ndocument_2 = document.split(start=125, stop=130)\n</code></pre>"},{"location":"#performing-ocr","title":"Performing OCR","text":"<pre><code>from docprompt import load_document, DocumentNode\nfrom docprompt.tasks.ocr.gcp import GoogleOcrProvider\n\nprovider = GoogleOcrProvider.from_service_account_file(\n  project_id=my_project_id,\n  processor_id=my_processor_id,\n  service_account_file=path_to_service_file\n)\n\ndocument = load_document(\"path/to/my.pdf\")\n\n# A container holds derived data for a document, like OCR or classification results\ndocument_node = DocumentNode.from_document(document)\n\nprovider.process_document_node(document_node) # Caches results on the document_node\n\ndocument_node[0].ocr_result # Access OCR results\n</code></pre>"},{"location":"#document-search","title":"Document Search","text":"<p>When a large language model returns a result, we might want to highlight that result for our users. However, language models return results as text, while what we need to show our users requires a page number and a bounding box.</p> <p>After extracting text from a PDF, we can support this pattern using <code>DocumentProvenanceLocator</code>, which lives on a <code>DocumentNode</code></p> <pre><code>from docprompt import load_document, DocumentNode\nfrom docprompt.tasks.ocr.gcp import GoogleOcrProvider\n\nprovider = GoogleOcrProvider.from_service_account_file(\n  project_id=my_project_id,\n  processor_id=my_processor_id,\n  service_account_file=path_to_service_file\n)\n\ndocument = load_document(\"path/to/my.pdf\")\n\n# A container holds derived data for a document, like OCR or classification results\ndocument_node = DocumentNode.from_document(document)\n\nprovider.process_document_node(document_node) # Caches results on the document_node\n\n# With OCR results available, we can now instantiate a locator and search through documents.\n\ndocument_node.locator.search(\"John Doe\") # This will return a list of all terms across the document that contain \"John Doe\"\ndocument_node.locator.search(\"Jane Doe\", page_number=4) # Just return results a list of matching results from page 4\n</code></pre> <p>This functionality uses a combination of <code>rtree</code> and the Rust library <code>tantivy</code>, allowing you to perform thousands of searches in seconds </p>"},{"location":"enterprise/","title":"Enterprise","text":"<p>For companies looking to unlock data, build custom language models, or for general professional support</p> <p>Talk to founders</p> <p>This covers:</p> <ul> <li>\u2705 Assistance with PDF-optimized prompt engineering for Document AI tasks</li> <li>\u2705 Feature Prioritization</li> <li>\u2705 Custom Integrations</li> <li>\u2705 Professional Support - Dedicated discord + slack</li> </ul>"},{"location":"enterprise/#what-topics-does-professional-support-cover","title":"What topics does Professional support cover?","text":"<p>The expertise we've developed during our time building medical processing pipelines has equipped us with the tools and knowhow needed to perform highly accurate information extraction in document-heavy domains. We offer consulting services that leverage this expertise to assist with prompt engineering, deployments, and general ML-ops in the Document AI space.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"concepts/nodes/","title":"Nodes in Docprompt","text":""},{"location":"concepts/nodes/#overview","title":"Overview","text":"<p>In Docprompt, nodes are fundamental structures used to represent and manage documents and their pages. They provide a way to store state and metadata associated with documents and individual pages, enabling advanced document analysis and processing capabilities.</p>"},{"location":"concepts/nodes/#key-concepts","title":"Key Concepts","text":""},{"location":"concepts/nodes/#documentnode","title":"DocumentNode","text":"<p>A <code>DocumentNode</code> represents a single document within the Docprompt system. It serves as a container for document-level metadata and provides access to individual pages through <code>PageNode</code> instances.</p> <pre><code>class DocumentNode(BaseModel, Generic[DocumentNodeMetadata, PageNodeMetadata]):\n    document: Document\n    page_nodes: List[PageNode[PageNodeMetadata]]\n    metadata: Optional[DocumentNodeMetadata]\n</code></pre> <p>Key features: - Stores a reference to the underlying <code>Document</code> object - Maintains a list of <code>PageNode</code> instances representing individual pages - Allows for custom document-level metadata - Provides access to a <code>DocumentProvenanceLocator</code> for efficient text search within the document</p>"},{"location":"concepts/nodes/#pagenode","title":"PageNode","text":"<p>A <code>PageNode</code> represents a single page within a document. It stores page-specific information and provides access to various analysis results, such as OCR data.</p> <pre><code>class PageNode(BaseModel, Generic[PageNodeMetadata]):\n    document: \"DocumentNode\"\n    page_number: PositiveInt\n    metadata: Optional[PageNodeMetadata]\n    extra: Dict[str, Any]\n    ocr_results: ResultContainer[OcrPageResult]\n</code></pre> <p>Key features: - References the parent <code>DocumentNode</code> - Stores the page number - Allows for custom page-level metadata - Provides a flexible <code>extra</code> field for additional data storage - Stores OCR results in a <code>ResultContainer</code></p>"},{"location":"concepts/nodes/#usage","title":"Usage","text":""},{"location":"concepts/nodes/#creating-a-documentnode","title":"Creating a DocumentNode","text":"<p>You can create a <code>DocumentNode</code> from a <code>Document</code> instance:</p> <pre><code>from docprompt import load_document, DocumentNode\n\ndocument = load_document(\"path/to/my.pdf\")\ndocument_node = DocumentNode.from_document(document)\n</code></pre>"},{"location":"concepts/nodes/#working-with-ocr-results","title":"Working with OCR Results","text":"<p>After processing a document with an OCR provider, you can access the results through the <code>DocumentNode</code> and <code>PageNode</code> structures:</p> <pre><code>from docprompt.tasks.ocr.gcp import GoogleOcrProvider\n\nprovider = GoogleOcrProvider.from_service_account_file(\n    project_id=my_project_id,\n    processor_id=my_processor_id,\n    service_account_file=path_to_service_file\n)\n\nprovider.process_document_node(document_node)\n\n# Access OCR results for a specific page\nocr_result = document_node.page_nodes[0].ocr_results\n</code></pre>"},{"location":"concepts/nodes/#using-documentprovenancelocator","title":"Using DocumentProvenanceLocator","text":"<p>The <code>DocumentProvenanceLocator</code> is a powerful tool for searching text within a document:</p> <pre><code># Search for text across the entire document\nresults = document_node.locator.search(\"John Doe\")\n\n# Search for text on a specific page\npage_results = document_node.locator.search(\"Jane Doe\", page_number=4)\n</code></pre>"},{"location":"concepts/nodes/#benefits-of-using-nodes","title":"Benefits of Using Nodes","text":"<ol> <li> <p>Separation of Concerns: Nodes allow you to separate the core PDF functionality (handled by the <code>Document</code> class) from additional metadata and analysis results.</p> </li> <li> <p>Flexible Metadata: Both <code>DocumentNode</code> and <code>PageNode</code> support generic metadata types, allowing you to add custom, type-safe metadata to your documents and pages.</p> </li> <li> <p>Result Caching: Nodes provide a convenient way to cache and access results from various analysis tasks, such as OCR.</p> </li> <li> <p>Efficient Text Search: The <code>DocumentProvenanceLocator</code> enables fast text search capabilities, leveraging OCR results for improved performance.</p> </li> <li> <p>Extensibility: The node structure allows for easy integration of new analysis tools and result types in the future.</p> </li> </ol> <p>By using the node structure in Docprompt, you can build powerful document analysis workflows that combine the core PDF functionality with advanced processing and search capabilities.</p>"},{"location":"concepts/primatives/","title":"Docprompt Primitives","text":"<p>Docprompt uses several primitive objects that are fundamental to its operation. These primitives are used throughout the library and are essential for understanding how Docprompt processes and represents documents.</p>"},{"location":"concepts/primatives/#pdfdocument","title":"PdfDocument","text":"<p>The <code>PdfDocument</code> class is a core primitive in Docprompt, representing a PDF document with various utilities for manipulation and analysis.</p> <pre><code>class PdfDocument(BaseModel):\n    name: str\n    file_bytes: bytes\n    file_path: Optional[str] = None\n</code></pre>"},{"location":"concepts/primatives/#key-features","title":"Key Features","text":"<ol> <li>Document Properties</li> <li><code>name</code>: The name of the document</li> <li><code>file_bytes</code>: The raw bytes of the PDF file</li> <li><code>file_path</code>: Optional path to the PDF file on disk</li> <li><code>page_count</code>: The number of pages in the document (computed field)</li> <li> <p><code>document_hash</code>: A unique hash of the document (computed field)</p> </li> <li> <p>Utility Methods</p> </li> <li><code>from_path(file_path)</code>: Create a PdfDocument from a file path</li> <li><code>from_bytes(file_bytes, name)</code>: Create a PdfDocument from bytes</li> <li><code>get_page_render_size(page_number, dpi)</code>: Get the render size of a specific page</li> <li><code>to_compressed_bytes()</code>: Compress the PDF using Ghostscript</li> <li><code>rasterize_page(page_number, ...)</code>: Rasterize a specific page with various options</li> <li><code>rasterize_pdf(...)</code>: Rasterize the entire PDF</li> <li><code>split(start, stop)</code>: Split the PDF into a new document</li> <li><code>as_tempfile()</code>: Create a temporary file from the PDF</li> <li><code>write_to_path(path)</code>: Write the PDF to a specific path</li> </ol>"},{"location":"concepts/primatives/#usage-example","title":"Usage Example","text":"<pre><code>from docprompt import PdfDocument\n\n# Load a PDF\npdf = PdfDocument.from_path(\"path/to/document.pdf\")\n\n# Get document properties\nprint(f\"Document name: {pdf.name}\")\nprint(f\"Page count: {pdf.page_count}\")\n\n# Rasterize a page\npage_image = pdf.rasterize_page(1, dpi=300)\n\n# Split the document\nnew_pdf = pdf.split(start=5, stop=10)\n</code></pre>"},{"location":"concepts/primatives/#layout-primitives","title":"Layout Primitives","text":"<p>Docprompt uses several layout primitives to represent the structure and content of documents.</p>"},{"location":"concepts/primatives/#normbbox","title":"NormBBox","text":"<p><code>NormBBox</code> represents a normalized bounding box with values between 0 and 1.</p> <pre><code>class NormBBox(BaseModel):\n    x0: BoundedFloat\n    top: BoundedFloat\n    x1: BoundedFloat\n    bottom: BoundedFloat\n</code></pre> <p>Key features: - Intersection operations (<code>__and__</code>) - Union operations (<code>__add__</code>) - Intersection over Union (IoU) calculation - Area and centroid properties</p>"},{"location":"concepts/primatives/#textblock","title":"TextBlock","text":"<p><code>TextBlock</code> represents a block of text within a document, including its bounding box and metadata.</p> <pre><code>class TextBlock(BaseModel):\n    text: str\n    type: SegmentLevels\n    source: TextblockSource\n    bounding_box: NormBBox\n    bounding_poly: Optional[BoundingPoly]\n    text_spans: Optional[List[TextSpan]]\n    metadata: Optional[TextBlockMetadata]\n</code></pre>"},{"location":"concepts/primatives/#point-and-boundingpoly","title":"Point and BoundingPoly","text":"<p><code>Point</code> and <code>BoundingPoly</code> are used to represent more complex shapes within a document.</p> <pre><code>class Point(BaseModel):\n    x: BoundedFloat\n    y: BoundedFloat\n\nclass BoundingPoly(BaseModel):\n    normalized_vertices: List[Point]\n</code></pre>"},{"location":"concepts/primatives/#textspan","title":"TextSpan","text":"<p><code>TextSpan</code> represents a span of text within a document or page.</p> <pre><code>class TextSpan(BaseModel):\n    start_index: int\n    end_index: int\n    level: Literal[\"page\", \"document\"]\n</code></pre>"},{"location":"concepts/primatives/#usage-example_1","title":"Usage Example","text":"<pre><code>from docprompt.schema.layout import NormBBox, TextBlock, TextBlockMetadata\n\n# Create a bounding box\nbbox = NormBBox(x0=0.1, top=0.1, x1=0.9, bottom=0.2)\n\n# Create a text block\ntext_block = TextBlock(\n    text=\"Example text\",\n    type=\"block\",\n    source=\"ocr\",\n    bounding_box=bbox,\n    metadata=TextBlockMetadata(confidence=0.95)\n)\n\n# Use the text block\nprint(f\"Text: {text_block.text}\")\nprint(f\"Bounding box: {text_block.bounding_box}\")\nprint(f\"Confidence: {text_block.confidence}\")\n</code></pre> <p>These primitives form the foundation of Docprompt's document processing capabilities, allowing for precise representation and manipulation of document content and structure.</p>"},{"location":"concepts/provenance/","title":"Provenance in Docprompt","text":""},{"location":"concepts/provenance/#overview","title":"Overview","text":"<p>Provenance in Docprompt refers to the ability to trace and locate specific pieces of text within a document. The <code>DocumentProvenanceLocator</code> class is a powerful tool that enables efficient text search, spatial queries, and fine-grained text location within documents that have been processed with OCR.</p>"},{"location":"concepts/provenance/#key-concepts","title":"Key Concepts","text":""},{"location":"concepts/provenance/#documentprovenancelocator","title":"DocumentProvenanceLocator","text":"<p>The <code>DocumentProvenanceLocator</code> is a class that provides advanced search capabilities for documents in Docprompt. It combines full-text search with spatial indexing to offer fast and accurate text location services.</p> <pre><code>@dataclass\nclass DocumentProvenanceLocator:\n    document_name: str\n    search_index: \"tantivy.Index\"\n    block_mapping: Dict[int, OcrPageResult]\n    geo_index: DocumentProvenanceGeoMap\n</code></pre> <p>Key features: - Full-text search using the Tantivy search engine - Spatial indexing using R-tree for efficient bounding box queries - Support for different granularity levels (word, line, block) - Ability to refine search results to word-level precision</p>"},{"location":"concepts/provenance/#main-functionalities","title":"Main Functionalities","text":""},{"location":"concepts/provenance/#1-text-search","title":"1. Text Search","text":"<p>The <code>search</code> method allows you to find specific text within a document:</p> <pre><code>def search(\n    self,\n    query: str,\n    page_number: Optional[int] = None,\n    *,\n    refine_to_word: bool = True,\n    require_exact_match: bool = True\n) -&gt; List[ProvenanceSource]:\n    # ... implementation ...\n</code></pre> <p>This method returns a list of <code>ProvenanceSource</code> objects, which contain detailed information about where the text was found, including page number, bounding box, and the surrounding context.</p>"},{"location":"concepts/provenance/#2-spatial-queries","title":"2. Spatial Queries","text":"<p>The <code>DocumentProvenanceLocator</code> supports spatial queries to find text blocks based on their location on the page:</p> <pre><code>def get_k_nearest_blocks(\n    self,\n    bbox: NormBBox,\n    page_number: int,\n    k: int,\n    granularity: BlockGranularity = \"block\"\n) -&gt; List[TextBlock]:\n    # ... implementation ...\n\ndef get_overlapping_blocks(\n    self,\n    bbox: NormBBox,\n    page_number: int,\n    granularity: BlockGranularity = \"block\"\n) -&gt; List[TextBlock]:\n    # ... implementation ...\n</code></pre> <p>These methods allow you to find text blocks that are near or overlapping with a given bounding box on a specific page.</p>"},{"location":"concepts/provenance/#usage","title":"Usage","text":""},{"location":"concepts/provenance/#recommended-usage-through-documentnode","title":"Recommended Usage: Through DocumentNode","text":"<p>The recommended way to use the <code>DocumentProvenanceLocator</code> is through the <code>DocumentNode</code> class. The <code>DocumentNode</code> provides two methods for working with the locator:</p> <ol> <li><code>locator</code> property: Lazily creates and returns the <code>DocumentProvenanceLocator</code>.</li> <li><code>refresh_locator()</code> method: Explicitly refreshes the locator for the document node.</li> </ol> <p>Here's how to use these methods:</p> <pre><code>from docprompt import load_document, DocumentNode\nfrom docprompt.tasks.ocr.gcp import GoogleOcrProvider\n\n# Load and process the document\ndocument = load_document(\"path/to/my.pdf\")\ndocument_node = DocumentNode.from_document(document)\n\n# Process the document with OCR\nprovider = GoogleOcrProvider.from_service_account_file(...)\nprovider.process_document_node(document_node)\n\n# Access the locator (creates it if it doesn't exist)\nlocator = document_node.locator\n\n# Perform a search\nresults = locator.search(\"Docprompt\")\n\n# If you need to refresh the locator (e.g., after updating OCR results)\ndocument_node.refresh_locator()\n</code></pre> <p>Note: Attempting to access the locator before OCR results are available will raise a <code>ValueError</code>.</p>"},{"location":"concepts/provenance/#alternative-standalone-usage","title":"Alternative: Standalone Usage","text":"<p>While the recommended approach is to use the locator through <code>DocumentNode</code>, you can also create and use a <code>DocumentProvenanceLocator</code> independently:</p> <pre><code>from docprompt.provenance.search import DocumentProvenanceLocator\n\n# Assuming you have a processed DocumentNode\nlocator = DocumentProvenanceLocator.from_document_node(document_node)\n\n# Now you can use the locator directly\nresults = locator.search(\"Docprompt\")\n</code></pre>"},{"location":"concepts/provenance/#searching-for-text","title":"Searching for Text","text":"<p>To search for text within the document:</p> <pre><code>results = locator.search(\"Docprompt\")\nfor result in results:\n    print(f\"Found on page {result.page_number}, bbox: {result.text_location.merged_source_block.bounding_box}\")\n</code></pre>"},{"location":"concepts/provenance/#performing-spatial-queries","title":"Performing Spatial Queries","text":"<p>To find text blocks near a specific location:</p> <pre><code>bbox = NormBBox(x0=0.1, y0=0.1, x1=0.2, y1=0.2)\nnearby_blocks = locator.get_k_nearest_blocks(bbox, page_number=1, k=5)\n</code></pre>"},{"location":"concepts/provenance/#benefits-of-using-provenance","title":"Benefits of Using Provenance","text":"<ol> <li>Accurate Text Location: Quickly find the exact location of text within a document, including page number and bounding box.</li> <li>Efficient Searching: Combine full-text search with spatial indexing for fast and accurate results.</li> <li>Flexible Granularity: Search and retrieve results at different levels of granularity (word, line, block).</li> <li>Integration with OCR: Seamlessly works with OCR results to provide comprehensive document analysis capabilities.</li> <li>Support for Complex Queries: Perform spatial queries to find text based on location within pages.</li> <li>Easy Access: Conveniently access the locator through the <code>DocumentNode</code> class, ensuring it's always available when needed.</li> </ol> <p>By leveraging the provenance functionality in Docprompt, you can build sophisticated document analysis workflows that require precise text location and contextual information retrieval.</p>"},{"location":"concepts/providers/","title":"Providers in Docprompt","text":""},{"location":"concepts/providers/#overview","title":"Overview","text":"<p>Providers in Docprompt are abstract interfaces that define how to add data to document nodes. They encapsulate various tasks such as OCR, classification, and more. The provider system is designed to be extensible, allowing users to create custom providers to add new functionality to Docprompt.</p>"},{"location":"concepts/providers/#key-concepts","title":"Key Concepts","text":""},{"location":"concepts/providers/#abstracttaskprovider","title":"AbstractTaskProvider","text":"<p>The <code>AbstractTaskProvider</code> is the base class for all providers in Docprompt. It defines the interface that all task providers must implement.</p> <pre><code>class AbstractTaskProvider(Generic[PageTaskResult]):\n    name: str\n    capabilities: List[str]\n\n    def process_document_pages(\n        self,\n        document: Document,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        **kwargs,\n    ) -&gt; Dict[int, PageTaskResult]:\n        raise NotImplementedError\n\n    def contribute_to_document_node(\n        self,\n        document_node: \"DocumentNode\",\n        results: Dict[int, PageTaskResult],\n    ) -&gt; None:\n        pass\n\n    def process_document_node(\n        self,\n        document_node: \"DocumentNode\",\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        contribute_to_document: bool = True,\n        **kwargs,\n    ) -&gt; Dict[int, PageTaskResult]:\n        # ... implementation ...\n</code></pre> <p>Key features: - Generic type <code>PageTaskResult</code> allows for type-safe results - <code>capabilities</code> list defines what the provider can do - <code>process_document_pages</code> method processes pages of a document - <code>contribute_to_document_node</code> method adds results to a <code>DocumentNode</code> - <code>process_document_node</code> method combines processing and contributing results</p>"},{"location":"concepts/providers/#capabilities","title":"CAPABILITIES","text":"<p>The <code>CAPABILITIES</code> enum defines the various capabilities that a provider can have:</p> <pre><code>class CAPABILITIES(Enum):\n    PAGE_RASTERIZATION = \"page-rasterization\"\n    PAGE_LAYOUT_OCR = \"page-layout-ocr\"\n    PAGE_TEXT_OCR = \"page-text-ocr\"\n    PAGE_CLASSIFICATION = \"page-classification\"\n    PAGE_SEGMENTATION = \"page-segmentation\"\n    PAGE_VQA = \"page-vqa\"\n    PAGE_TABLE_IDENTIFICATION = \"page-table-identification\"\n    PAGE_TABLE_EXTRACTION = \"page-table-extraction\"\n</code></pre>"},{"location":"concepts/providers/#resultcontainer","title":"ResultContainer","text":"<p>The <code>ResultContainer</code> is a generic class that holds the results of a task:</p> <pre><code>class ResultContainer(BaseModel, Generic[PageOrDocumentTaskResult]):\n    results: Dict[str, PageOrDocumentTaskResult] = Field(\n        description=\"The results of the task, keyed by provider\", default_factory=dict\n    )\n\n    @property\n    def result(self):\n        return next(iter(self.results.values()), None)\n</code></pre>"},{"location":"concepts/providers/#creating-custom-providers","title":"Creating Custom Providers","text":"<p>To extend Docprompt's functionality, you can create custom providers. Here's an shortened example of a builtin OCR provider from GCP:</p> <pre><code>from docprompt.tasks.base import AbstractTaskProvider, CAPABILITIES\nfrom docprompt.schema.layout import TextBlock\nfrom pydantic import Field\n\nclass OcrPageResult(BasePageResult):\n    page_text: str = Field(description=\"The text for the entire page in reading order\")\n    word_level_blocks: List[TextBlock] = Field(default_factory=list)\n    line_level_blocks: List[TextBlock] = Field(default_factory=list)\n    block_level_blocks: List[TextBlock] = Field(default_factory=list)\n    raster_image: Optional[bytes] = Field(default=None)\n\nclass GoogleOcrProvider(AbstractTaskProvider[OcrPageResult]):\n    name = \"Google Document AI\"\n    capabilities = [\n        CAPABILITIES.PAGE_TEXT_OCR.value,\n        CAPABILITIES.PAGE_LAYOUT_OCR.value,\n        CAPABILITIES.PAGE_RASTERIZATION.value,\n    ]\n\n    def process_document_pages(\n        self,\n        document: Document,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        **kwargs,\n    ) -&gt; Dict[int, OcrPageResult]:\n        # Implement OCR logic here\n        pass\n\n    def contribute_to_document_node(\n        self,\n        document_node: \"DocumentNode\",\n        results: Dict[int, OcrPageResult],\n    ) -&gt; None:\n        # Add OCR results to document node\n        pass\n</code></pre>"},{"location":"concepts/providers/#usage","title":"Usage","text":"<p>Here's how you can use a provider in your Docprompt workflow:</p> <pre><code>from docprompt import load_document, DocumentNode\nfrom docprompt.providers.ocr import GoogleOcrProvider\n\n# Load a document\ndocument = load_document(\"path/to/my.pdf\")\ndocument_node = DocumentNode.from_document(document)\n\n# Create and use the OCR provider\nocr_provider = GoogleOcrProvider(...)\nocr_results = ocr_provider.process_document_node(document_node)\n\n# Access OCR results\nfor page_number, result in ocr_results.items():\n    print(f\"Page {page_number} text: {result.page_text[:100]}...\")\n</code></pre>"},{"location":"concepts/providers/#benefits-of-using-providers","title":"Benefits of Using Providers","text":"<ol> <li>Extensibility: Easily add new functionality to Docprompt by creating custom providers.</li> <li>Modularity: Each provider encapsulates a specific task, making the codebase more organized and maintainable.</li> <li>Type Safety: Generic types ensure that providers produce and consume the correct types of results.</li> <li>Standardized Interface: All providers follow the same interface, making it easy to switch between different implementations.</li> <li>Capability-based Design: Providers declare their capabilities, allowing for dynamic feature discovery and usage.</li> </ol> <p>By leveraging the provider system in Docprompt, you can create flexible and powerful document processing pipelines that can be easily extended and customized to meet your specific needs.</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>_exec<ul> <li>ghostscript</li> </ul> </li> <li>_pdfium</li> <li>contrib<ul> <li>parser_bot</li> </ul> </li> <li>provenance<ul> <li>search</li> <li>source</li> <li>util</li> </ul> </li> <li>rasterize</li> <li>schema<ul> <li>document</li> <li>layout</li> <li>pipeline</li> </ul> </li> <li>tasks<ul> <li>base</li> <li>classification</li> <li>message</li> <li>ocr<ul> <li>gcp</li> <li>result</li> </ul> </li> <li>table_extraction<ul> <li>base</li> <li>schema</li> </ul> </li> </ul> </li> <li>utils<ul> <li>compressor</li> <li>date_extraction</li> <li>masking<ul> <li>image</li> </ul> </li> <li>splitter</li> <li>util</li> </ul> </li> </ul>"},{"location":"reference/_pdfium/","title":"_pdfium","text":""},{"location":"reference/_pdfium/#docprompt._pdfium.chunk_iterable","title":"<code>chunk_iterable(iterable, chunk_size)</code>","text":"<p>Splits an iterable into chunks of specified size, distributing the remainder evenly.</p> <p>Parameters:</p> Name Type Description Default <code>iterable</code> <code>Iterable[T]</code> <p>The iterable to be chunked.</p> required <code>chunk_size</code> <code>int</code> <p>The desired size of each chunk.</p> required <p>Returns:</p> Type Description <code>List[List[T]]</code> <p>List[List[T]]: A list of lists, where each sublist is a chunk.</p> Source code in <code>docprompt/_pdfium.py</code> <pre><code>def chunk_iterable(iterable: Iterable[T], chunk_size: int) -&gt; List[List[T]]:\n    \"\"\"\n    Splits an iterable into chunks of specified size, distributing the remainder evenly.\n\n    Args:\n        iterable (Iterable[T]): The iterable to be chunked.\n        chunk_size (int): The desired size of each chunk.\n\n    Returns:\n        List[List[T]]: A list of lists, where each sublist is a chunk.\n    \"\"\"\n    # Convert the iterable to a list\n    items = list(iterable)\n    total_items = len(items)\n\n    # Calculate the number of chunks needed\n    num_chunks = (total_items + chunk_size - 1) // chunk_size\n\n    # Calculate the ideal size of each chunk\n    ideal_chunk_size = total_items // num_chunks\n    remainder = total_items % num_chunks\n\n    # Create the chunks\n    chunks = []\n    start = 0\n    for i in range(num_chunks):\n        end = start + ideal_chunk_size + (1 if i &lt; remainder else 0)\n        chunks.append(items[start:end])\n        start = end\n\n    return chunks\n</code></pre>"},{"location":"reference/_pdfium/#docprompt._pdfium.get_pdfium_document","title":"<code>get_pdfium_document(fp, password=None)</code>","text":"<p>Loads a PDF document with a lock to prevent race conditions in threaded environments</p> Source code in <code>docprompt/_pdfium.py</code> <pre><code>@contextmanager\ndef get_pdfium_document(\n    fp: Union[PathLike, Path, bytes, str], password: Optional[str] = None\n):\n    \"\"\"\n    Loads a PDF document with a lock to prevent race conditions in threaded environments\n    \"\"\"\n    with PDFIUM_LOAD_LOCK:\n        pdf = pdfium.PdfDocument(fp, password=password, autoclose=False)\n\n    try:\n        yield pdf\n    finally:\n        pdf.close()\n</code></pre>"},{"location":"reference/_pdfium/#docprompt._pdfium.rasterize_page_with_pdfium","title":"<code>rasterize_page_with_pdfium(fp, page_number, *, return_mode='pil', post_process_fn=None, **kwargs)</code>","text":"<p>Rasterizes a page of a PDF document</p> Source code in <code>docprompt/_pdfium.py</code> <pre><code>def rasterize_page_with_pdfium(\n    fp: Union[PathLike, Path, bytes],\n    page_number: int,\n    *,\n    return_mode: Literal[\"pil\", \"bytes\"] = \"pil\",\n    post_process_fn: Optional[Callable[[Image.Image], Image.Image]] = None,\n    **kwargs,\n) -&gt; Union[Image.Image, bytes]:\n    \"\"\"\n    Rasterizes a page of a PDF document\n    \"\"\"\n    with get_pdfium_document(fp) as pdf:\n        return _render_job(\n            page_number - 1,\n            pdf,\n            kwargs,\n            return_mode=return_mode,\n            post_process_fn=post_process_fn,\n        )\n</code></pre>"},{"location":"reference/_pdfium/#docprompt._pdfium.rasterize_pdf_with_pdfium","title":"<code>rasterize_pdf_with_pdfium(fp, password=None, *, return_mode='pil', post_process_fn=None, **kwargs)</code>","text":"<p>Rasterizes an entire PDF using PDFium and a pool of workers</p> Source code in <code>docprompt/_pdfium.py</code> <pre><code>def rasterize_pdf_with_pdfium(\n    fp: Union[PathLike, Path, bytes],\n    password: Optional[str] = None,\n    *,\n    return_mode: Literal[\"pil\", \"bytes\"] = \"pil\",\n    post_process_fn: Optional[Callable[[Image.Image], Image.Image]] = None,\n    **kwargs,\n) -&gt; List[Union[Image.Image, bytes]]:\n    \"\"\"\n    Rasterizes an entire PDF using PDFium and a pool of workers\n    \"\"\"\n    with get_pdfium_document(fp, password=password) as pdf:\n        total_pages = len(pdf)\n\n    max_workers = min(mp.cpu_count(), total_pages)\n\n    ctx = mp.get_context(\"spawn\")\n\n    with potential_temporary_file(fp) as temp_fp:\n        initargs = (\n            None,\n            temp_fp,\n            password,\n            False,\n            kwargs,\n            return_mode,\n            post_process_fn,\n        )\n\n        with ft.ProcessPoolExecutor(\n            max_workers=max_workers,\n            initializer=_render_parallel_init,\n            initargs=initargs,\n            mp_context=ctx,\n        ) as executor:\n            results = executor.map(\n                _render_parallel_job, range(total_pages), chunksize=1\n            )\n\n        return list(results)\n</code></pre>"},{"location":"reference/_pdfium/#docprompt._pdfium.rasterize_pdfs_with_pdfium","title":"<code>rasterize_pdfs_with_pdfium(fps, passwords=None, *, return_mode='pil', post_process_fn=None, **kwargs)</code>","text":"<p>Like 'rasterize_pdf_with_pdfium', but optimized for multiple PDFs by loading all PDF's into the workers memory space</p> Source code in <code>docprompt/_pdfium.py</code> <pre><code>def rasterize_pdfs_with_pdfium(\n    fps: List[Union[PathLike, Path, bytes]],\n    passwords: Optional[List[str]] = None,\n    *,\n    return_mode: Literal[\"pil\", \"bytes\"] = \"pil\",\n    post_process_fn: Optional[Callable[[Image.Image], Image.Image]] = None,\n    **kwargs,\n) -&gt; Dict[int, Dict[int, Union[Image.Image, bytes]]]:\n    \"\"\"\n    Like 'rasterize_pdf_with_pdfium', but optimized for multiple PDFs by loading all PDF's into the workers memory space\n    \"\"\"\n    if passwords and len(passwords) != len(fps):\n        raise ValueError(\n            \"If specifying passwords, must provide one for each PDF. Use None for no password.\"\n        )\n    passwords = passwords or [None] * len(fps)\n\n    ctx = mp.get_context(\"spawn\")\n\n    with tempfile.TemporaryDirectory(prefix=\"docprompt_raster_tmp\") as tempdir:\n        writable_fps = _get_writable_temp_fp_paths(fps, tempdir)\n        page_counts = _get_page_counts_from_pdfs(writable_fps)\n        total_to_process = sum(page_counts)\n\n        max_workers = min(mp.cpu_count(), total_to_process)\n\n        pdf_page_map = dict(enumerate(page_counts))\n        name_to_idx = {fp: i for i, fp in enumerate(writable_fps)}\n\n        core_pdf_assignments = distribute_pdfs(pdf_page_map, max_workers)\n\n        with mp.Manager() as manager:\n            mp_queue = manager.Queue()\n\n            processes = []\n\n            with tqdm(total=total_to_process, desc=\"Rasterizing PDF's\") as pbar:\n                for core_id, pdf_page_map in core_pdf_assignments.items():\n                    data = {\n                        (writable_fps[i], passwords[i]): pages\n                        for i, pages in pdf_page_map.items()\n                    }\n\n                    p = ctx.Process(\n                        target=process_work,\n                        args=(data, post_process_fn, return_mode, mp_queue),\n                    )\n                    p.start()\n                    processes.append(p)\n\n                results: Dict[int, Dict[int, Union[Image.Image, bytes]]] = {}\n\n                while any(p.is_alive() for p in processes) or not mp_queue.empty():\n                    try:\n                        pdf, page, result = mp_queue.get(timeout=0.5)\n                        i = name_to_idx[pdf]\n                        results.setdefault(i, {})[page] = result\n                        pbar.update(1)\n                    except queue.Empty:\n                        pass\n\n    return results\n</code></pre>"},{"location":"reference/rasterize/","title":"rasterize","text":""},{"location":"reference/rasterize/#docprompt.rasterize.estimate_png_byte_size","title":"<code>estimate_png_byte_size(image, assummed_compression_ratio=4.0, overhead_bytes=1024)</code>","text":"<p>Provides an estimate of the size of a PNG image given the uncompressed size and an assumed compression ratio.</p> <p>The default compression ratio of 4.0 is based on the assumption that the image is a document, and represents a pessimistic estimate.</p> Source code in <code>docprompt/rasterize.py</code> <pre><code>def estimate_png_byte_size(\n    image: Image.Image,\n    assummed_compression_ratio: float = 4.0,\n    overhead_bytes: int = 1024,\n) -&gt; int:\n    \"\"\"\n    Provides an estimate of the size of a PNG image given the uncompressed size and an assumed compression ratio.\n\n    The default compression ratio of 4.0 is based on the assumption that the image is a document, and represents a\n    pessimistic estimate.\n    \"\"\"\n    width, height = image.size\n    mode = image.mode\n\n    # Determine bytes per pixel based on image mode\n    if mode == \"1\":\n        bytes_per_pixel = 1 / 8  # 1 bit per pixel\n    elif mode == \"L\":\n        bytes_per_pixel = 1  # 1 byte per pixel\n    elif mode == \"LA\":\n        bytes_per_pixel = 2  # 2 bytes per pixel\n    elif mode == \"RGB\":\n        bytes_per_pixel = 3  # 3 bytes per pixel\n    elif mode == \"RGBA\":\n        bytes_per_pixel = 4  # 4 bytes per pixel\n    else:\n        raise ValueError(f\"Unsupported image mode: {mode}\")\n\n    uncompressed_size = width * height * bytes_per_pixel\n    compressed_size = uncompressed_size / assummed_compression_ratio\n\n    return int(compressed_size + overhead_bytes)\n</code></pre>"},{"location":"reference/rasterize/#docprompt.rasterize.mask_image_from_bboxes","title":"<code>mask_image_from_bboxes(image, bboxes, *, mask_color='black')</code>","text":"<p>Given a set of normalized bounding boxes, masks the image. :param image: PIL Image object or bytes object representing an image. :param bboxes: Iterable of NormBBox objects. :param mask_color: Color used for the mask, can be a string (e.g., \"black\") or a tuple (e.g., (0, 0, 0)).</p> Source code in <code>docprompt/rasterize.py</code> <pre><code>def mask_image_from_bboxes(\n    image: PILOrBytes,\n    bboxes: Iterable[NormBBox],\n    *,\n    mask_color: Union[str, int] = \"black\",\n):\n    \"\"\"\n    Given a set of normalized bounding boxes, masks the image.\n    :param image: PIL Image object or bytes object representing an image.\n    :param bboxes: Iterable of NormBBox objects.\n    :param mask_color: Color used for the mask, can be a string (e.g., \"black\") or a tuple (e.g., (0, 0, 0)).\n    \"\"\"\n    # Convert bytes image to PIL Image if necessary\n    if isinstance(image, bytes):\n        image = load_image_from_bytes(image)\n\n    # Get image dimensions\n    width, height = image.size\n\n    # Create a drawing context\n    draw = ImageDraw.Draw(image)\n\n    # Draw rectangles over the specified bounding boxes\n    for bbox in bboxes:\n        # Convert normalized coordinates to absolute coordinates\n        absolute_bbox = (\n            bbox.x0 * width,\n            bbox.top * height,\n            bbox.x1 * width,\n            bbox.bottom * height,\n        )\n        # Draw rectangle\n        draw.rectangle(absolute_bbox, fill=mask_color)\n\n    return image\n</code></pre>"},{"location":"reference/rasterize/#docprompt.rasterize.resize_image_to_fize_size_limit","title":"<code>resize_image_to_fize_size_limit(image, max_file_size_bytes, *, resize_mode='thumbnail', resize_step_size=0.1, allow_channel_reduction=True, image_convert_mode='L')</code>","text":"<p>Incrementally resizes an image until it is under a certain file size</p> Source code in <code>docprompt/rasterize.py</code> <pre><code>def resize_image_to_fize_size_limit(\n    image: PILOrBytes,\n    max_file_size_bytes: int,\n    *,\n    resize_mode: ResizeModes = \"thumbnail\",\n    resize_step_size: float = 0.1,\n    allow_channel_reduction: bool = True,\n    image_convert_mode: str = \"L\",\n) -&gt; Image.Image:\n    \"\"\"\n    Incrementally resizes an image until it is under a certain file size\n    \"\"\"\n    if resize_step_size &lt;= 0 or resize_step_size &gt;= 0.5:\n        raise ValueError(\"resize_step_size must be between 0 and 0.5\")\n\n    if isinstance(image, bytes):\n        image = load_image_from_bytes(image)\n\n    estimated_bytes = estimate_png_byte_size(image)\n\n    if estimated_bytes &lt; max_file_size_bytes:\n        return image\n\n    # Convert image to the desired mode if it has multiple channels\n    if allow_channel_reduction and image.mode in [\"LA\", \"RGBA\"]:\n        image = image.convert(image_convert_mode)\n\n        if estimate_png_byte_size(image) &lt; max_file_size_bytes:\n            return image\n\n    step_count = 0\n    working_image = image.copy()\n\n    while estimated_bytes &gt; max_file_size_bytes:\n        new_width = int(image.width * (1 - resize_step_size * step_count))\n        new_height = int(image.height * (1 - resize_step_size * step_count))\n\n        if new_width &lt;= 200 or new_height &lt;= 200:\n            logger.warning(\n                f\"Image could not be resized to under {max_file_size_bytes} bytes. Reached {estimated_bytes} bytes.\"\n            )\n            break\n\n        if resize_mode == \"thumbnail\":\n            working_image.thumbnail((new_width, new_height))\n        elif resize_mode == \"resize\":\n            working_image = working_image.resize((new_width, new_height))\n\n        estimated_bytes = estimate_png_byte_size(working_image)\n\n        if estimated_bytes &lt; max_file_size_bytes:\n            return working_image\n\n        step_count += 1\n\n    return working_image\n</code></pre>"},{"location":"reference/_exec/","title":"Index","text":""},{"location":"reference/_exec/ghostscript/","title":"ghostscript","text":""},{"location":"reference/contrib/","title":"Index","text":""},{"location":"reference/contrib/parser_bot/","title":"parser_bot","text":""},{"location":"reference/provenance/","title":"Index","text":""},{"location":"reference/provenance/#docprompt.provenance.PageTextLocation","title":"<code>PageTextLocation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Specifies the location of a piece of text in a page</p> Source code in <code>docprompt/provenance/source.py</code> <pre><code>class PageTextLocation(BaseModel):\n    \"\"\"\n    Specifies the location of a piece of text in a page\n    \"\"\"\n\n    source_blocks: List[TextBlock] = Field(\n        description=\"The source text blocks\", repr=False\n    )\n    text: str  # Sometimes the source text is less than the textblock's text.\n    score: float\n    granularity: Literal[\"word\", \"line\", \"block\"] = \"block\"\n\n    merged_source_block: Optional[TextBlock] = Field(default=None)\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.ProvenanceSource","title":"<code>ProvenanceSource</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Bundled with some data, specifies exactly where a piece of verbatim text came from in a document.</p> Source code in <code>docprompt/provenance/source.py</code> <pre><code>class ProvenanceSource(BaseModel):\n    \"\"\"\n    Bundled with some data, specifies exactly where a piece of verbatim text came from\n    in a document.\n    \"\"\"\n\n    document_name: str\n    page_number: PositiveInt\n    text_location: Optional[PageTextLocation] = None\n\n    @computed_field  # type: ignore\n    @property\n    def source_block(self) -&gt; Optional[TextBlock]:\n        if self.text_location:\n            if self.text_location.merged_source_block:\n                return self.text_location.merged_source_block\n            if self.text_location.source_blocks:\n                return self.text_location.source_blocks[0]\n\n            return None\n\n    @property\n    def text(self) -&gt; str:\n        if self.text_location:\n            return \"\\n\".join([block.text for block in self.text_location.source_blocks])\n\n        return \"\"\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.search","title":"<code>search</code>","text":""},{"location":"reference/provenance/#docprompt.provenance.search.DocumentProvenanceLocator","title":"<code>DocumentProvenanceLocator</code>  <code>dataclass</code>","text":"Source code in <code>docprompt/provenance/search.py</code> <pre><code>@dataclass\nclass DocumentProvenanceLocator:\n    document_name: str\n    search_index: \"tantivy.Index\"\n    block_mapping: Dict[int, OcrPageResult] = field(repr=False)\n    geo_index: DocumentProvenanceGeoMap = field(repr=False)\n\n    @classmethod\n    def from_document_node(cls, document_node: \"DocumentNode\"):\n        index = create_tantivy_document_wise_block_index()\n        block_mapping_dict = {}\n        geo_index_dict: DocumentProvenanceGeoMap = {}\n\n        writer = index.writer()\n\n        for page_node in document_node.page_nodes:\n            if (\n                not page_node.ocr_results.result\n                or not page_node.ocr_results.result.block_level_blocks\n            ):\n                continue\n\n            ocr_result = page_node.ocr_results.result\n\n            for idx, text_block in enumerate(ocr_result.block_level_blocks):\n                writer.add_document(\n                    tantivy.Document(\n                        page_number=page_node.page_number,\n                        block_type=text_block.type,\n                        block_page_idx=idx,\n                        content=text_block.text,\n                    )\n                )\n\n            for granularity in [\"word\", \"line\", \"block\"]:\n                text_blocks = getattr(ocr_result, f\"{granularity}_level_blocks\", [])\n\n                bounding_boxes = [text_block.bounding_box for text_block in text_blocks]\n\n                if bounding_boxes:\n                    r_tree = RTreeIndex(\n                        insert_generator(bounding_boxes), fill_factor=0.9\n                    )\n                else:\n                    r_tree = RTreeIndex()\n\n                if page_node.page_number not in geo_index_dict:\n                    geo_index_dict[page_node.page_number] = {}\n\n                geo_index_dict[page_node.page_number][granularity] = r_tree  # type: ignore\n\n            block_mapping_dict[page_node.page_number] = ocr_result\n\n        writer.commit()\n        index.reload()\n\n        return cls(\n            document_name=document_node.document.name,\n            search_index=index,\n            block_mapping=block_mapping_dict,\n            geo_index=geo_index_dict,\n        )\n\n    def _construct_tantivy_query(\n        self, query: str, page_number: Optional[int] = None\n    ) -&gt; tantivy.Query:\n        query = preprocess_query_text(query)\n\n        if page_number is None:\n            return self.search_index.parse_query(f'content:\"{query}\"')\n        else:\n            return self.search_index.parse_query(\n                f'(page_number:{page_number}) AND content:\"{query}\"'\n            )\n\n    def get_k_nearest_blocks(\n        self,\n        bbox: NormBBox,\n        page_number: int,\n        k: int,\n        granularity: BlockGranularity = \"block\",\n    ) -&gt; List[TextBlock]:\n        \"\"\"\n        Get the k nearest text blocks to a given bounding box\n        \"\"\"\n        search_tuple = construct_valid_rtree_tuple(bbox)\n\n        word_level_bbox_indices = list(\n            self.geo_index[page_number][granularity].nearest(\n                search_tuple, num_results=k\n            )\n        )\n\n        block_mapping = self.block_mapping[page_number]\n\n        nearest_blocks = [\n            getattr(block_mapping, granularity + \"s\")[idx]\n            for idx in word_level_bbox_indices\n        ]\n\n        nearest_blocks.sort(key=lambda x: (x.bounding_box.top, x.bounding_box.x0))\n\n        return [x for x in nearest_blocks if x.bounding_box != bbox]\n\n    def get_overlapping_blocks(\n        self, bbox: NormBBox, page_number: int, granularity: BlockGranularity = \"block\"\n    ) -&gt; List[TextBlock]:\n        \"\"\"\n        Get the text blocks that overlap with a given bounding box\n        \"\"\"\n        search_tuple = construct_valid_rtree_tuple(bbox)\n\n        bbox_indices = list(\n            self.geo_index[page_number][granularity].intersection(search_tuple)\n        )\n\n        block_mapping = self.block_mapping[page_number]\n\n        overlapping_blocks = [\n            getattr(block_mapping, f\"{granularity}_level_blocks\")[idx]\n            for idx in bbox_indices\n        ]\n\n        overlapping_blocks.sort(key=lambda x: (x.bounding_box.top, x.bounding_box.x0))\n\n        return [x for x in overlapping_blocks if x.bounding_box != bbox]\n\n    def search_raw(self, raw_query: str) -&gt; List[str]:\n        \"\"\"\n        Search for a piece of text using a raw query\n\n        Args:\n            query: The text to search for\n            page_number: The page number to search on\n        \"\"\"\n        parsed_query = self.search_index.parse_query(raw_query)\n\n        searcher = self.search_index.searcher()\n\n        search_results = searcher.search(parsed_query, limit=100)\n\n        results = []\n\n        for score, doc_address in search_results.hits:\n            doc = searcher.doc(doc_address)\n\n            result_page_number = doc[\"page_number\"][0]\n            result_block_page_idx = doc[\"block_page_idx\"][0]\n            block_mapping = self.block_mapping[result_page_number]\n\n            source_block: TextBlock = block_mapping.block_level_blocks[\n                result_block_page_idx\n            ]\n\n            results.append(source_block.text)\n\n        return results\n\n    def refine_query_to_word_level(\n        self, query: str, page_number: int, enclosing_block: TextBlock\n    ):\n        \"\"\"\n        Refine a query to the word level\n        \"\"\"\n        search_tuple = construct_valid_rtree_tuple(enclosing_block.bounding_box)\n\n        word_level_bbox_indices = list(\n            self.geo_index[page_number][\"word\"].intersection(search_tuple)\n        )\n        word_level_blocks_in_original_bbox = [\n            self.block_mapping[page_number].word_level_blocks[idx]\n            for idx in word_level_bbox_indices\n        ]\n\n        refine_result = refine_block_to_word_level(\n            source_block=enclosing_block,\n            intersecting_word_level_blocks=word_level_blocks_in_original_bbox,\n            query=query,\n        )\n\n        return refine_result\n\n    def search(\n        self,\n        query: str,\n        page_number: Optional[int] = None,\n        *,\n        refine_to_word: bool = True,\n        require_exact_match: bool = True,\n    ) -&gt; List[ProvenanceSource]:\n        \"\"\"\n        Search for a piece of text in the document and return the source of it\n\n        Args:\n            query: The text to search for\n            page_number: The page number to search on\n            refine_to_word: Whether to refine the search to the word level\n            require_exact_match: Whether to require null results if `refine_to_word` is True and no exact match is found\n        \"\"\"\n        search_query = self._construct_tantivy_query(query, page_number)\n\n        searcher = self.search_index.searcher()\n\n        search_results = searcher.search(search_query, limit=100)\n\n        results = []\n\n        for score, doc_address in search_results.hits:\n            doc = searcher.doc(doc_address)\n\n            result_page_number = doc[\"page_number\"][0]\n            result_block_page_idx = doc[\"block_page_idx\"][0]\n            block_mapping = self.block_mapping[result_page_number]\n\n            source_block: TextBlock = block_mapping.block_level_blocks[\n                result_block_page_idx\n            ]\n\n            source_blocks = [source_block]\n            principal_block = source_block\n\n            if refine_to_word:\n                refine_result = self.refine_query_to_word_level(\n                    query=query,\n                    page_number=result_page_number,\n                    enclosing_block=source_block,\n                )\n\n                if refine_result is not None:\n                    principal_block, source_blocks = refine_result\n                elif require_exact_match:\n                    continue\n\n            source = ProvenanceSource(\n                document_name=self.document_name,\n                page_number=result_page_number,\n                text_location=PageTextLocation(\n                    source_blocks=source_blocks,\n                    text=query,\n                    score=score,\n                    granularity=\"block\",\n                    merged_source_block=principal_block,\n                ),\n            )\n            results.append(source)\n\n        results.sort(key=lambda x: x.page_number)\n\n        return results\n\n    def search_n_best(\n        self, query: str, n: int = 3, mode: SearchBestModes = \"shortest_text\"\n    ) -&gt; List[ProvenanceSource]:\n        results = self.search(query)\n\n        if not results:\n            return []\n\n        if mode == \"shortest_text\":\n            score_func = lambda x: len(x.source_block.text)  # noqa: E731\n        elif mode == \"longest_text\":\n            score_func = lambda x: -len(x[0].source_block.text)  # noqa: E731\n        elif mode == \"highest_score\":\n            score_func = lambda x: x[1]  # noqa: E731\n        else:\n            raise ValueError(f\"Unknown mode {mode}\")\n\n        results.sort(key=score_func)\n\n        return results[:n]\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.search.DocumentProvenanceLocator.get_k_nearest_blocks","title":"<code>get_k_nearest_blocks(bbox, page_number, k, granularity='block')</code>","text":"<p>Get the k nearest text blocks to a given bounding box</p> Source code in <code>docprompt/provenance/search.py</code> <pre><code>def get_k_nearest_blocks(\n    self,\n    bbox: NormBBox,\n    page_number: int,\n    k: int,\n    granularity: BlockGranularity = \"block\",\n) -&gt; List[TextBlock]:\n    \"\"\"\n    Get the k nearest text blocks to a given bounding box\n    \"\"\"\n    search_tuple = construct_valid_rtree_tuple(bbox)\n\n    word_level_bbox_indices = list(\n        self.geo_index[page_number][granularity].nearest(\n            search_tuple, num_results=k\n        )\n    )\n\n    block_mapping = self.block_mapping[page_number]\n\n    nearest_blocks = [\n        getattr(block_mapping, granularity + \"s\")[idx]\n        for idx in word_level_bbox_indices\n    ]\n\n    nearest_blocks.sort(key=lambda x: (x.bounding_box.top, x.bounding_box.x0))\n\n    return [x for x in nearest_blocks if x.bounding_box != bbox]\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.search.DocumentProvenanceLocator.get_overlapping_blocks","title":"<code>get_overlapping_blocks(bbox, page_number, granularity='block')</code>","text":"<p>Get the text blocks that overlap with a given bounding box</p> Source code in <code>docprompt/provenance/search.py</code> <pre><code>def get_overlapping_blocks(\n    self, bbox: NormBBox, page_number: int, granularity: BlockGranularity = \"block\"\n) -&gt; List[TextBlock]:\n    \"\"\"\n    Get the text blocks that overlap with a given bounding box\n    \"\"\"\n    search_tuple = construct_valid_rtree_tuple(bbox)\n\n    bbox_indices = list(\n        self.geo_index[page_number][granularity].intersection(search_tuple)\n    )\n\n    block_mapping = self.block_mapping[page_number]\n\n    overlapping_blocks = [\n        getattr(block_mapping, f\"{granularity}_level_blocks\")[idx]\n        for idx in bbox_indices\n    ]\n\n    overlapping_blocks.sort(key=lambda x: (x.bounding_box.top, x.bounding_box.x0))\n\n    return [x for x in overlapping_blocks if x.bounding_box != bbox]\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.search.DocumentProvenanceLocator.refine_query_to_word_level","title":"<code>refine_query_to_word_level(query, page_number, enclosing_block)</code>","text":"<p>Refine a query to the word level</p> Source code in <code>docprompt/provenance/search.py</code> <pre><code>def refine_query_to_word_level(\n    self, query: str, page_number: int, enclosing_block: TextBlock\n):\n    \"\"\"\n    Refine a query to the word level\n    \"\"\"\n    search_tuple = construct_valid_rtree_tuple(enclosing_block.bounding_box)\n\n    word_level_bbox_indices = list(\n        self.geo_index[page_number][\"word\"].intersection(search_tuple)\n    )\n    word_level_blocks_in_original_bbox = [\n        self.block_mapping[page_number].word_level_blocks[idx]\n        for idx in word_level_bbox_indices\n    ]\n\n    refine_result = refine_block_to_word_level(\n        source_block=enclosing_block,\n        intersecting_word_level_blocks=word_level_blocks_in_original_bbox,\n        query=query,\n    )\n\n    return refine_result\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.search.DocumentProvenanceLocator.search","title":"<code>search(query, page_number=None, *, refine_to_word=True, require_exact_match=True)</code>","text":"<p>Search for a piece of text in the document and return the source of it</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The text to search for</p> required <code>page_number</code> <code>Optional[int]</code> <p>The page number to search on</p> <code>None</code> <code>refine_to_word</code> <code>bool</code> <p>Whether to refine the search to the word level</p> <code>True</code> <code>require_exact_match</code> <code>bool</code> <p>Whether to require null results if <code>refine_to_word</code> is True and no exact match is found</p> <code>True</code> Source code in <code>docprompt/provenance/search.py</code> <pre><code>def search(\n    self,\n    query: str,\n    page_number: Optional[int] = None,\n    *,\n    refine_to_word: bool = True,\n    require_exact_match: bool = True,\n) -&gt; List[ProvenanceSource]:\n    \"\"\"\n    Search for a piece of text in the document and return the source of it\n\n    Args:\n        query: The text to search for\n        page_number: The page number to search on\n        refine_to_word: Whether to refine the search to the word level\n        require_exact_match: Whether to require null results if `refine_to_word` is True and no exact match is found\n    \"\"\"\n    search_query = self._construct_tantivy_query(query, page_number)\n\n    searcher = self.search_index.searcher()\n\n    search_results = searcher.search(search_query, limit=100)\n\n    results = []\n\n    for score, doc_address in search_results.hits:\n        doc = searcher.doc(doc_address)\n\n        result_page_number = doc[\"page_number\"][0]\n        result_block_page_idx = doc[\"block_page_idx\"][0]\n        block_mapping = self.block_mapping[result_page_number]\n\n        source_block: TextBlock = block_mapping.block_level_blocks[\n            result_block_page_idx\n        ]\n\n        source_blocks = [source_block]\n        principal_block = source_block\n\n        if refine_to_word:\n            refine_result = self.refine_query_to_word_level(\n                query=query,\n                page_number=result_page_number,\n                enclosing_block=source_block,\n            )\n\n            if refine_result is not None:\n                principal_block, source_blocks = refine_result\n            elif require_exact_match:\n                continue\n\n        source = ProvenanceSource(\n            document_name=self.document_name,\n            page_number=result_page_number,\n            text_location=PageTextLocation(\n                source_blocks=source_blocks,\n                text=query,\n                score=score,\n                granularity=\"block\",\n                merged_source_block=principal_block,\n            ),\n        )\n        results.append(source)\n\n    results.sort(key=lambda x: x.page_number)\n\n    return results\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.search.DocumentProvenanceLocator.search_raw","title":"<code>search_raw(raw_query)</code>","text":"<p>Search for a piece of text using a raw query</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>The text to search for</p> required <code>page_number</code> <p>The page number to search on</p> required Source code in <code>docprompt/provenance/search.py</code> <pre><code>def search_raw(self, raw_query: str) -&gt; List[str]:\n    \"\"\"\n    Search for a piece of text using a raw query\n\n    Args:\n        query: The text to search for\n        page_number: The page number to search on\n    \"\"\"\n    parsed_query = self.search_index.parse_query(raw_query)\n\n    searcher = self.search_index.searcher()\n\n    search_results = searcher.search(parsed_query, limit=100)\n\n    results = []\n\n    for score, doc_address in search_results.hits:\n        doc = searcher.doc(doc_address)\n\n        result_page_number = doc[\"page_number\"][0]\n        result_block_page_idx = doc[\"block_page_idx\"][0]\n        block_mapping = self.block_mapping[result_page_number]\n\n        source_block: TextBlock = block_mapping.block_level_blocks[\n            result_block_page_idx\n        ]\n\n        results.append(source_block.text)\n\n    return results\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.source","title":"<code>source</code>","text":""},{"location":"reference/provenance/#docprompt.provenance.source.PageTextLocation","title":"<code>PageTextLocation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Specifies the location of a piece of text in a page</p> Source code in <code>docprompt/provenance/source.py</code> <pre><code>class PageTextLocation(BaseModel):\n    \"\"\"\n    Specifies the location of a piece of text in a page\n    \"\"\"\n\n    source_blocks: List[TextBlock] = Field(\n        description=\"The source text blocks\", repr=False\n    )\n    text: str  # Sometimes the source text is less than the textblock's text.\n    score: float\n    granularity: Literal[\"word\", \"line\", \"block\"] = \"block\"\n\n    merged_source_block: Optional[TextBlock] = Field(default=None)\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.source.ProvenanceSource","title":"<code>ProvenanceSource</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Bundled with some data, specifies exactly where a piece of verbatim text came from in a document.</p> Source code in <code>docprompt/provenance/source.py</code> <pre><code>class ProvenanceSource(BaseModel):\n    \"\"\"\n    Bundled with some data, specifies exactly where a piece of verbatim text came from\n    in a document.\n    \"\"\"\n\n    document_name: str\n    page_number: PositiveInt\n    text_location: Optional[PageTextLocation] = None\n\n    @computed_field  # type: ignore\n    @property\n    def source_block(self) -&gt; Optional[TextBlock]:\n        if self.text_location:\n            if self.text_location.merged_source_block:\n                return self.text_location.merged_source_block\n            if self.text_location.source_blocks:\n                return self.text_location.source_blocks[0]\n\n            return None\n\n    @property\n    def text(self) -&gt; str:\n        if self.text_location:\n            return \"\\n\".join([block.text for block in self.text_location.source_blocks])\n\n        return \"\"\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.util","title":"<code>util</code>","text":""},{"location":"reference/provenance/#docprompt.provenance.util.insert_generator","title":"<code>insert_generator(bboxes, data=None)</code>","text":"<p>Make an iterator that yields tuples of (id, bbox, data) for insertion into an RTree index which improves performance massively.</p> Source code in <code>docprompt/provenance/util.py</code> <pre><code>def insert_generator(bboxes: List[NormBBox], data: Optional[Iterable[Any]] = None):\n    \"\"\"\n    Make an iterator that yields tuples of (id, bbox, data) for insertion into an RTree index\n    which improves performance massively.\n    \"\"\"\n    data = data or [None] * len(bboxes)\n\n    for idx, (bbox, data_item) in enumerate(zip(bboxes, data)):\n        yield (idx, construct_valid_rtree_tuple(bbox), data_item)\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.util.preprocess_query_text","title":"<code>preprocess_query_text(text)</code>","text":"<p>Improve matching ability by applying some preprocessing to the query text.</p> Source code in <code>docprompt/provenance/util.py</code> <pre><code>def preprocess_query_text(text: str) -&gt; str:\n    \"\"\"\n    Improve matching ability by applying some preprocessing to the query text.\n    \"\"\"\n    for regex in _prefix_regexs:\n        text = regex.sub(\"\", text)\n\n    text = text.strip()\n\n    text = text.replace('\"', \"\")\n\n    return text\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.util.refine_block_to_word_level","title":"<code>refine_block_to_word_level(source_block, intersecting_word_level_blocks, query)</code>","text":"<p>Create a new text block by merging the intersecting word level blocks that match the query.</p> Source code in <code>docprompt/provenance/util.py</code> <pre><code>def refine_block_to_word_level(\n    source_block: TextBlock,\n    intersecting_word_level_blocks: List[TextBlock],\n    query: str,\n):\n    \"\"\"\n    Create a new text block by merging the intersecting word level blocks that\n    match the query.\n\n    \"\"\"\n    intersecting_word_level_blocks.sort(\n        key=lambda x: (x.bounding_box.top, x.bounding_box.x0)\n    )\n\n    tokenized_query = word_tokenize(query)\n\n    if len(tokenized_query) == 1:\n        fuzzified = default_process(tokenized_query[0])\n        for word_level_block in intersecting_word_level_blocks:\n            if fuzz.ratio(fuzzified, default_process(word_level_block.text)) &gt; 87.5:\n                return word_level_block, [word_level_block]\n    else:\n        fuzzified_word_level_texts = [\n            default_process(word_level_block.text)\n            for word_level_block in intersecting_word_level_blocks\n        ]\n\n        # Populate the block mapping\n        token_block_mapping = defaultdict(set)\n\n        first_word = tokenized_query[0]\n        last_word = tokenized_query[-1]\n\n        for token in tokenized_query:\n            fuzzified_token = default_process(token)\n            for i, word_level_block in enumerate(intersecting_word_level_blocks):\n                if fuzz.ratio(fuzzified_token, fuzzified_word_level_texts[i]) &gt; 87.5:\n                    token_block_mapping[token].add(i)\n\n        graph = networkx.DiGraph()\n        prev = tokenized_query[0]\n\n        for i in token_block_mapping[prev]:\n            graph.add_node(i)\n\n        for token in tokenized_query[1:]:\n            for prev_block in token_block_mapping[prev]:\n                for block in sorted(token_block_mapping[token]):\n                    if block &gt; prev_block:\n                        weight = (\n                            (block - prev_block) ** 2\n                        )  # Square the distance to penalize large jumps, which encourages reading order\n                        graph.add_edge(prev_block, block, weight=weight)\n\n            prev = token\n\n        # Get every combination of first and last word\n        first_word_blocks = token_block_mapping[first_word]\n        last_word_blocks = token_block_mapping[last_word]\n\n        combinations = sorted(\n            [(x, y) for x in first_word_blocks for y in last_word_blocks if x &lt; y],\n            key=lambda x: abs(x[1] - x[0]),\n        )\n\n        for start, end in combinations:\n            try:\n                path = networkx.shortest_path(graph, start, end, weight=\"weight\")\n            except networkx.NetworkXNoPath:\n                continue\n            except Exception:\n                continue\n\n            matching_blocks = [intersecting_word_level_blocks[i] for i in path]\n\n            merged_bbox = NormBBox.combine(\n                *[word_level_block.bounding_box for word_level_block in matching_blocks]\n            )\n\n            merged_text = \"\"\n\n            for word_level_block in matching_blocks:\n                merged_text += word_level_block.text\n                if not word_level_block.text.endswith(\" \"):\n                    merged_text += \" \"  # Ensure there is a space between words\n\n            return (\n                TextBlock(\n                    text=merged_text,\n                    type=\"block\",\n                    bounding_box=merged_bbox,\n                    metadata=source_block.metadata,\n                ),\n                matching_blocks,\n            )\n</code></pre>"},{"location":"reference/provenance/#docprompt.provenance.util.word_tokenize","title":"<code>word_tokenize(text)</code>","text":"<p>Tokenize a string into words.</p> Source code in <code>docprompt/provenance/util.py</code> <pre><code>def word_tokenize(text: str) -&gt; List[str]:\n    \"\"\"\n    Tokenize a string into words.\n    \"\"\"\n    return re.split(r\"\\s+\", text)\n</code></pre>"},{"location":"reference/provenance/search/","title":"search","text":""},{"location":"reference/provenance/search/#docprompt.provenance.search.DocumentProvenanceLocator","title":"<code>DocumentProvenanceLocator</code>  <code>dataclass</code>","text":"Source code in <code>docprompt/provenance/search.py</code> <pre><code>@dataclass\nclass DocumentProvenanceLocator:\n    document_name: str\n    search_index: \"tantivy.Index\"\n    block_mapping: Dict[int, OcrPageResult] = field(repr=False)\n    geo_index: DocumentProvenanceGeoMap = field(repr=False)\n\n    @classmethod\n    def from_document_node(cls, document_node: \"DocumentNode\"):\n        index = create_tantivy_document_wise_block_index()\n        block_mapping_dict = {}\n        geo_index_dict: DocumentProvenanceGeoMap = {}\n\n        writer = index.writer()\n\n        for page_node in document_node.page_nodes:\n            if (\n                not page_node.ocr_results.result\n                or not page_node.ocr_results.result.block_level_blocks\n            ):\n                continue\n\n            ocr_result = page_node.ocr_results.result\n\n            for idx, text_block in enumerate(ocr_result.block_level_blocks):\n                writer.add_document(\n                    tantivy.Document(\n                        page_number=page_node.page_number,\n                        block_type=text_block.type,\n                        block_page_idx=idx,\n                        content=text_block.text,\n                    )\n                )\n\n            for granularity in [\"word\", \"line\", \"block\"]:\n                text_blocks = getattr(ocr_result, f\"{granularity}_level_blocks\", [])\n\n                bounding_boxes = [text_block.bounding_box for text_block in text_blocks]\n\n                if bounding_boxes:\n                    r_tree = RTreeIndex(\n                        insert_generator(bounding_boxes), fill_factor=0.9\n                    )\n                else:\n                    r_tree = RTreeIndex()\n\n                if page_node.page_number not in geo_index_dict:\n                    geo_index_dict[page_node.page_number] = {}\n\n                geo_index_dict[page_node.page_number][granularity] = r_tree  # type: ignore\n\n            block_mapping_dict[page_node.page_number] = ocr_result\n\n        writer.commit()\n        index.reload()\n\n        return cls(\n            document_name=document_node.document.name,\n            search_index=index,\n            block_mapping=block_mapping_dict,\n            geo_index=geo_index_dict,\n        )\n\n    def _construct_tantivy_query(\n        self, query: str, page_number: Optional[int] = None\n    ) -&gt; tantivy.Query:\n        query = preprocess_query_text(query)\n\n        if page_number is None:\n            return self.search_index.parse_query(f'content:\"{query}\"')\n        else:\n            return self.search_index.parse_query(\n                f'(page_number:{page_number}) AND content:\"{query}\"'\n            )\n\n    def get_k_nearest_blocks(\n        self,\n        bbox: NormBBox,\n        page_number: int,\n        k: int,\n        granularity: BlockGranularity = \"block\",\n    ) -&gt; List[TextBlock]:\n        \"\"\"\n        Get the k nearest text blocks to a given bounding box\n        \"\"\"\n        search_tuple = construct_valid_rtree_tuple(bbox)\n\n        word_level_bbox_indices = list(\n            self.geo_index[page_number][granularity].nearest(\n                search_tuple, num_results=k\n            )\n        )\n\n        block_mapping = self.block_mapping[page_number]\n\n        nearest_blocks = [\n            getattr(block_mapping, granularity + \"s\")[idx]\n            for idx in word_level_bbox_indices\n        ]\n\n        nearest_blocks.sort(key=lambda x: (x.bounding_box.top, x.bounding_box.x0))\n\n        return [x for x in nearest_blocks if x.bounding_box != bbox]\n\n    def get_overlapping_blocks(\n        self, bbox: NormBBox, page_number: int, granularity: BlockGranularity = \"block\"\n    ) -&gt; List[TextBlock]:\n        \"\"\"\n        Get the text blocks that overlap with a given bounding box\n        \"\"\"\n        search_tuple = construct_valid_rtree_tuple(bbox)\n\n        bbox_indices = list(\n            self.geo_index[page_number][granularity].intersection(search_tuple)\n        )\n\n        block_mapping = self.block_mapping[page_number]\n\n        overlapping_blocks = [\n            getattr(block_mapping, f\"{granularity}_level_blocks\")[idx]\n            for idx in bbox_indices\n        ]\n\n        overlapping_blocks.sort(key=lambda x: (x.bounding_box.top, x.bounding_box.x0))\n\n        return [x for x in overlapping_blocks if x.bounding_box != bbox]\n\n    def search_raw(self, raw_query: str) -&gt; List[str]:\n        \"\"\"\n        Search for a piece of text using a raw query\n\n        Args:\n            query: The text to search for\n            page_number: The page number to search on\n        \"\"\"\n        parsed_query = self.search_index.parse_query(raw_query)\n\n        searcher = self.search_index.searcher()\n\n        search_results = searcher.search(parsed_query, limit=100)\n\n        results = []\n\n        for score, doc_address in search_results.hits:\n            doc = searcher.doc(doc_address)\n\n            result_page_number = doc[\"page_number\"][0]\n            result_block_page_idx = doc[\"block_page_idx\"][0]\n            block_mapping = self.block_mapping[result_page_number]\n\n            source_block: TextBlock = block_mapping.block_level_blocks[\n                result_block_page_idx\n            ]\n\n            results.append(source_block.text)\n\n        return results\n\n    def refine_query_to_word_level(\n        self, query: str, page_number: int, enclosing_block: TextBlock\n    ):\n        \"\"\"\n        Refine a query to the word level\n        \"\"\"\n        search_tuple = construct_valid_rtree_tuple(enclosing_block.bounding_box)\n\n        word_level_bbox_indices = list(\n            self.geo_index[page_number][\"word\"].intersection(search_tuple)\n        )\n        word_level_blocks_in_original_bbox = [\n            self.block_mapping[page_number].word_level_blocks[idx]\n            for idx in word_level_bbox_indices\n        ]\n\n        refine_result = refine_block_to_word_level(\n            source_block=enclosing_block,\n            intersecting_word_level_blocks=word_level_blocks_in_original_bbox,\n            query=query,\n        )\n\n        return refine_result\n\n    def search(\n        self,\n        query: str,\n        page_number: Optional[int] = None,\n        *,\n        refine_to_word: bool = True,\n        require_exact_match: bool = True,\n    ) -&gt; List[ProvenanceSource]:\n        \"\"\"\n        Search for a piece of text in the document and return the source of it\n\n        Args:\n            query: The text to search for\n            page_number: The page number to search on\n            refine_to_word: Whether to refine the search to the word level\n            require_exact_match: Whether to require null results if `refine_to_word` is True and no exact match is found\n        \"\"\"\n        search_query = self._construct_tantivy_query(query, page_number)\n\n        searcher = self.search_index.searcher()\n\n        search_results = searcher.search(search_query, limit=100)\n\n        results = []\n\n        for score, doc_address in search_results.hits:\n            doc = searcher.doc(doc_address)\n\n            result_page_number = doc[\"page_number\"][0]\n            result_block_page_idx = doc[\"block_page_idx\"][0]\n            block_mapping = self.block_mapping[result_page_number]\n\n            source_block: TextBlock = block_mapping.block_level_blocks[\n                result_block_page_idx\n            ]\n\n            source_blocks = [source_block]\n            principal_block = source_block\n\n            if refine_to_word:\n                refine_result = self.refine_query_to_word_level(\n                    query=query,\n                    page_number=result_page_number,\n                    enclosing_block=source_block,\n                )\n\n                if refine_result is not None:\n                    principal_block, source_blocks = refine_result\n                elif require_exact_match:\n                    continue\n\n            source = ProvenanceSource(\n                document_name=self.document_name,\n                page_number=result_page_number,\n                text_location=PageTextLocation(\n                    source_blocks=source_blocks,\n                    text=query,\n                    score=score,\n                    granularity=\"block\",\n                    merged_source_block=principal_block,\n                ),\n            )\n            results.append(source)\n\n        results.sort(key=lambda x: x.page_number)\n\n        return results\n\n    def search_n_best(\n        self, query: str, n: int = 3, mode: SearchBestModes = \"shortest_text\"\n    ) -&gt; List[ProvenanceSource]:\n        results = self.search(query)\n\n        if not results:\n            return []\n\n        if mode == \"shortest_text\":\n            score_func = lambda x: len(x.source_block.text)  # noqa: E731\n        elif mode == \"longest_text\":\n            score_func = lambda x: -len(x[0].source_block.text)  # noqa: E731\n        elif mode == \"highest_score\":\n            score_func = lambda x: x[1]  # noqa: E731\n        else:\n            raise ValueError(f\"Unknown mode {mode}\")\n\n        results.sort(key=score_func)\n\n        return results[:n]\n</code></pre>"},{"location":"reference/provenance/search/#docprompt.provenance.search.DocumentProvenanceLocator.get_k_nearest_blocks","title":"<code>get_k_nearest_blocks(bbox, page_number, k, granularity='block')</code>","text":"<p>Get the k nearest text blocks to a given bounding box</p> Source code in <code>docprompt/provenance/search.py</code> <pre><code>def get_k_nearest_blocks(\n    self,\n    bbox: NormBBox,\n    page_number: int,\n    k: int,\n    granularity: BlockGranularity = \"block\",\n) -&gt; List[TextBlock]:\n    \"\"\"\n    Get the k nearest text blocks to a given bounding box\n    \"\"\"\n    search_tuple = construct_valid_rtree_tuple(bbox)\n\n    word_level_bbox_indices = list(\n        self.geo_index[page_number][granularity].nearest(\n            search_tuple, num_results=k\n        )\n    )\n\n    block_mapping = self.block_mapping[page_number]\n\n    nearest_blocks = [\n        getattr(block_mapping, granularity + \"s\")[idx]\n        for idx in word_level_bbox_indices\n    ]\n\n    nearest_blocks.sort(key=lambda x: (x.bounding_box.top, x.bounding_box.x0))\n\n    return [x for x in nearest_blocks if x.bounding_box != bbox]\n</code></pre>"},{"location":"reference/provenance/search/#docprompt.provenance.search.DocumentProvenanceLocator.get_overlapping_blocks","title":"<code>get_overlapping_blocks(bbox, page_number, granularity='block')</code>","text":"<p>Get the text blocks that overlap with a given bounding box</p> Source code in <code>docprompt/provenance/search.py</code> <pre><code>def get_overlapping_blocks(\n    self, bbox: NormBBox, page_number: int, granularity: BlockGranularity = \"block\"\n) -&gt; List[TextBlock]:\n    \"\"\"\n    Get the text blocks that overlap with a given bounding box\n    \"\"\"\n    search_tuple = construct_valid_rtree_tuple(bbox)\n\n    bbox_indices = list(\n        self.geo_index[page_number][granularity].intersection(search_tuple)\n    )\n\n    block_mapping = self.block_mapping[page_number]\n\n    overlapping_blocks = [\n        getattr(block_mapping, f\"{granularity}_level_blocks\")[idx]\n        for idx in bbox_indices\n    ]\n\n    overlapping_blocks.sort(key=lambda x: (x.bounding_box.top, x.bounding_box.x0))\n\n    return [x for x in overlapping_blocks if x.bounding_box != bbox]\n</code></pre>"},{"location":"reference/provenance/search/#docprompt.provenance.search.DocumentProvenanceLocator.refine_query_to_word_level","title":"<code>refine_query_to_word_level(query, page_number, enclosing_block)</code>","text":"<p>Refine a query to the word level</p> Source code in <code>docprompt/provenance/search.py</code> <pre><code>def refine_query_to_word_level(\n    self, query: str, page_number: int, enclosing_block: TextBlock\n):\n    \"\"\"\n    Refine a query to the word level\n    \"\"\"\n    search_tuple = construct_valid_rtree_tuple(enclosing_block.bounding_box)\n\n    word_level_bbox_indices = list(\n        self.geo_index[page_number][\"word\"].intersection(search_tuple)\n    )\n    word_level_blocks_in_original_bbox = [\n        self.block_mapping[page_number].word_level_blocks[idx]\n        for idx in word_level_bbox_indices\n    ]\n\n    refine_result = refine_block_to_word_level(\n        source_block=enclosing_block,\n        intersecting_word_level_blocks=word_level_blocks_in_original_bbox,\n        query=query,\n    )\n\n    return refine_result\n</code></pre>"},{"location":"reference/provenance/search/#docprompt.provenance.search.DocumentProvenanceLocator.search","title":"<code>search(query, page_number=None, *, refine_to_word=True, require_exact_match=True)</code>","text":"<p>Search for a piece of text in the document and return the source of it</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The text to search for</p> required <code>page_number</code> <code>Optional[int]</code> <p>The page number to search on</p> <code>None</code> <code>refine_to_word</code> <code>bool</code> <p>Whether to refine the search to the word level</p> <code>True</code> <code>require_exact_match</code> <code>bool</code> <p>Whether to require null results if <code>refine_to_word</code> is True and no exact match is found</p> <code>True</code> Source code in <code>docprompt/provenance/search.py</code> <pre><code>def search(\n    self,\n    query: str,\n    page_number: Optional[int] = None,\n    *,\n    refine_to_word: bool = True,\n    require_exact_match: bool = True,\n) -&gt; List[ProvenanceSource]:\n    \"\"\"\n    Search for a piece of text in the document and return the source of it\n\n    Args:\n        query: The text to search for\n        page_number: The page number to search on\n        refine_to_word: Whether to refine the search to the word level\n        require_exact_match: Whether to require null results if `refine_to_word` is True and no exact match is found\n    \"\"\"\n    search_query = self._construct_tantivy_query(query, page_number)\n\n    searcher = self.search_index.searcher()\n\n    search_results = searcher.search(search_query, limit=100)\n\n    results = []\n\n    for score, doc_address in search_results.hits:\n        doc = searcher.doc(doc_address)\n\n        result_page_number = doc[\"page_number\"][0]\n        result_block_page_idx = doc[\"block_page_idx\"][0]\n        block_mapping = self.block_mapping[result_page_number]\n\n        source_block: TextBlock = block_mapping.block_level_blocks[\n            result_block_page_idx\n        ]\n\n        source_blocks = [source_block]\n        principal_block = source_block\n\n        if refine_to_word:\n            refine_result = self.refine_query_to_word_level(\n                query=query,\n                page_number=result_page_number,\n                enclosing_block=source_block,\n            )\n\n            if refine_result is not None:\n                principal_block, source_blocks = refine_result\n            elif require_exact_match:\n                continue\n\n        source = ProvenanceSource(\n            document_name=self.document_name,\n            page_number=result_page_number,\n            text_location=PageTextLocation(\n                source_blocks=source_blocks,\n                text=query,\n                score=score,\n                granularity=\"block\",\n                merged_source_block=principal_block,\n            ),\n        )\n        results.append(source)\n\n    results.sort(key=lambda x: x.page_number)\n\n    return results\n</code></pre>"},{"location":"reference/provenance/search/#docprompt.provenance.search.DocumentProvenanceLocator.search_raw","title":"<code>search_raw(raw_query)</code>","text":"<p>Search for a piece of text using a raw query</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p>The text to search for</p> required <code>page_number</code> <p>The page number to search on</p> required Source code in <code>docprompt/provenance/search.py</code> <pre><code>def search_raw(self, raw_query: str) -&gt; List[str]:\n    \"\"\"\n    Search for a piece of text using a raw query\n\n    Args:\n        query: The text to search for\n        page_number: The page number to search on\n    \"\"\"\n    parsed_query = self.search_index.parse_query(raw_query)\n\n    searcher = self.search_index.searcher()\n\n    search_results = searcher.search(parsed_query, limit=100)\n\n    results = []\n\n    for score, doc_address in search_results.hits:\n        doc = searcher.doc(doc_address)\n\n        result_page_number = doc[\"page_number\"][0]\n        result_block_page_idx = doc[\"block_page_idx\"][0]\n        block_mapping = self.block_mapping[result_page_number]\n\n        source_block: TextBlock = block_mapping.block_level_blocks[\n            result_block_page_idx\n        ]\n\n        results.append(source_block.text)\n\n    return results\n</code></pre>"},{"location":"reference/provenance/source/","title":"source","text":""},{"location":"reference/provenance/source/#docprompt.provenance.source.PageTextLocation","title":"<code>PageTextLocation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Specifies the location of a piece of text in a page</p> Source code in <code>docprompt/provenance/source.py</code> <pre><code>class PageTextLocation(BaseModel):\n    \"\"\"\n    Specifies the location of a piece of text in a page\n    \"\"\"\n\n    source_blocks: List[TextBlock] = Field(\n        description=\"The source text blocks\", repr=False\n    )\n    text: str  # Sometimes the source text is less than the textblock's text.\n    score: float\n    granularity: Literal[\"word\", \"line\", \"block\"] = \"block\"\n\n    merged_source_block: Optional[TextBlock] = Field(default=None)\n</code></pre>"},{"location":"reference/provenance/source/#docprompt.provenance.source.ProvenanceSource","title":"<code>ProvenanceSource</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Bundled with some data, specifies exactly where a piece of verbatim text came from in a document.</p> Source code in <code>docprompt/provenance/source.py</code> <pre><code>class ProvenanceSource(BaseModel):\n    \"\"\"\n    Bundled with some data, specifies exactly where a piece of verbatim text came from\n    in a document.\n    \"\"\"\n\n    document_name: str\n    page_number: PositiveInt\n    text_location: Optional[PageTextLocation] = None\n\n    @computed_field  # type: ignore\n    @property\n    def source_block(self) -&gt; Optional[TextBlock]:\n        if self.text_location:\n            if self.text_location.merged_source_block:\n                return self.text_location.merged_source_block\n            if self.text_location.source_blocks:\n                return self.text_location.source_blocks[0]\n\n            return None\n\n    @property\n    def text(self) -&gt; str:\n        if self.text_location:\n            return \"\\n\".join([block.text for block in self.text_location.source_blocks])\n\n        return \"\"\n</code></pre>"},{"location":"reference/provenance/util/","title":"util","text":""},{"location":"reference/provenance/util/#docprompt.provenance.util.insert_generator","title":"<code>insert_generator(bboxes, data=None)</code>","text":"<p>Make an iterator that yields tuples of (id, bbox, data) for insertion into an RTree index which improves performance massively.</p> Source code in <code>docprompt/provenance/util.py</code> <pre><code>def insert_generator(bboxes: List[NormBBox], data: Optional[Iterable[Any]] = None):\n    \"\"\"\n    Make an iterator that yields tuples of (id, bbox, data) for insertion into an RTree index\n    which improves performance massively.\n    \"\"\"\n    data = data or [None] * len(bboxes)\n\n    for idx, (bbox, data_item) in enumerate(zip(bboxes, data)):\n        yield (idx, construct_valid_rtree_tuple(bbox), data_item)\n</code></pre>"},{"location":"reference/provenance/util/#docprompt.provenance.util.preprocess_query_text","title":"<code>preprocess_query_text(text)</code>","text":"<p>Improve matching ability by applying some preprocessing to the query text.</p> Source code in <code>docprompt/provenance/util.py</code> <pre><code>def preprocess_query_text(text: str) -&gt; str:\n    \"\"\"\n    Improve matching ability by applying some preprocessing to the query text.\n    \"\"\"\n    for regex in _prefix_regexs:\n        text = regex.sub(\"\", text)\n\n    text = text.strip()\n\n    text = text.replace('\"', \"\")\n\n    return text\n</code></pre>"},{"location":"reference/provenance/util/#docprompt.provenance.util.refine_block_to_word_level","title":"<code>refine_block_to_word_level(source_block, intersecting_word_level_blocks, query)</code>","text":"<p>Create a new text block by merging the intersecting word level blocks that match the query.</p> Source code in <code>docprompt/provenance/util.py</code> <pre><code>def refine_block_to_word_level(\n    source_block: TextBlock,\n    intersecting_word_level_blocks: List[TextBlock],\n    query: str,\n):\n    \"\"\"\n    Create a new text block by merging the intersecting word level blocks that\n    match the query.\n\n    \"\"\"\n    intersecting_word_level_blocks.sort(\n        key=lambda x: (x.bounding_box.top, x.bounding_box.x0)\n    )\n\n    tokenized_query = word_tokenize(query)\n\n    if len(tokenized_query) == 1:\n        fuzzified = default_process(tokenized_query[0])\n        for word_level_block in intersecting_word_level_blocks:\n            if fuzz.ratio(fuzzified, default_process(word_level_block.text)) &gt; 87.5:\n                return word_level_block, [word_level_block]\n    else:\n        fuzzified_word_level_texts = [\n            default_process(word_level_block.text)\n            for word_level_block in intersecting_word_level_blocks\n        ]\n\n        # Populate the block mapping\n        token_block_mapping = defaultdict(set)\n\n        first_word = tokenized_query[0]\n        last_word = tokenized_query[-1]\n\n        for token in tokenized_query:\n            fuzzified_token = default_process(token)\n            for i, word_level_block in enumerate(intersecting_word_level_blocks):\n                if fuzz.ratio(fuzzified_token, fuzzified_word_level_texts[i]) &gt; 87.5:\n                    token_block_mapping[token].add(i)\n\n        graph = networkx.DiGraph()\n        prev = tokenized_query[0]\n\n        for i in token_block_mapping[prev]:\n            graph.add_node(i)\n\n        for token in tokenized_query[1:]:\n            for prev_block in token_block_mapping[prev]:\n                for block in sorted(token_block_mapping[token]):\n                    if block &gt; prev_block:\n                        weight = (\n                            (block - prev_block) ** 2\n                        )  # Square the distance to penalize large jumps, which encourages reading order\n                        graph.add_edge(prev_block, block, weight=weight)\n\n            prev = token\n\n        # Get every combination of first and last word\n        first_word_blocks = token_block_mapping[first_word]\n        last_word_blocks = token_block_mapping[last_word]\n\n        combinations = sorted(\n            [(x, y) for x in first_word_blocks for y in last_word_blocks if x &lt; y],\n            key=lambda x: abs(x[1] - x[0]),\n        )\n\n        for start, end in combinations:\n            try:\n                path = networkx.shortest_path(graph, start, end, weight=\"weight\")\n            except networkx.NetworkXNoPath:\n                continue\n            except Exception:\n                continue\n\n            matching_blocks = [intersecting_word_level_blocks[i] for i in path]\n\n            merged_bbox = NormBBox.combine(\n                *[word_level_block.bounding_box for word_level_block in matching_blocks]\n            )\n\n            merged_text = \"\"\n\n            for word_level_block in matching_blocks:\n                merged_text += word_level_block.text\n                if not word_level_block.text.endswith(\" \"):\n                    merged_text += \" \"  # Ensure there is a space between words\n\n            return (\n                TextBlock(\n                    text=merged_text,\n                    type=\"block\",\n                    bounding_box=merged_bbox,\n                    metadata=source_block.metadata,\n                ),\n                matching_blocks,\n            )\n</code></pre>"},{"location":"reference/provenance/util/#docprompt.provenance.util.word_tokenize","title":"<code>word_tokenize(text)</code>","text":"<p>Tokenize a string into words.</p> Source code in <code>docprompt/provenance/util.py</code> <pre><code>def word_tokenize(text: str) -&gt; List[str]:\n    \"\"\"\n    Tokenize a string into words.\n    \"\"\"\n    return re.split(r\"\\s+\", text)\n</code></pre>"},{"location":"reference/schema/","title":"Index","text":""},{"location":"reference/schema/#docprompt.schema.document","title":"<code>document</code>","text":""},{"location":"reference/schema/#docprompt.schema.document.PdfDocument","title":"<code>PdfDocument</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a PDF document</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>class PdfDocument(BaseModel):\n    \"\"\"\n    Represents a PDF document\n    \"\"\"\n\n    name: str = Field(description=\"The name of the document\")\n    file_bytes: bytes = Field(description=\"The bytes of the document\", repr=False)\n    file_path: Optional[str] = None\n\n    def __len__(self):\n        return self.num_pages\n\n    def __hash__(self):\n        return hash(self.document_hash)\n\n    @computed_field\n    @cached_property\n    def page_count(self) -&gt; PositiveInt:\n        from docprompt.utils.util import get_page_count\n\n        return get_page_count(self.file_bytes)\n\n    @property\n    def num_pages(self):\n        return self.page_count\n\n    @property\n    def bytes_per_page(self):\n        return len(self.file_bytes) / self.num_pages\n\n    @computed_field\n    @cached_property\n    def document_hash(self) -&gt; str:\n        from docprompt.utils.util import hash_from_bytes\n\n        return hash_from_bytes(self.file_bytes)\n\n    @field_serializer(\"file_bytes\")\n    def serialize_file_bytes(self, v: bytes, _info):\n        compressed = gzip.compress(v)\n\n        return base64.b64encode(compressed).decode(\"utf-8\")\n\n    @field_validator(\"file_bytes\")\n    def validate_file_bytes(cls, v: bytes):\n        if not isinstance(v, bytes):\n            raise ValueError(\"File bytes must be bytes\")\n\n        if len(v) == 0:\n            raise ValueError(\"File bytes must not be empty\")\n\n        if filetype.guess_mime(v) == \"text/plain\":\n            v = base64.b64decode(v, validate=True)\n\n        if filetype.guess_mime(v) == \"application/gzip\":\n            v = gzip.decompress(v)\n\n        if filetype.guess_mime(v) != \"application/pdf\":\n            raise ValueError(\"File bytes must be a PDF\")\n\n        return v\n\n    @classmethod\n    def from_path(cls, file_path: Union[PathLike, str]):\n        file_path = Path(file_path)\n\n        if not file_path.is_file():\n            raise ValueError(f\"File path {file_path} is not a file\")\n\n        file_bytes = file_path.read_bytes()\n\n        return cls(name=file_path.name, file_path=str(file_path), file_bytes=file_bytes)\n\n    @classmethod\n    def from_bytes(cls, file_bytes: bytes, name: Optional[str] = None):\n        if name is None:\n            name = f\"PDF-{datetime.now().isoformat()}.pdf\"\n\n        return cls(name=name, file_bytes=file_bytes)\n\n    def get_bytes(self) -&gt; bytes:\n        return self.file_bytes  # Deprecated\n\n    @property\n    def path(self):\n        return self.file_path\n\n    def get_page_render_size(\n        self, page_number: int, dpi: int = DEFAULT_DPI\n    ) -&gt; Tuple[int, int]:\n        \"\"\"\n        Returns the render size of a page in pixels\n        \"\"\"\n        return get_page_render_size_from_bytes(self.get_bytes(), page_number, dpi=dpi)\n\n    def to_compressed_bytes(self, compression_kwargs: dict = {}) -&gt; bytes:\n        \"\"\"\n        Compresses the document using Ghostscript\n        \"\"\"\n        with self.as_tempfile() as temp_path:\n            return compress_pdf_to_bytes(temp_path, **compression_kwargs)\n\n    def rasterize_page(\n        self,\n        page_number: int,\n        *,\n        dpi: int = DEFAULT_DPI,\n        downscale_size: Optional[Tuple[int, int]] = None,\n        resize_mode: ResizeModes = \"thumbnail\",\n        max_file_size_bytes: Optional[int] = None,\n        resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n        do_convert: bool = False,\n        image_convert_mode: str = \"L\",\n        do_quantize: bool = False,\n        quantize_color_count: int = 8,\n        return_mode: Literal[\"pil\", \"bytes\"] = \"bytes\",\n    ):\n        \"\"\"\n        Rasterizes a page of the document using Pdfium\n        \"\"\"\n        if page_number &lt;= 0 or page_number &gt; self.num_pages:\n            raise ValueError(f\"Page number must be between 0 and {self.num_pages}\")\n\n        post_process_fn = None\n\n        if any(\n            (\n                downscale_size,\n                max_file_size_bytes,\n                resize_aspect_ratios,\n                do_convert,\n                do_quantize,\n            )\n        ):\n            post_process_fn = partial(\n                process_raster_image,\n                resize_width=downscale_size[0] if downscale_size else None,\n                resize_height=downscale_size[1] if downscale_size else None,\n                resize_mode=resize_mode,\n                resize_aspect_ratios=resize_aspect_ratios,\n                do_convert=do_convert,\n                image_convert_mode=image_convert_mode,\n                do_quantize=do_quantize,\n                quantize_color_count=quantize_color_count,\n                max_file_size_bytes=max_file_size_bytes,\n            )\n\n        rastered = rasterize_page_with_pdfium(\n            self.file_bytes,\n            page_number,\n            return_mode=return_mode,\n            post_process_fn=post_process_fn,\n            scale=(1 / 72) * dpi,\n        )\n\n        return rastered\n\n    def rasterize_page_to_data_uri(\n        self,\n        page_number: int,\n        *,\n        dpi: int = DEFAULT_DPI,\n        downscale_size: Optional[Tuple[int, int]] = None,\n        resize_mode: ResizeModes = \"thumbnail\",\n        max_file_size_bytes: Optional[int] = None,\n        resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n        do_convert: bool = False,\n        image_convert_mode: str = \"L\",\n        do_quantize: bool = False,\n        quantize_color_count: int = 8,\n        render_grayscale: bool = False,\n    ) -&gt; str:\n        \"\"\"\n        Rasterizes a page of the document using Pdfium and returns a data URI, which can\n        be embedded into HTML or passed to large language models\n        \"\"\"\n        image_bytes = self.rasterize_page(\n            page_number,\n            dpi=dpi,\n            downscale_size=downscale_size,\n            do_convert=do_convert,\n            image_convert_mode=image_convert_mode,\n            do_quantize=do_quantize,\n            quantize_color_count=quantize_color_count,\n            resize_mode=resize_mode,\n            max_file_size_bytes=max_file_size_bytes,\n            resize_aspect_ratios=resize_aspect_ratios,\n            return_mode=\"bytes\",\n        )\n        return f\"data:image/png;base64,{base64.b64encode(image_bytes).decode('utf-8')}\"\n\n    def rasterize_pdf(\n        self,\n        dpi: int = DEFAULT_DPI,\n        downscale_size: Optional[Tuple[int, int]] = None,\n        resize_mode: ResizeModes = \"thumbnail\",\n        max_file_size_bytes: Optional[int] = None,\n        resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n        do_convert: bool = False,\n        image_convert_mode: str = \"L\",\n        do_quantize: bool = False,\n        quantize_color_count: int = 8,\n        return_mode: Literal[\"pil\", \"bytes\"] = \"bytes\",\n        render_grayscale: bool = False,\n    ) -&gt; Dict[int, bytes]:\n        \"\"\"\n        Rasterizes the entire document using Pdfium\n        \"\"\"\n        result = {}\n\n        post_process_fn = None\n\n        if any(\n            (\n                downscale_size,\n                max_file_size_bytes,\n                resize_aspect_ratios,\n                do_convert,\n                do_quantize,\n            )\n        ):\n            post_process_fn = partial(\n                process_raster_image,\n                resize_width=downscale_size[0] if downscale_size else None,\n                resize_height=downscale_size[1] if downscale_size else None,\n                resize_mode=resize_mode,\n                resize_aspect_ratios=resize_aspect_ratios,\n                do_convert=do_convert,\n                image_convert_mode=image_convert_mode,\n                do_quantize=do_quantize,\n                quantize_color_count=quantize_color_count,\n                max_file_size_bytes=max_file_size_bytes,\n            )\n\n        for idx, rastered in enumerate(\n            rasterize_pdf_with_pdfium(\n                self.file_bytes,\n                scale=(1 / 72) * dpi,\n                grayscale=render_grayscale,\n                return_mode=return_mode,\n                post_process_fn=post_process_fn,\n            )\n        ):\n            result[idx + 1] = rastered\n\n        return result\n\n    def split(self, start: Optional[int] = None, stop: Optional[int] = None):\n        \"\"\"\n        Splits a document into multiple documents\n        \"\"\"\n        if start is None and stop is None:\n            raise ValueError(\"Must specify either start or stop\")\n\n        start = start or 0\n\n        from docprompt.utils.splitter import split_pdf_to_bytes\n\n        split_bytes = split_pdf_to_bytes(\n            self.file_bytes, start_page=start, stop_page=stop\n        )\n\n        return Document.from_bytes(split_bytes, name=self.name)\n\n    def as_tempfile(self, **kwargs):\n        \"\"\"\n        Returns a tempfile of the document\n        \"\"\"\n\n        @contextmanager\n        def tempfile_context() -&gt; Generator[str, None, None]:\n            tempfile_kwargs = {\"mode\": \"wb\", \"delete\": True, \"suffix\": \".pdf\", **kwargs}\n\n            with tempfile.NamedTemporaryFile(**tempfile_kwargs) as f:\n                f.write(self.file_bytes)\n                f.flush()\n                yield f.name\n\n        return tempfile_context()\n\n    def write_to_path(self, path: Union[PathLike, str], **kwargs):\n        \"\"\"\n        Writes the document to a path\n        \"\"\"\n        path = Path(path)\n\n        if path.is_dir():\n            path = path / self.name\n\n        with path.open(\"wb\") as f:\n            f.write(self.file_bytes)\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.document.PdfDocument.as_tempfile","title":"<code>as_tempfile(**kwargs)</code>","text":"<p>Returns a tempfile of the document</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def as_tempfile(self, **kwargs):\n    \"\"\"\n    Returns a tempfile of the document\n    \"\"\"\n\n    @contextmanager\n    def tempfile_context() -&gt; Generator[str, None, None]:\n        tempfile_kwargs = {\"mode\": \"wb\", \"delete\": True, \"suffix\": \".pdf\", **kwargs}\n\n        with tempfile.NamedTemporaryFile(**tempfile_kwargs) as f:\n            f.write(self.file_bytes)\n            f.flush()\n            yield f.name\n\n    return tempfile_context()\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.document.PdfDocument.get_page_render_size","title":"<code>get_page_render_size(page_number, dpi=DEFAULT_DPI)</code>","text":"<p>Returns the render size of a page in pixels</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def get_page_render_size(\n    self, page_number: int, dpi: int = DEFAULT_DPI\n) -&gt; Tuple[int, int]:\n    \"\"\"\n    Returns the render size of a page in pixels\n    \"\"\"\n    return get_page_render_size_from_bytes(self.get_bytes(), page_number, dpi=dpi)\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.document.PdfDocument.rasterize_page","title":"<code>rasterize_page(page_number, *, dpi=DEFAULT_DPI, downscale_size=None, resize_mode='thumbnail', max_file_size_bytes=None, resize_aspect_ratios=None, do_convert=False, image_convert_mode='L', do_quantize=False, quantize_color_count=8, return_mode='bytes')</code>","text":"<p>Rasterizes a page of the document using Pdfium</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def rasterize_page(\n    self,\n    page_number: int,\n    *,\n    dpi: int = DEFAULT_DPI,\n    downscale_size: Optional[Tuple[int, int]] = None,\n    resize_mode: ResizeModes = \"thumbnail\",\n    max_file_size_bytes: Optional[int] = None,\n    resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n    do_convert: bool = False,\n    image_convert_mode: str = \"L\",\n    do_quantize: bool = False,\n    quantize_color_count: int = 8,\n    return_mode: Literal[\"pil\", \"bytes\"] = \"bytes\",\n):\n    \"\"\"\n    Rasterizes a page of the document using Pdfium\n    \"\"\"\n    if page_number &lt;= 0 or page_number &gt; self.num_pages:\n        raise ValueError(f\"Page number must be between 0 and {self.num_pages}\")\n\n    post_process_fn = None\n\n    if any(\n        (\n            downscale_size,\n            max_file_size_bytes,\n            resize_aspect_ratios,\n            do_convert,\n            do_quantize,\n        )\n    ):\n        post_process_fn = partial(\n            process_raster_image,\n            resize_width=downscale_size[0] if downscale_size else None,\n            resize_height=downscale_size[1] if downscale_size else None,\n            resize_mode=resize_mode,\n            resize_aspect_ratios=resize_aspect_ratios,\n            do_convert=do_convert,\n            image_convert_mode=image_convert_mode,\n            do_quantize=do_quantize,\n            quantize_color_count=quantize_color_count,\n            max_file_size_bytes=max_file_size_bytes,\n        )\n\n    rastered = rasterize_page_with_pdfium(\n        self.file_bytes,\n        page_number,\n        return_mode=return_mode,\n        post_process_fn=post_process_fn,\n        scale=(1 / 72) * dpi,\n    )\n\n    return rastered\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.document.PdfDocument.rasterize_page_to_data_uri","title":"<code>rasterize_page_to_data_uri(page_number, *, dpi=DEFAULT_DPI, downscale_size=None, resize_mode='thumbnail', max_file_size_bytes=None, resize_aspect_ratios=None, do_convert=False, image_convert_mode='L', do_quantize=False, quantize_color_count=8, render_grayscale=False)</code>","text":"<p>Rasterizes a page of the document using Pdfium and returns a data URI, which can be embedded into HTML or passed to large language models</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def rasterize_page_to_data_uri(\n    self,\n    page_number: int,\n    *,\n    dpi: int = DEFAULT_DPI,\n    downscale_size: Optional[Tuple[int, int]] = None,\n    resize_mode: ResizeModes = \"thumbnail\",\n    max_file_size_bytes: Optional[int] = None,\n    resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n    do_convert: bool = False,\n    image_convert_mode: str = \"L\",\n    do_quantize: bool = False,\n    quantize_color_count: int = 8,\n    render_grayscale: bool = False,\n) -&gt; str:\n    \"\"\"\n    Rasterizes a page of the document using Pdfium and returns a data URI, which can\n    be embedded into HTML or passed to large language models\n    \"\"\"\n    image_bytes = self.rasterize_page(\n        page_number,\n        dpi=dpi,\n        downscale_size=downscale_size,\n        do_convert=do_convert,\n        image_convert_mode=image_convert_mode,\n        do_quantize=do_quantize,\n        quantize_color_count=quantize_color_count,\n        resize_mode=resize_mode,\n        max_file_size_bytes=max_file_size_bytes,\n        resize_aspect_ratios=resize_aspect_ratios,\n        return_mode=\"bytes\",\n    )\n    return f\"data:image/png;base64,{base64.b64encode(image_bytes).decode('utf-8')}\"\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.document.PdfDocument.rasterize_pdf","title":"<code>rasterize_pdf(dpi=DEFAULT_DPI, downscale_size=None, resize_mode='thumbnail', max_file_size_bytes=None, resize_aspect_ratios=None, do_convert=False, image_convert_mode='L', do_quantize=False, quantize_color_count=8, return_mode='bytes', render_grayscale=False)</code>","text":"<p>Rasterizes the entire document using Pdfium</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def rasterize_pdf(\n    self,\n    dpi: int = DEFAULT_DPI,\n    downscale_size: Optional[Tuple[int, int]] = None,\n    resize_mode: ResizeModes = \"thumbnail\",\n    max_file_size_bytes: Optional[int] = None,\n    resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n    do_convert: bool = False,\n    image_convert_mode: str = \"L\",\n    do_quantize: bool = False,\n    quantize_color_count: int = 8,\n    return_mode: Literal[\"pil\", \"bytes\"] = \"bytes\",\n    render_grayscale: bool = False,\n) -&gt; Dict[int, bytes]:\n    \"\"\"\n    Rasterizes the entire document using Pdfium\n    \"\"\"\n    result = {}\n\n    post_process_fn = None\n\n    if any(\n        (\n            downscale_size,\n            max_file_size_bytes,\n            resize_aspect_ratios,\n            do_convert,\n            do_quantize,\n        )\n    ):\n        post_process_fn = partial(\n            process_raster_image,\n            resize_width=downscale_size[0] if downscale_size else None,\n            resize_height=downscale_size[1] if downscale_size else None,\n            resize_mode=resize_mode,\n            resize_aspect_ratios=resize_aspect_ratios,\n            do_convert=do_convert,\n            image_convert_mode=image_convert_mode,\n            do_quantize=do_quantize,\n            quantize_color_count=quantize_color_count,\n            max_file_size_bytes=max_file_size_bytes,\n        )\n\n    for idx, rastered in enumerate(\n        rasterize_pdf_with_pdfium(\n            self.file_bytes,\n            scale=(1 / 72) * dpi,\n            grayscale=render_grayscale,\n            return_mode=return_mode,\n            post_process_fn=post_process_fn,\n        )\n    ):\n        result[idx + 1] = rastered\n\n    return result\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.document.PdfDocument.split","title":"<code>split(start=None, stop=None)</code>","text":"<p>Splits a document into multiple documents</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def split(self, start: Optional[int] = None, stop: Optional[int] = None):\n    \"\"\"\n    Splits a document into multiple documents\n    \"\"\"\n    if start is None and stop is None:\n        raise ValueError(\"Must specify either start or stop\")\n\n    start = start or 0\n\n    from docprompt.utils.splitter import split_pdf_to_bytes\n\n    split_bytes = split_pdf_to_bytes(\n        self.file_bytes, start_page=start, stop_page=stop\n    )\n\n    return Document.from_bytes(split_bytes, name=self.name)\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.document.PdfDocument.to_compressed_bytes","title":"<code>to_compressed_bytes(compression_kwargs={})</code>","text":"<p>Compresses the document using Ghostscript</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def to_compressed_bytes(self, compression_kwargs: dict = {}) -&gt; bytes:\n    \"\"\"\n    Compresses the document using Ghostscript\n    \"\"\"\n    with self.as_tempfile() as temp_path:\n        return compress_pdf_to_bytes(temp_path, **compression_kwargs)\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.document.PdfDocument.write_to_path","title":"<code>write_to_path(path, **kwargs)</code>","text":"<p>Writes the document to a path</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def write_to_path(self, path: Union[PathLike, str], **kwargs):\n    \"\"\"\n    Writes the document to a path\n    \"\"\"\n    path = Path(path)\n\n    if path.is_dir():\n        path = path / self.name\n\n    with path.open(\"wb\") as f:\n        f.write(self.file_bytes)\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.document.get_page_render_size_from_bytes","title":"<code>get_page_render_size_from_bytes(file_bytes, page_number, dpi=DEFAULT_DPI)</code>","text":"<p>Returns the render size of a page in pixels</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def get_page_render_size_from_bytes(\n    file_bytes: bytes, page_number: int, dpi: int = DEFAULT_DPI\n):\n    \"\"\"\n    Returns the render size of a page in pixels\n    \"\"\"\n\n    with get_pdfium_document(file_bytes) as pdf:\n        page = pdf.get_page(page_number)\n\n        mediabox = page.get_mediabox()\n\n        base_width = int(mediabox[2] - mediabox[0])\n        base_height = int(mediabox[3] - mediabox[1])\n\n        width = int(base_width * dpi / 72)\n        height = int(base_height * dpi / 72)\n\n        return width, height\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.layout","title":"<code>layout</code>","text":""},{"location":"reference/schema/#docprompt.schema.layout.BoundingPoly","title":"<code>BoundingPoly</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a normalized bounding poly with each value in the range [0, 1]</p> <p>Used for higher order shapes like polygons on a page</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>class BoundingPoly(BaseModel):\n    \"\"\"\n    Represents a normalized bounding poly with each value in the range [0, 1]\n\n    Used for higher order shapes like polygons on a page\n    \"\"\"\n\n    normalized_vertices: List[Point]\n\n    def __getitem__(self, index):\n        return self.normalized_vertices[index]\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.layout.NormBBox","title":"<code>NormBBox</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a normalized bounding box with each value in the range [0, 1]</p> <p>Where x1 &gt; x0 and bottom &gt; top</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>class NormBBox(BaseModel):\n    \"\"\"\n    Represents a normalized bounding box with each value in the range [0, 1]\n\n    Where x1 &gt; x0 and bottom &gt; top\n    \"\"\"\n\n    x0: BoundedFloat\n    top: BoundedFloat\n    x1: BoundedFloat\n    bottom: BoundedFloat\n\n    class Config:\n        json_encoders = {float: lambda v: round(v, 5)}  # 1/10,000 increments is plenty\n\n    def as_tuple(self):\n        return (self.x0, self.top, self.x1, self.bottom)\n\n    def __getitem__(self, index):\n        # Lots of if statements to prevent new allocations\n        if index &gt; 3:\n            raise IndexError(\"Index out of range\")\n\n        if index == 0:\n            return self.x0\n        elif index == 1:\n            return self.top\n        elif index == 2:\n            return self.x1\n        elif index == 3:\n            return self.bottom\n\n    def __eq__(self, other):\n        if not isinstance(other, NormBBox):\n            return False\n\n        return self.as_tuple() == other.as_tuple()\n\n    def __hash__(self):\n        return hash(self.as_tuple())\n\n    def __and__(self, other):\n        if not isinstance(other, NormBBox):\n            raise TypeError(\"Can only compute intersection with NormBBox\")\n        # Compute the intersection of two bounding boxes\n        new_x0 = max(self.x0, other.x0)\n        new_top = max(self.top, other.top)\n        new_x1 = min(self.x1, other.x1)\n        new_bottom = min(self.bottom, other.bottom)\n\n        # Check if there is an actual intersection and if the resulting bounding box is valid\n        if new_x0 &lt;= new_x1 and new_top &lt;= new_bottom:\n            return NormBBox(x0=new_x0, top=new_top, x1=new_x1, bottom=new_bottom)\n        else:\n            # Return an empty or non-existent bounding box representation\n            return None\n\n    def __add__(self, other):\n        if not isinstance(other, NormBBox):\n            raise TypeError(\"Can only add NormBBox to NormBBox\")\n\n        return NormBBox(\n            x0=min(self.x0, other.x0),\n            top=min(self.top, other.top),\n            x1=max(self.x1, other.x1),\n            bottom=max(self.bottom, other.bottom),\n        )\n\n    def __contains__(self, other):\n        return (\n            self.x0 &lt;= other.x0\n            and self.top &lt;= other.top\n            and self.x1 &gt;= other.x1\n            and self.bottom &gt;= other.bottom\n        )\n\n    def intersection_over_union(self, other):\n        if not isinstance(other, NormBBox):\n            raise TypeError(\"Can only compute IOU with NormBBox\")\n\n        # Compute the intersection\n        intersection_bbox = self &amp; other\n\n        if intersection_bbox:\n            intersection_area = intersection_bbox.area\n            union_area = self.area + other.area - intersection_area\n            return intersection_area / union_area\n\n        return 0  # No intersection\n\n    def x_overlap(self, other):\n        \"\"\"\n        Get the overlap, between 0 and 1, of the x-axis of two bounding boxes\n        \"\"\"\n        return max(0, min(self.x1, other.x1) - max(self.x0, other.x0))\n\n    def y_overlap(self, other):\n        \"\"\"\n        Get the overlap, between 0 and 1, of the y-axis of two bounding boxes\n        \"\"\"\n        return max(0, min(self.bottom, other.bottom) - max(self.top, other.top))\n\n    @classmethod\n    def combine(cls, *bboxes: \"NormBBox\"):\n        \"\"\"\n        Combines multiple bounding boxes into a single bounding box\n        \"\"\"\n        if len(bboxes) == 0:\n            raise ValueError(\"Must provide at least one bounding box\")\n\n        if len(bboxes) == 1:\n            return bboxes[0]\n\n        working_bbox = bboxes[0]\n        for bbox in bboxes[1:]:\n            working_bbox = working_bbox + bbox\n\n        return working_bbox\n\n    @classmethod\n    def from_bounding_poly(cls, bounding_poly: \"BoundingPoly\"):\n        \"\"\"\n        Returns a NormBBox from a BoundingPoly\n        \"\"\"\n        if len(bounding_poly.normalized_vertices) != 4:\n            raise ValueError(\n                \"BoundingPoly must have 4 vertices for NormBBox conversion\"\n            )\n\n        (\n            top_left,\n            top_right,\n            bottom_right,\n            bottom_left,\n        ) = bounding_poly.normalized_vertices\n\n        return cls(\n            x0=top_left.x,\n            top=top_left.y,\n            x1=bottom_right.x,\n            bottom=bottom_right.y,\n        )\n\n    @property\n    def width(self):\n        return self.x1 - self.x0\n\n    @property\n    def height(self):\n        return self.bottom - self.top\n\n    @property\n    def area(self):\n        return self.width * self.height\n\n    @property\n    def centroid(self):\n        return (self.x0 + self.x1) / 2, (self.top + self.bottom) / 2\n\n    @property\n    def y_center(self):\n        return (self.top + self.bottom) / 2\n\n    @property\n    def x_center(self):\n        return (self.x0 + self.x1) / 2\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.layout.NormBBox.combine","title":"<code>combine(*bboxes)</code>  <code>classmethod</code>","text":"<p>Combines multiple bounding boxes into a single bounding box</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>@classmethod\ndef combine(cls, *bboxes: \"NormBBox\"):\n    \"\"\"\n    Combines multiple bounding boxes into a single bounding box\n    \"\"\"\n    if len(bboxes) == 0:\n        raise ValueError(\"Must provide at least one bounding box\")\n\n    if len(bboxes) == 1:\n        return bboxes[0]\n\n    working_bbox = bboxes[0]\n    for bbox in bboxes[1:]:\n        working_bbox = working_bbox + bbox\n\n    return working_bbox\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.layout.NormBBox.from_bounding_poly","title":"<code>from_bounding_poly(bounding_poly)</code>  <code>classmethod</code>","text":"<p>Returns a NormBBox from a BoundingPoly</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>@classmethod\ndef from_bounding_poly(cls, bounding_poly: \"BoundingPoly\"):\n    \"\"\"\n    Returns a NormBBox from a BoundingPoly\n    \"\"\"\n    if len(bounding_poly.normalized_vertices) != 4:\n        raise ValueError(\n            \"BoundingPoly must have 4 vertices for NormBBox conversion\"\n        )\n\n    (\n        top_left,\n        top_right,\n        bottom_right,\n        bottom_left,\n    ) = bounding_poly.normalized_vertices\n\n    return cls(\n        x0=top_left.x,\n        top=top_left.y,\n        x1=bottom_right.x,\n        bottom=bottom_right.y,\n    )\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.layout.NormBBox.x_overlap","title":"<code>x_overlap(other)</code>","text":"<p>Get the overlap, between 0 and 1, of the x-axis of two bounding boxes</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>def x_overlap(self, other):\n    \"\"\"\n    Get the overlap, between 0 and 1, of the x-axis of two bounding boxes\n    \"\"\"\n    return max(0, min(self.x1, other.x1) - max(self.x0, other.x0))\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.layout.NormBBox.y_overlap","title":"<code>y_overlap(other)</code>","text":"<p>Get the overlap, between 0 and 1, of the y-axis of two bounding boxes</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>def y_overlap(self, other):\n    \"\"\"\n    Get the overlap, between 0 and 1, of the y-axis of two bounding boxes\n    \"\"\"\n    return max(0, min(self.bottom, other.bottom) - max(self.top, other.top))\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.layout.Point","title":"<code>Point</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a normalized bounding box with each value in the range [0, 1]</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>class Point(BaseModel):\n    \"\"\"\n    Represents a normalized bounding box with each value in the range [0, 1]\n    \"\"\"\n\n    class Config:\n        json_encoders = {float: lambda v: round(v, 5)}  # 1/10,000 increments is plenty\n\n    x: BoundedFloat\n    y: BoundedFloat\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.layout.TextBlock","title":"<code>TextBlock</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a single block of text, with its bounding box. The bounding box is a tuple of (x0, top, x1, bottom) and is normalized to the page size.</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>class TextBlock(BaseModel):\n    \"\"\"\n    Represents a single block of text, with its bounding box.\n    The bounding box is a tuple of (x0, top, x1, bottom) and\n    is normalized to the page size.\n    \"\"\"\n\n    class Config:\n        json_encoders = {float: lambda v: round(v, 5)}  # 1/10,000 increments is plenty\n\n    text: str\n    type: SegmentLevels\n    source: TextblockSource = Field(\n        default=\"derived\", description=\"The source of the text block\"\n    )\n\n    # Layout information\n    bounding_box: NormBBox = Field(default=None, repr=False)\n    bounding_poly: Optional[BoundingPoly] = Field(default=None, repr=False)\n    text_spans: Optional[List[TextSpan]] = Field(default=None, repr=False)\n\n    metadata: Optional[TextBlockMetadata] = Field(default_factory=TextBlockMetadata)\n\n    def __getitem__(self, index):\n        return getattr(self, index)\n\n    def __hash__(self):\n        return hash((self.text, self.bounding_box.as_tuple()))\n\n    @property\n    def confidence(self):\n        return self.metadata.confidence\n\n    @property\n    def direction(self):\n        return self.metadata.direction\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.pipeline","title":"<code>pipeline</code>","text":""},{"location":"reference/schema/#docprompt.schema.pipeline.DocumentCollection","title":"<code>DocumentCollection</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[DocumentCollectionMetadata, DocumentNodeMetadata, PageNodeMetadata]</code></p> <p>Represents a collection of documents with some common metadata</p> Source code in <code>docprompt/schema/pipeline.py</code> <pre><code>class DocumentCollection(\n    BaseModel,\n    Generic[DocumentCollectionMetadata, DocumentNodeMetadata, PageNodeMetadata],\n):\n    \"\"\"\n    Represents a collection of documents with some common metadata\n    \"\"\"\n\n    document_nodes: List[DocumentNode[DocumentNodeMetadata, PageNodeMetadata]]\n    metadata: DocumentCollectionMetadata\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.pipeline.DocumentNode","title":"<code>DocumentNode</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[DocumentNodeMetadata, PageNodeMetadata]</code></p> <p>Represents a single document, with some metadata</p> Source code in <code>docprompt/schema/pipeline.py</code> <pre><code>class DocumentNode(BaseModel, Generic[DocumentNodeMetadata, PageNodeMetadata]):\n    \"\"\"\n    Represents a single document, with some metadata\n    \"\"\"\n\n    document: Document\n    page_nodes: List[PageNode[PageNodeMetadata]] = Field(\n        description=\"The pages in the document\", default_factory=list, repr=False\n    )\n    metadata: Optional[DocumentNodeMetadata] = Field(\n        description=\"Application-specific metadata for the document\", default=None\n    )\n\n    _locator: Optional[\"DocumentProvenanceLocator\"] = PrivateAttr(default=None)\n\n    def __getstate__(self):\n        state = super().__getstate__()\n\n        state[\"__pydantic_private__\"][\"_locator\"] = None\n\n        return state\n\n    def __len__(self):\n        return len(self.page_nodes)\n\n    def __getitem__(self, index):\n        return self.page_nodes[index]\n\n    def __iter__(self):\n        return iter(self.page_nodes)\n\n    @property\n    def rasterizer(self):\n        return DocumentRasterizer(self)\n\n    @property\n    def locator(self):\n        if self._locator is None:\n            self.refresh_locator()\n\n        return self._locator\n\n    def refresh_locator(self):\n        \"\"\"\n        Refreshes the locator for this document node\n        \"\"\"\n        from docprompt.provenance.search import DocumentProvenanceLocator\n\n        if any(not page.ocr_results.result for page in self.page_nodes):\n            raise ValueError(\n                \"Cannot create a locator for a document node with missing OCR results\"\n            )\n\n        self._locator = DocumentProvenanceLocator.from_document_node(self)\n\n        return self.locator\n\n    @classmethod\n    def from_document(\n        cls,\n        document: Document,\n        document_metadata: Optional[DocumentNodeMetadata] = None,\n    ):\n        document_node: \"DocumentNode[DocumentNodeMetadata, PageNodeMetadata]\" = (\n            DocumentNode(document=document, metadata=document_metadata)\n        )\n\n        for page_number in range(1, len(document) + 1):\n            document_node.page_nodes.append(\n                PageNode(document=document_node, page_number=page_number)\n            )\n\n        return document_node\n\n    @property\n    def file_hash(self):\n        return self.document.document_hash\n\n    @property\n    def document_name(self):\n        return self.document.name\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.pipeline.DocumentNode.refresh_locator","title":"<code>refresh_locator()</code>","text":"<p>Refreshes the locator for this document node</p> Source code in <code>docprompt/schema/pipeline.py</code> <pre><code>def refresh_locator(self):\n    \"\"\"\n    Refreshes the locator for this document node\n    \"\"\"\n    from docprompt.provenance.search import DocumentProvenanceLocator\n\n    if any(not page.ocr_results.result for page in self.page_nodes):\n        raise ValueError(\n            \"Cannot create a locator for a document node with missing OCR results\"\n        )\n\n    self._locator = DocumentProvenanceLocator.from_document_node(self)\n\n    return self.locator\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.pipeline.DocumentRasterizer","title":"<code>DocumentRasterizer</code>","text":"Source code in <code>docprompt/schema/pipeline.py</code> <pre><code>class DocumentRasterizer:\n    def __init__(self, owner: \"DocumentNode\"):\n        self.owner = owner\n\n    def rasterize(\n        self,\n        name: str,\n        *,\n        return_mode: Literal[\"bytes\", \"pil\"] = \"bytes\",\n        dpi: int = 100,\n        downscale_size: Optional[Tuple[int, int]] = None,\n        resize_mode: ResizeModes = \"thumbnail\",\n        resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n        do_convert: bool = False,\n        image_convert_mode: str = \"L\",\n        do_quantize: bool = False,\n        quantize_color_count: int = 8,\n        max_file_size_bytes: Optional[int] = None,\n        render_grayscale: bool = False,\n    ) -&gt; List[Union[bytes, Image.Image]]:\n        images = self.owner.document.rasterize_pdf(\n            dpi=dpi,\n            downscale_size=downscale_size,\n            resize_mode=resize_mode,\n            resize_aspect_ratios=resize_aspect_ratios,\n            do_convert=do_convert,\n            image_convert_mode=image_convert_mode,\n            do_quantize=do_quantize,\n            quantize_color_count=quantize_color_count,\n            max_file_size_bytes=max_file_size_bytes,\n            render_grayscale=render_grayscale,\n            return_mode=return_mode,\n        )\n\n        for page_number, image in images.items():\n            page_node = self.owner.page_nodes[page_number - 1]\n\n            page_node._raster_cache[name] = image\n\n        return list(images.values())\n\n    def propagate_cache(self, name: str, rasters: Dict[int, Union[bytes, Image.Image]]):\n        \"\"\"\n        Should be one-indexed\n        \"\"\"\n        for page_number, raster in rasters.items():\n            page_node = self.owner.page_nodes[page_number - 1]\n\n            page_node._raster_cache[name] = raster\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.pipeline.DocumentRasterizer.propagate_cache","title":"<code>propagate_cache(name, rasters)</code>","text":"<p>Should be one-indexed</p> Source code in <code>docprompt/schema/pipeline.py</code> <pre><code>def propagate_cache(self, name: str, rasters: Dict[int, Union[bytes, Image.Image]]):\n    \"\"\"\n    Should be one-indexed\n    \"\"\"\n    for page_number, raster in rasters.items():\n        page_node = self.owner.page_nodes[page_number - 1]\n\n        page_node._raster_cache[name] = raster\n</code></pre>"},{"location":"reference/schema/#docprompt.schema.pipeline.PageNode","title":"<code>PageNode</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[PageNodeMetadata]</code></p> <p>Represents a single page in a document, with some metadata</p> Source code in <code>docprompt/schema/pipeline.py</code> <pre><code>class PageNode(BaseModel, Generic[PageNodeMetadata]):\n    \"\"\"\n    Represents a single page in a document, with some metadata\n    \"\"\"\n\n    document: \"DocumentNode\" = Field(exclude=True, repr=False)\n    page_number: PositiveInt = Field(description=\"The page number\")\n    metadata: Optional[PageNodeMetadata] = Field(\n        description=\"Application-specific metadata for the page\", default=None\n    )\n    extra: Dict[str, Any] = Field(\n        description=\"Extra data that can be stored on the page node\",\n        default_factory=dict,\n    )\n\n    ocr_results: ResultContainer[OcrPageResult] = Field(\n        default_factory=lambda: ResultContainer(),\n        description=\"The OCR results for the page\",\n        repr=False,\n    )\n\n    _raster_cache: Dict[str, bytes] = PrivateAttr(default_factory=dict)\n\n    def __getstate__(self):\n        state = super().__getstate__()\n\n        state[\"__pydantic_private__\"][\"_raster_cache\"] = {}\n\n        return state\n\n    @property\n    def rasterizer(self):\n        return PageRasterizer(self._raster_cache, self)\n\n    def search(\n        self, query: str, refine_to_words: bool = True, require_exact_match: bool = True\n    ):\n        return self.document.locator.search(\n            query,\n            page_number=self.page_number,\n            refine_to_word=refine_to_words,\n            require_exact_match=require_exact_match,\n        )\n</code></pre>"},{"location":"reference/schema/document/","title":"document","text":""},{"location":"reference/schema/document/#docprompt.schema.document.PdfDocument","title":"<code>PdfDocument</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a PDF document</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>class PdfDocument(BaseModel):\n    \"\"\"\n    Represents a PDF document\n    \"\"\"\n\n    name: str = Field(description=\"The name of the document\")\n    file_bytes: bytes = Field(description=\"The bytes of the document\", repr=False)\n    file_path: Optional[str] = None\n\n    def __len__(self):\n        return self.num_pages\n\n    def __hash__(self):\n        return hash(self.document_hash)\n\n    @computed_field\n    @cached_property\n    def page_count(self) -&gt; PositiveInt:\n        from docprompt.utils.util import get_page_count\n\n        return get_page_count(self.file_bytes)\n\n    @property\n    def num_pages(self):\n        return self.page_count\n\n    @property\n    def bytes_per_page(self):\n        return len(self.file_bytes) / self.num_pages\n\n    @computed_field\n    @cached_property\n    def document_hash(self) -&gt; str:\n        from docprompt.utils.util import hash_from_bytes\n\n        return hash_from_bytes(self.file_bytes)\n\n    @field_serializer(\"file_bytes\")\n    def serialize_file_bytes(self, v: bytes, _info):\n        compressed = gzip.compress(v)\n\n        return base64.b64encode(compressed).decode(\"utf-8\")\n\n    @field_validator(\"file_bytes\")\n    def validate_file_bytes(cls, v: bytes):\n        if not isinstance(v, bytes):\n            raise ValueError(\"File bytes must be bytes\")\n\n        if len(v) == 0:\n            raise ValueError(\"File bytes must not be empty\")\n\n        if filetype.guess_mime(v) == \"text/plain\":\n            v = base64.b64decode(v, validate=True)\n\n        if filetype.guess_mime(v) == \"application/gzip\":\n            v = gzip.decompress(v)\n\n        if filetype.guess_mime(v) != \"application/pdf\":\n            raise ValueError(\"File bytes must be a PDF\")\n\n        return v\n\n    @classmethod\n    def from_path(cls, file_path: Union[PathLike, str]):\n        file_path = Path(file_path)\n\n        if not file_path.is_file():\n            raise ValueError(f\"File path {file_path} is not a file\")\n\n        file_bytes = file_path.read_bytes()\n\n        return cls(name=file_path.name, file_path=str(file_path), file_bytes=file_bytes)\n\n    @classmethod\n    def from_bytes(cls, file_bytes: bytes, name: Optional[str] = None):\n        if name is None:\n            name = f\"PDF-{datetime.now().isoformat()}.pdf\"\n\n        return cls(name=name, file_bytes=file_bytes)\n\n    def get_bytes(self) -&gt; bytes:\n        return self.file_bytes  # Deprecated\n\n    @property\n    def path(self):\n        return self.file_path\n\n    def get_page_render_size(\n        self, page_number: int, dpi: int = DEFAULT_DPI\n    ) -&gt; Tuple[int, int]:\n        \"\"\"\n        Returns the render size of a page in pixels\n        \"\"\"\n        return get_page_render_size_from_bytes(self.get_bytes(), page_number, dpi=dpi)\n\n    def to_compressed_bytes(self, compression_kwargs: dict = {}) -&gt; bytes:\n        \"\"\"\n        Compresses the document using Ghostscript\n        \"\"\"\n        with self.as_tempfile() as temp_path:\n            return compress_pdf_to_bytes(temp_path, **compression_kwargs)\n\n    def rasterize_page(\n        self,\n        page_number: int,\n        *,\n        dpi: int = DEFAULT_DPI,\n        downscale_size: Optional[Tuple[int, int]] = None,\n        resize_mode: ResizeModes = \"thumbnail\",\n        max_file_size_bytes: Optional[int] = None,\n        resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n        do_convert: bool = False,\n        image_convert_mode: str = \"L\",\n        do_quantize: bool = False,\n        quantize_color_count: int = 8,\n        return_mode: Literal[\"pil\", \"bytes\"] = \"bytes\",\n    ):\n        \"\"\"\n        Rasterizes a page of the document using Pdfium\n        \"\"\"\n        if page_number &lt;= 0 or page_number &gt; self.num_pages:\n            raise ValueError(f\"Page number must be between 0 and {self.num_pages}\")\n\n        post_process_fn = None\n\n        if any(\n            (\n                downscale_size,\n                max_file_size_bytes,\n                resize_aspect_ratios,\n                do_convert,\n                do_quantize,\n            )\n        ):\n            post_process_fn = partial(\n                process_raster_image,\n                resize_width=downscale_size[0] if downscale_size else None,\n                resize_height=downscale_size[1] if downscale_size else None,\n                resize_mode=resize_mode,\n                resize_aspect_ratios=resize_aspect_ratios,\n                do_convert=do_convert,\n                image_convert_mode=image_convert_mode,\n                do_quantize=do_quantize,\n                quantize_color_count=quantize_color_count,\n                max_file_size_bytes=max_file_size_bytes,\n            )\n\n        rastered = rasterize_page_with_pdfium(\n            self.file_bytes,\n            page_number,\n            return_mode=return_mode,\n            post_process_fn=post_process_fn,\n            scale=(1 / 72) * dpi,\n        )\n\n        return rastered\n\n    def rasterize_page_to_data_uri(\n        self,\n        page_number: int,\n        *,\n        dpi: int = DEFAULT_DPI,\n        downscale_size: Optional[Tuple[int, int]] = None,\n        resize_mode: ResizeModes = \"thumbnail\",\n        max_file_size_bytes: Optional[int] = None,\n        resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n        do_convert: bool = False,\n        image_convert_mode: str = \"L\",\n        do_quantize: bool = False,\n        quantize_color_count: int = 8,\n        render_grayscale: bool = False,\n    ) -&gt; str:\n        \"\"\"\n        Rasterizes a page of the document using Pdfium and returns a data URI, which can\n        be embedded into HTML or passed to large language models\n        \"\"\"\n        image_bytes = self.rasterize_page(\n            page_number,\n            dpi=dpi,\n            downscale_size=downscale_size,\n            do_convert=do_convert,\n            image_convert_mode=image_convert_mode,\n            do_quantize=do_quantize,\n            quantize_color_count=quantize_color_count,\n            resize_mode=resize_mode,\n            max_file_size_bytes=max_file_size_bytes,\n            resize_aspect_ratios=resize_aspect_ratios,\n            return_mode=\"bytes\",\n        )\n        return f\"data:image/png;base64,{base64.b64encode(image_bytes).decode('utf-8')}\"\n\n    def rasterize_pdf(\n        self,\n        dpi: int = DEFAULT_DPI,\n        downscale_size: Optional[Tuple[int, int]] = None,\n        resize_mode: ResizeModes = \"thumbnail\",\n        max_file_size_bytes: Optional[int] = None,\n        resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n        do_convert: bool = False,\n        image_convert_mode: str = \"L\",\n        do_quantize: bool = False,\n        quantize_color_count: int = 8,\n        return_mode: Literal[\"pil\", \"bytes\"] = \"bytes\",\n        render_grayscale: bool = False,\n    ) -&gt; Dict[int, bytes]:\n        \"\"\"\n        Rasterizes the entire document using Pdfium\n        \"\"\"\n        result = {}\n\n        post_process_fn = None\n\n        if any(\n            (\n                downscale_size,\n                max_file_size_bytes,\n                resize_aspect_ratios,\n                do_convert,\n                do_quantize,\n            )\n        ):\n            post_process_fn = partial(\n                process_raster_image,\n                resize_width=downscale_size[0] if downscale_size else None,\n                resize_height=downscale_size[1] if downscale_size else None,\n                resize_mode=resize_mode,\n                resize_aspect_ratios=resize_aspect_ratios,\n                do_convert=do_convert,\n                image_convert_mode=image_convert_mode,\n                do_quantize=do_quantize,\n                quantize_color_count=quantize_color_count,\n                max_file_size_bytes=max_file_size_bytes,\n            )\n\n        for idx, rastered in enumerate(\n            rasterize_pdf_with_pdfium(\n                self.file_bytes,\n                scale=(1 / 72) * dpi,\n                grayscale=render_grayscale,\n                return_mode=return_mode,\n                post_process_fn=post_process_fn,\n            )\n        ):\n            result[idx + 1] = rastered\n\n        return result\n\n    def split(self, start: Optional[int] = None, stop: Optional[int] = None):\n        \"\"\"\n        Splits a document into multiple documents\n        \"\"\"\n        if start is None and stop is None:\n            raise ValueError(\"Must specify either start or stop\")\n\n        start = start or 0\n\n        from docprompt.utils.splitter import split_pdf_to_bytes\n\n        split_bytes = split_pdf_to_bytes(\n            self.file_bytes, start_page=start, stop_page=stop\n        )\n\n        return Document.from_bytes(split_bytes, name=self.name)\n\n    def as_tempfile(self, **kwargs):\n        \"\"\"\n        Returns a tempfile of the document\n        \"\"\"\n\n        @contextmanager\n        def tempfile_context() -&gt; Generator[str, None, None]:\n            tempfile_kwargs = {\"mode\": \"wb\", \"delete\": True, \"suffix\": \".pdf\", **kwargs}\n\n            with tempfile.NamedTemporaryFile(**tempfile_kwargs) as f:\n                f.write(self.file_bytes)\n                f.flush()\n                yield f.name\n\n        return tempfile_context()\n\n    def write_to_path(self, path: Union[PathLike, str], **kwargs):\n        \"\"\"\n        Writes the document to a path\n        \"\"\"\n        path = Path(path)\n\n        if path.is_dir():\n            path = path / self.name\n\n        with path.open(\"wb\") as f:\n            f.write(self.file_bytes)\n</code></pre>"},{"location":"reference/schema/document/#docprompt.schema.document.PdfDocument.as_tempfile","title":"<code>as_tempfile(**kwargs)</code>","text":"<p>Returns a tempfile of the document</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def as_tempfile(self, **kwargs):\n    \"\"\"\n    Returns a tempfile of the document\n    \"\"\"\n\n    @contextmanager\n    def tempfile_context() -&gt; Generator[str, None, None]:\n        tempfile_kwargs = {\"mode\": \"wb\", \"delete\": True, \"suffix\": \".pdf\", **kwargs}\n\n        with tempfile.NamedTemporaryFile(**tempfile_kwargs) as f:\n            f.write(self.file_bytes)\n            f.flush()\n            yield f.name\n\n    return tempfile_context()\n</code></pre>"},{"location":"reference/schema/document/#docprompt.schema.document.PdfDocument.get_page_render_size","title":"<code>get_page_render_size(page_number, dpi=DEFAULT_DPI)</code>","text":"<p>Returns the render size of a page in pixels</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def get_page_render_size(\n    self, page_number: int, dpi: int = DEFAULT_DPI\n) -&gt; Tuple[int, int]:\n    \"\"\"\n    Returns the render size of a page in pixels\n    \"\"\"\n    return get_page_render_size_from_bytes(self.get_bytes(), page_number, dpi=dpi)\n</code></pre>"},{"location":"reference/schema/document/#docprompt.schema.document.PdfDocument.rasterize_page","title":"<code>rasterize_page(page_number, *, dpi=DEFAULT_DPI, downscale_size=None, resize_mode='thumbnail', max_file_size_bytes=None, resize_aspect_ratios=None, do_convert=False, image_convert_mode='L', do_quantize=False, quantize_color_count=8, return_mode='bytes')</code>","text":"<p>Rasterizes a page of the document using Pdfium</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def rasterize_page(\n    self,\n    page_number: int,\n    *,\n    dpi: int = DEFAULT_DPI,\n    downscale_size: Optional[Tuple[int, int]] = None,\n    resize_mode: ResizeModes = \"thumbnail\",\n    max_file_size_bytes: Optional[int] = None,\n    resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n    do_convert: bool = False,\n    image_convert_mode: str = \"L\",\n    do_quantize: bool = False,\n    quantize_color_count: int = 8,\n    return_mode: Literal[\"pil\", \"bytes\"] = \"bytes\",\n):\n    \"\"\"\n    Rasterizes a page of the document using Pdfium\n    \"\"\"\n    if page_number &lt;= 0 or page_number &gt; self.num_pages:\n        raise ValueError(f\"Page number must be between 0 and {self.num_pages}\")\n\n    post_process_fn = None\n\n    if any(\n        (\n            downscale_size,\n            max_file_size_bytes,\n            resize_aspect_ratios,\n            do_convert,\n            do_quantize,\n        )\n    ):\n        post_process_fn = partial(\n            process_raster_image,\n            resize_width=downscale_size[0] if downscale_size else None,\n            resize_height=downscale_size[1] if downscale_size else None,\n            resize_mode=resize_mode,\n            resize_aspect_ratios=resize_aspect_ratios,\n            do_convert=do_convert,\n            image_convert_mode=image_convert_mode,\n            do_quantize=do_quantize,\n            quantize_color_count=quantize_color_count,\n            max_file_size_bytes=max_file_size_bytes,\n        )\n\n    rastered = rasterize_page_with_pdfium(\n        self.file_bytes,\n        page_number,\n        return_mode=return_mode,\n        post_process_fn=post_process_fn,\n        scale=(1 / 72) * dpi,\n    )\n\n    return rastered\n</code></pre>"},{"location":"reference/schema/document/#docprompt.schema.document.PdfDocument.rasterize_page_to_data_uri","title":"<code>rasterize_page_to_data_uri(page_number, *, dpi=DEFAULT_DPI, downscale_size=None, resize_mode='thumbnail', max_file_size_bytes=None, resize_aspect_ratios=None, do_convert=False, image_convert_mode='L', do_quantize=False, quantize_color_count=8, render_grayscale=False)</code>","text":"<p>Rasterizes a page of the document using Pdfium and returns a data URI, which can be embedded into HTML or passed to large language models</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def rasterize_page_to_data_uri(\n    self,\n    page_number: int,\n    *,\n    dpi: int = DEFAULT_DPI,\n    downscale_size: Optional[Tuple[int, int]] = None,\n    resize_mode: ResizeModes = \"thumbnail\",\n    max_file_size_bytes: Optional[int] = None,\n    resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n    do_convert: bool = False,\n    image_convert_mode: str = \"L\",\n    do_quantize: bool = False,\n    quantize_color_count: int = 8,\n    render_grayscale: bool = False,\n) -&gt; str:\n    \"\"\"\n    Rasterizes a page of the document using Pdfium and returns a data URI, which can\n    be embedded into HTML or passed to large language models\n    \"\"\"\n    image_bytes = self.rasterize_page(\n        page_number,\n        dpi=dpi,\n        downscale_size=downscale_size,\n        do_convert=do_convert,\n        image_convert_mode=image_convert_mode,\n        do_quantize=do_quantize,\n        quantize_color_count=quantize_color_count,\n        resize_mode=resize_mode,\n        max_file_size_bytes=max_file_size_bytes,\n        resize_aspect_ratios=resize_aspect_ratios,\n        return_mode=\"bytes\",\n    )\n    return f\"data:image/png;base64,{base64.b64encode(image_bytes).decode('utf-8')}\"\n</code></pre>"},{"location":"reference/schema/document/#docprompt.schema.document.PdfDocument.rasterize_pdf","title":"<code>rasterize_pdf(dpi=DEFAULT_DPI, downscale_size=None, resize_mode='thumbnail', max_file_size_bytes=None, resize_aspect_ratios=None, do_convert=False, image_convert_mode='L', do_quantize=False, quantize_color_count=8, return_mode='bytes', render_grayscale=False)</code>","text":"<p>Rasterizes the entire document using Pdfium</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def rasterize_pdf(\n    self,\n    dpi: int = DEFAULT_DPI,\n    downscale_size: Optional[Tuple[int, int]] = None,\n    resize_mode: ResizeModes = \"thumbnail\",\n    max_file_size_bytes: Optional[int] = None,\n    resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n    do_convert: bool = False,\n    image_convert_mode: str = \"L\",\n    do_quantize: bool = False,\n    quantize_color_count: int = 8,\n    return_mode: Literal[\"pil\", \"bytes\"] = \"bytes\",\n    render_grayscale: bool = False,\n) -&gt; Dict[int, bytes]:\n    \"\"\"\n    Rasterizes the entire document using Pdfium\n    \"\"\"\n    result = {}\n\n    post_process_fn = None\n\n    if any(\n        (\n            downscale_size,\n            max_file_size_bytes,\n            resize_aspect_ratios,\n            do_convert,\n            do_quantize,\n        )\n    ):\n        post_process_fn = partial(\n            process_raster_image,\n            resize_width=downscale_size[0] if downscale_size else None,\n            resize_height=downscale_size[1] if downscale_size else None,\n            resize_mode=resize_mode,\n            resize_aspect_ratios=resize_aspect_ratios,\n            do_convert=do_convert,\n            image_convert_mode=image_convert_mode,\n            do_quantize=do_quantize,\n            quantize_color_count=quantize_color_count,\n            max_file_size_bytes=max_file_size_bytes,\n        )\n\n    for idx, rastered in enumerate(\n        rasterize_pdf_with_pdfium(\n            self.file_bytes,\n            scale=(1 / 72) * dpi,\n            grayscale=render_grayscale,\n            return_mode=return_mode,\n            post_process_fn=post_process_fn,\n        )\n    ):\n        result[idx + 1] = rastered\n\n    return result\n</code></pre>"},{"location":"reference/schema/document/#docprompt.schema.document.PdfDocument.split","title":"<code>split(start=None, stop=None)</code>","text":"<p>Splits a document into multiple documents</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def split(self, start: Optional[int] = None, stop: Optional[int] = None):\n    \"\"\"\n    Splits a document into multiple documents\n    \"\"\"\n    if start is None and stop is None:\n        raise ValueError(\"Must specify either start or stop\")\n\n    start = start or 0\n\n    from docprompt.utils.splitter import split_pdf_to_bytes\n\n    split_bytes = split_pdf_to_bytes(\n        self.file_bytes, start_page=start, stop_page=stop\n    )\n\n    return Document.from_bytes(split_bytes, name=self.name)\n</code></pre>"},{"location":"reference/schema/document/#docprompt.schema.document.PdfDocument.to_compressed_bytes","title":"<code>to_compressed_bytes(compression_kwargs={})</code>","text":"<p>Compresses the document using Ghostscript</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def to_compressed_bytes(self, compression_kwargs: dict = {}) -&gt; bytes:\n    \"\"\"\n    Compresses the document using Ghostscript\n    \"\"\"\n    with self.as_tempfile() as temp_path:\n        return compress_pdf_to_bytes(temp_path, **compression_kwargs)\n</code></pre>"},{"location":"reference/schema/document/#docprompt.schema.document.PdfDocument.write_to_path","title":"<code>write_to_path(path, **kwargs)</code>","text":"<p>Writes the document to a path</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def write_to_path(self, path: Union[PathLike, str], **kwargs):\n    \"\"\"\n    Writes the document to a path\n    \"\"\"\n    path = Path(path)\n\n    if path.is_dir():\n        path = path / self.name\n\n    with path.open(\"wb\") as f:\n        f.write(self.file_bytes)\n</code></pre>"},{"location":"reference/schema/document/#docprompt.schema.document.get_page_render_size_from_bytes","title":"<code>get_page_render_size_from_bytes(file_bytes, page_number, dpi=DEFAULT_DPI)</code>","text":"<p>Returns the render size of a page in pixels</p> Source code in <code>docprompt/schema/document.py</code> <pre><code>def get_page_render_size_from_bytes(\n    file_bytes: bytes, page_number: int, dpi: int = DEFAULT_DPI\n):\n    \"\"\"\n    Returns the render size of a page in pixels\n    \"\"\"\n\n    with get_pdfium_document(file_bytes) as pdf:\n        page = pdf.get_page(page_number)\n\n        mediabox = page.get_mediabox()\n\n        base_width = int(mediabox[2] - mediabox[0])\n        base_height = int(mediabox[3] - mediabox[1])\n\n        width = int(base_width * dpi / 72)\n        height = int(base_height * dpi / 72)\n\n        return width, height\n</code></pre>"},{"location":"reference/schema/layout/","title":"layout","text":""},{"location":"reference/schema/layout/#docprompt.schema.layout.BoundingPoly","title":"<code>BoundingPoly</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a normalized bounding poly with each value in the range [0, 1]</p> <p>Used for higher order shapes like polygons on a page</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>class BoundingPoly(BaseModel):\n    \"\"\"\n    Represents a normalized bounding poly with each value in the range [0, 1]\n\n    Used for higher order shapes like polygons on a page\n    \"\"\"\n\n    normalized_vertices: List[Point]\n\n    def __getitem__(self, index):\n        return self.normalized_vertices[index]\n</code></pre>"},{"location":"reference/schema/layout/#docprompt.schema.layout.NormBBox","title":"<code>NormBBox</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a normalized bounding box with each value in the range [0, 1]</p> <p>Where x1 &gt; x0 and bottom &gt; top</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>class NormBBox(BaseModel):\n    \"\"\"\n    Represents a normalized bounding box with each value in the range [0, 1]\n\n    Where x1 &gt; x0 and bottom &gt; top\n    \"\"\"\n\n    x0: BoundedFloat\n    top: BoundedFloat\n    x1: BoundedFloat\n    bottom: BoundedFloat\n\n    class Config:\n        json_encoders = {float: lambda v: round(v, 5)}  # 1/10,000 increments is plenty\n\n    def as_tuple(self):\n        return (self.x0, self.top, self.x1, self.bottom)\n\n    def __getitem__(self, index):\n        # Lots of if statements to prevent new allocations\n        if index &gt; 3:\n            raise IndexError(\"Index out of range\")\n\n        if index == 0:\n            return self.x0\n        elif index == 1:\n            return self.top\n        elif index == 2:\n            return self.x1\n        elif index == 3:\n            return self.bottom\n\n    def __eq__(self, other):\n        if not isinstance(other, NormBBox):\n            return False\n\n        return self.as_tuple() == other.as_tuple()\n\n    def __hash__(self):\n        return hash(self.as_tuple())\n\n    def __and__(self, other):\n        if not isinstance(other, NormBBox):\n            raise TypeError(\"Can only compute intersection with NormBBox\")\n        # Compute the intersection of two bounding boxes\n        new_x0 = max(self.x0, other.x0)\n        new_top = max(self.top, other.top)\n        new_x1 = min(self.x1, other.x1)\n        new_bottom = min(self.bottom, other.bottom)\n\n        # Check if there is an actual intersection and if the resulting bounding box is valid\n        if new_x0 &lt;= new_x1 and new_top &lt;= new_bottom:\n            return NormBBox(x0=new_x0, top=new_top, x1=new_x1, bottom=new_bottom)\n        else:\n            # Return an empty or non-existent bounding box representation\n            return None\n\n    def __add__(self, other):\n        if not isinstance(other, NormBBox):\n            raise TypeError(\"Can only add NormBBox to NormBBox\")\n\n        return NormBBox(\n            x0=min(self.x0, other.x0),\n            top=min(self.top, other.top),\n            x1=max(self.x1, other.x1),\n            bottom=max(self.bottom, other.bottom),\n        )\n\n    def __contains__(self, other):\n        return (\n            self.x0 &lt;= other.x0\n            and self.top &lt;= other.top\n            and self.x1 &gt;= other.x1\n            and self.bottom &gt;= other.bottom\n        )\n\n    def intersection_over_union(self, other):\n        if not isinstance(other, NormBBox):\n            raise TypeError(\"Can only compute IOU with NormBBox\")\n\n        # Compute the intersection\n        intersection_bbox = self &amp; other\n\n        if intersection_bbox:\n            intersection_area = intersection_bbox.area\n            union_area = self.area + other.area - intersection_area\n            return intersection_area / union_area\n\n        return 0  # No intersection\n\n    def x_overlap(self, other):\n        \"\"\"\n        Get the overlap, between 0 and 1, of the x-axis of two bounding boxes\n        \"\"\"\n        return max(0, min(self.x1, other.x1) - max(self.x0, other.x0))\n\n    def y_overlap(self, other):\n        \"\"\"\n        Get the overlap, between 0 and 1, of the y-axis of two bounding boxes\n        \"\"\"\n        return max(0, min(self.bottom, other.bottom) - max(self.top, other.top))\n\n    @classmethod\n    def combine(cls, *bboxes: \"NormBBox\"):\n        \"\"\"\n        Combines multiple bounding boxes into a single bounding box\n        \"\"\"\n        if len(bboxes) == 0:\n            raise ValueError(\"Must provide at least one bounding box\")\n\n        if len(bboxes) == 1:\n            return bboxes[0]\n\n        working_bbox = bboxes[0]\n        for bbox in bboxes[1:]:\n            working_bbox = working_bbox + bbox\n\n        return working_bbox\n\n    @classmethod\n    def from_bounding_poly(cls, bounding_poly: \"BoundingPoly\"):\n        \"\"\"\n        Returns a NormBBox from a BoundingPoly\n        \"\"\"\n        if len(bounding_poly.normalized_vertices) != 4:\n            raise ValueError(\n                \"BoundingPoly must have 4 vertices for NormBBox conversion\"\n            )\n\n        (\n            top_left,\n            top_right,\n            bottom_right,\n            bottom_left,\n        ) = bounding_poly.normalized_vertices\n\n        return cls(\n            x0=top_left.x,\n            top=top_left.y,\n            x1=bottom_right.x,\n            bottom=bottom_right.y,\n        )\n\n    @property\n    def width(self):\n        return self.x1 - self.x0\n\n    @property\n    def height(self):\n        return self.bottom - self.top\n\n    @property\n    def area(self):\n        return self.width * self.height\n\n    @property\n    def centroid(self):\n        return (self.x0 + self.x1) / 2, (self.top + self.bottom) / 2\n\n    @property\n    def y_center(self):\n        return (self.top + self.bottom) / 2\n\n    @property\n    def x_center(self):\n        return (self.x0 + self.x1) / 2\n</code></pre>"},{"location":"reference/schema/layout/#docprompt.schema.layout.NormBBox.combine","title":"<code>combine(*bboxes)</code>  <code>classmethod</code>","text":"<p>Combines multiple bounding boxes into a single bounding box</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>@classmethod\ndef combine(cls, *bboxes: \"NormBBox\"):\n    \"\"\"\n    Combines multiple bounding boxes into a single bounding box\n    \"\"\"\n    if len(bboxes) == 0:\n        raise ValueError(\"Must provide at least one bounding box\")\n\n    if len(bboxes) == 1:\n        return bboxes[0]\n\n    working_bbox = bboxes[0]\n    for bbox in bboxes[1:]:\n        working_bbox = working_bbox + bbox\n\n    return working_bbox\n</code></pre>"},{"location":"reference/schema/layout/#docprompt.schema.layout.NormBBox.from_bounding_poly","title":"<code>from_bounding_poly(bounding_poly)</code>  <code>classmethod</code>","text":"<p>Returns a NormBBox from a BoundingPoly</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>@classmethod\ndef from_bounding_poly(cls, bounding_poly: \"BoundingPoly\"):\n    \"\"\"\n    Returns a NormBBox from a BoundingPoly\n    \"\"\"\n    if len(bounding_poly.normalized_vertices) != 4:\n        raise ValueError(\n            \"BoundingPoly must have 4 vertices for NormBBox conversion\"\n        )\n\n    (\n        top_left,\n        top_right,\n        bottom_right,\n        bottom_left,\n    ) = bounding_poly.normalized_vertices\n\n    return cls(\n        x0=top_left.x,\n        top=top_left.y,\n        x1=bottom_right.x,\n        bottom=bottom_right.y,\n    )\n</code></pre>"},{"location":"reference/schema/layout/#docprompt.schema.layout.NormBBox.x_overlap","title":"<code>x_overlap(other)</code>","text":"<p>Get the overlap, between 0 and 1, of the x-axis of two bounding boxes</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>def x_overlap(self, other):\n    \"\"\"\n    Get the overlap, between 0 and 1, of the x-axis of two bounding boxes\n    \"\"\"\n    return max(0, min(self.x1, other.x1) - max(self.x0, other.x0))\n</code></pre>"},{"location":"reference/schema/layout/#docprompt.schema.layout.NormBBox.y_overlap","title":"<code>y_overlap(other)</code>","text":"<p>Get the overlap, between 0 and 1, of the y-axis of two bounding boxes</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>def y_overlap(self, other):\n    \"\"\"\n    Get the overlap, between 0 and 1, of the y-axis of two bounding boxes\n    \"\"\"\n    return max(0, min(self.bottom, other.bottom) - max(self.top, other.top))\n</code></pre>"},{"location":"reference/schema/layout/#docprompt.schema.layout.Point","title":"<code>Point</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a normalized bounding box with each value in the range [0, 1]</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>class Point(BaseModel):\n    \"\"\"\n    Represents a normalized bounding box with each value in the range [0, 1]\n    \"\"\"\n\n    class Config:\n        json_encoders = {float: lambda v: round(v, 5)}  # 1/10,000 increments is plenty\n\n    x: BoundedFloat\n    y: BoundedFloat\n</code></pre>"},{"location":"reference/schema/layout/#docprompt.schema.layout.TextBlock","title":"<code>TextBlock</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a single block of text, with its bounding box. The bounding box is a tuple of (x0, top, x1, bottom) and is normalized to the page size.</p> Source code in <code>docprompt/schema/layout.py</code> <pre><code>class TextBlock(BaseModel):\n    \"\"\"\n    Represents a single block of text, with its bounding box.\n    The bounding box is a tuple of (x0, top, x1, bottom) and\n    is normalized to the page size.\n    \"\"\"\n\n    class Config:\n        json_encoders = {float: lambda v: round(v, 5)}  # 1/10,000 increments is plenty\n\n    text: str\n    type: SegmentLevels\n    source: TextblockSource = Field(\n        default=\"derived\", description=\"The source of the text block\"\n    )\n\n    # Layout information\n    bounding_box: NormBBox = Field(default=None, repr=False)\n    bounding_poly: Optional[BoundingPoly] = Field(default=None, repr=False)\n    text_spans: Optional[List[TextSpan]] = Field(default=None, repr=False)\n\n    metadata: Optional[TextBlockMetadata] = Field(default_factory=TextBlockMetadata)\n\n    def __getitem__(self, index):\n        return getattr(self, index)\n\n    def __hash__(self):\n        return hash((self.text, self.bounding_box.as_tuple()))\n\n    @property\n    def confidence(self):\n        return self.metadata.confidence\n\n    @property\n    def direction(self):\n        return self.metadata.direction\n</code></pre>"},{"location":"reference/schema/pipeline/","title":"pipeline","text":""},{"location":"reference/schema/pipeline/#docprompt.schema.pipeline.DocumentCollection","title":"<code>DocumentCollection</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[DocumentCollectionMetadata, DocumentNodeMetadata, PageNodeMetadata]</code></p> <p>Represents a collection of documents with some common metadata</p> Source code in <code>docprompt/schema/pipeline.py</code> <pre><code>class DocumentCollection(\n    BaseModel,\n    Generic[DocumentCollectionMetadata, DocumentNodeMetadata, PageNodeMetadata],\n):\n    \"\"\"\n    Represents a collection of documents with some common metadata\n    \"\"\"\n\n    document_nodes: List[DocumentNode[DocumentNodeMetadata, PageNodeMetadata]]\n    metadata: DocumentCollectionMetadata\n</code></pre>"},{"location":"reference/schema/pipeline/#docprompt.schema.pipeline.DocumentNode","title":"<code>DocumentNode</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[DocumentNodeMetadata, PageNodeMetadata]</code></p> <p>Represents a single document, with some metadata</p> Source code in <code>docprompt/schema/pipeline.py</code> <pre><code>class DocumentNode(BaseModel, Generic[DocumentNodeMetadata, PageNodeMetadata]):\n    \"\"\"\n    Represents a single document, with some metadata\n    \"\"\"\n\n    document: Document\n    page_nodes: List[PageNode[PageNodeMetadata]] = Field(\n        description=\"The pages in the document\", default_factory=list, repr=False\n    )\n    metadata: Optional[DocumentNodeMetadata] = Field(\n        description=\"Application-specific metadata for the document\", default=None\n    )\n\n    _locator: Optional[\"DocumentProvenanceLocator\"] = PrivateAttr(default=None)\n\n    def __getstate__(self):\n        state = super().__getstate__()\n\n        state[\"__pydantic_private__\"][\"_locator\"] = None\n\n        return state\n\n    def __len__(self):\n        return len(self.page_nodes)\n\n    def __getitem__(self, index):\n        return self.page_nodes[index]\n\n    def __iter__(self):\n        return iter(self.page_nodes)\n\n    @property\n    def rasterizer(self):\n        return DocumentRasterizer(self)\n\n    @property\n    def locator(self):\n        if self._locator is None:\n            self.refresh_locator()\n\n        return self._locator\n\n    def refresh_locator(self):\n        \"\"\"\n        Refreshes the locator for this document node\n        \"\"\"\n        from docprompt.provenance.search import DocumentProvenanceLocator\n\n        if any(not page.ocr_results.result for page in self.page_nodes):\n            raise ValueError(\n                \"Cannot create a locator for a document node with missing OCR results\"\n            )\n\n        self._locator = DocumentProvenanceLocator.from_document_node(self)\n\n        return self.locator\n\n    @classmethod\n    def from_document(\n        cls,\n        document: Document,\n        document_metadata: Optional[DocumentNodeMetadata] = None,\n    ):\n        document_node: \"DocumentNode[DocumentNodeMetadata, PageNodeMetadata]\" = (\n            DocumentNode(document=document, metadata=document_metadata)\n        )\n\n        for page_number in range(1, len(document) + 1):\n            document_node.page_nodes.append(\n                PageNode(document=document_node, page_number=page_number)\n            )\n\n        return document_node\n\n    @property\n    def file_hash(self):\n        return self.document.document_hash\n\n    @property\n    def document_name(self):\n        return self.document.name\n</code></pre>"},{"location":"reference/schema/pipeline/#docprompt.schema.pipeline.DocumentNode.refresh_locator","title":"<code>refresh_locator()</code>","text":"<p>Refreshes the locator for this document node</p> Source code in <code>docprompt/schema/pipeline.py</code> <pre><code>def refresh_locator(self):\n    \"\"\"\n    Refreshes the locator for this document node\n    \"\"\"\n    from docprompt.provenance.search import DocumentProvenanceLocator\n\n    if any(not page.ocr_results.result for page in self.page_nodes):\n        raise ValueError(\n            \"Cannot create a locator for a document node with missing OCR results\"\n        )\n\n    self._locator = DocumentProvenanceLocator.from_document_node(self)\n\n    return self.locator\n</code></pre>"},{"location":"reference/schema/pipeline/#docprompt.schema.pipeline.DocumentRasterizer","title":"<code>DocumentRasterizer</code>","text":"Source code in <code>docprompt/schema/pipeline.py</code> <pre><code>class DocumentRasterizer:\n    def __init__(self, owner: \"DocumentNode\"):\n        self.owner = owner\n\n    def rasterize(\n        self,\n        name: str,\n        *,\n        return_mode: Literal[\"bytes\", \"pil\"] = \"bytes\",\n        dpi: int = 100,\n        downscale_size: Optional[Tuple[int, int]] = None,\n        resize_mode: ResizeModes = \"thumbnail\",\n        resize_aspect_ratios: Optional[Iterable[AspectRatioRule]] = None,\n        do_convert: bool = False,\n        image_convert_mode: str = \"L\",\n        do_quantize: bool = False,\n        quantize_color_count: int = 8,\n        max_file_size_bytes: Optional[int] = None,\n        render_grayscale: bool = False,\n    ) -&gt; List[Union[bytes, Image.Image]]:\n        images = self.owner.document.rasterize_pdf(\n            dpi=dpi,\n            downscale_size=downscale_size,\n            resize_mode=resize_mode,\n            resize_aspect_ratios=resize_aspect_ratios,\n            do_convert=do_convert,\n            image_convert_mode=image_convert_mode,\n            do_quantize=do_quantize,\n            quantize_color_count=quantize_color_count,\n            max_file_size_bytes=max_file_size_bytes,\n            render_grayscale=render_grayscale,\n            return_mode=return_mode,\n        )\n\n        for page_number, image in images.items():\n            page_node = self.owner.page_nodes[page_number - 1]\n\n            page_node._raster_cache[name] = image\n\n        return list(images.values())\n\n    def propagate_cache(self, name: str, rasters: Dict[int, Union[bytes, Image.Image]]):\n        \"\"\"\n        Should be one-indexed\n        \"\"\"\n        for page_number, raster in rasters.items():\n            page_node = self.owner.page_nodes[page_number - 1]\n\n            page_node._raster_cache[name] = raster\n</code></pre>"},{"location":"reference/schema/pipeline/#docprompt.schema.pipeline.DocumentRasterizer.propagate_cache","title":"<code>propagate_cache(name, rasters)</code>","text":"<p>Should be one-indexed</p> Source code in <code>docprompt/schema/pipeline.py</code> <pre><code>def propagate_cache(self, name: str, rasters: Dict[int, Union[bytes, Image.Image]]):\n    \"\"\"\n    Should be one-indexed\n    \"\"\"\n    for page_number, raster in rasters.items():\n        page_node = self.owner.page_nodes[page_number - 1]\n\n        page_node._raster_cache[name] = raster\n</code></pre>"},{"location":"reference/schema/pipeline/#docprompt.schema.pipeline.PageNode","title":"<code>PageNode</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[PageNodeMetadata]</code></p> <p>Represents a single page in a document, with some metadata</p> Source code in <code>docprompt/schema/pipeline.py</code> <pre><code>class PageNode(BaseModel, Generic[PageNodeMetadata]):\n    \"\"\"\n    Represents a single page in a document, with some metadata\n    \"\"\"\n\n    document: \"DocumentNode\" = Field(exclude=True, repr=False)\n    page_number: PositiveInt = Field(description=\"The page number\")\n    metadata: Optional[PageNodeMetadata] = Field(\n        description=\"Application-specific metadata for the page\", default=None\n    )\n    extra: Dict[str, Any] = Field(\n        description=\"Extra data that can be stored on the page node\",\n        default_factory=dict,\n    )\n\n    ocr_results: ResultContainer[OcrPageResult] = Field(\n        default_factory=lambda: ResultContainer(),\n        description=\"The OCR results for the page\",\n        repr=False,\n    )\n\n    _raster_cache: Dict[str, bytes] = PrivateAttr(default_factory=dict)\n\n    def __getstate__(self):\n        state = super().__getstate__()\n\n        state[\"__pydantic_private__\"][\"_raster_cache\"] = {}\n\n        return state\n\n    @property\n    def rasterizer(self):\n        return PageRasterizer(self._raster_cache, self)\n\n    def search(\n        self, query: str, refine_to_words: bool = True, require_exact_match: bool = True\n    ):\n        return self.document.locator.search(\n            query,\n            page_number=self.page_number,\n            refine_to_word=refine_to_words,\n            require_exact_match=require_exact_match,\n        )\n</code></pre>"},{"location":"reference/tasks/","title":"Index","text":""},{"location":"reference/tasks/#docprompt.tasks.base","title":"<code>base</code>","text":""},{"location":"reference/tasks/#docprompt.tasks.base.AbstractLanguageModelTaskProvider","title":"<code>AbstractLanguageModelTaskProvider</code>","text":"<p>               Bases: <code>AbstractTaskProvider</code></p> <p>Provides additional methods for language model specific tasks</p> Source code in <code>docprompt/tasks/base.py</code> <pre><code>class AbstractLanguageModelTaskProvider(AbstractTaskProvider):\n    \"\"\"\n    Provides additional methods for language model specific tasks\n    \"\"\"\n\n    def __init__(self, language_model: Any, *, model_name: Optional[str] = None):\n        self.language_model = language_model\n        self.model_type = validate_language_model(language_model)\n\n        self.model_name = model_name\n\n        self._validate_kwargs()\n\n    def _validate_kwargs(self):\n        \"\"\"\n        Validates the kwargs for the language model\n        \"\"\"\n        if self.model_type == \"openai\" and self.model_name is None:\n            raise ValueError(\"model_name must be provided for OpenAI language models\")\n</code></pre>"},{"location":"reference/tasks/#docprompt.tasks.base.AbstractTaskProvider","title":"<code>AbstractTaskProvider</code>","text":"<p>               Bases: <code>Generic[PageTaskResult]</code></p> <p>A task provider performs a specific, repeatable task on a document or its pages</p> Source code in <code>docprompt/tasks/base.py</code> <pre><code>class AbstractTaskProvider(Generic[PageTaskResult]):\n    \"\"\"\n    A task provider performs a specific, repeatable task on a document or its pages\n    \"\"\"\n\n    name: str\n    capabilities: List[str]\n\n    def process_document_pages(\n        self,\n        document: Document,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        **kwargs,\n    ) -&gt; Dict[int, PageTaskResult]:\n        raise NotImplementedError\n\n    def contribute_to_document_node(\n        self,\n        document_node: \"DocumentNode\",\n        results: Dict[int, PageTaskResult],\n    ) -&gt; None:\n        \"\"\"\n        Adds the results of this task to the document node and/or its page nodes\n        \"\"\"\n        pass\n\n    def process_document_node(\n        self,\n        document_node: \"DocumentNode\",\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        contribute_to_document: bool = True,\n        **kwargs,\n    ) -&gt; Dict[int, PageTaskResult]:\n        results = self.process_document_pages(\n            document_node.document, start=start, stop=stop, **kwargs\n        )\n\n        if contribute_to_document:\n            self.contribute_to_document_node(document_node, results)\n\n        return results\n</code></pre>"},{"location":"reference/tasks/#docprompt.tasks.base.AbstractTaskProvider.contribute_to_document_node","title":"<code>contribute_to_document_node(document_node, results)</code>","text":"<p>Adds the results of this task to the document node and/or its page nodes</p> Source code in <code>docprompt/tasks/base.py</code> <pre><code>def contribute_to_document_node(\n    self,\n    document_node: \"DocumentNode\",\n    results: Dict[int, PageTaskResult],\n) -&gt; None:\n    \"\"\"\n    Adds the results of this task to the document node and/or its page nodes\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/tasks/#docprompt.tasks.base.CAPABILITIES","title":"<code>CAPABILITIES</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Represents a capability that a provider can fulfill</p> Source code in <code>docprompt/tasks/base.py</code> <pre><code>class CAPABILITIES(Enum):\n    \"\"\"\n    Represents a capability that a provider can fulfill\n    \"\"\"\n\n    PAGE_RASTERIZATION = \"page-rasterization\"\n    PAGE_LAYOUT_OCR = \"page-layout-ocr\"\n    PAGE_TEXT_OCR = \"page-text-ocr\"\n    PAGE_CLASSIFICATION = \"page-classification\"\n    PAGE_SEGMENTATION = \"page-segmentation\"\n    PAGE_VQA = \"page-vqa\"\n    PAGE_TABLE_IDENTIFICATION = \"page-table-identification\"\n    PAGE_TABLE_EXTRACTION = \"page-table-extraction\"\n</code></pre>"},{"location":"reference/tasks/#docprompt.tasks.base.ResultContainer","title":"<code>ResultContainer</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[PageOrDocumentTaskResult]</code></p> <p>Represents a container for results of a task</p> Source code in <code>docprompt/tasks/base.py</code> <pre><code>class ResultContainer(BaseModel, Generic[PageOrDocumentTaskResult]):\n    \"\"\"\n    Represents a container for results of a task\n    \"\"\"\n\n    results: Dict[str, PageOrDocumentTaskResult] = Field(\n        description=\"The results of the task, keyed by provider\", default_factory=dict\n    )\n\n    @property\n    def result(self):\n        return next(iter(self.results.values()), None)\n</code></pre>"},{"location":"reference/tasks/#docprompt.tasks.base.attempt_import","title":"<code>attempt_import(name)</code>","text":"<p>Attempts to import a module or class by name</p> Source code in <code>docprompt/tasks/base.py</code> <pre><code>def attempt_import(name: str):\n    \"\"\"\n    Attempts to import a module or class by name\n    \"\"\"\n    package, obj = name.rsplit(\".\", 1)\n\n    try:\n        module = importlib.import_module(package)\n    except ImportError:\n        return None\n\n    return getattr(module, obj, None)\n</code></pre>"},{"location":"reference/tasks/#docprompt.tasks.message","title":"<code>message</code>","text":"<p>The core primatives for any language model interfacing. Docprompt uses these for the prompt garden, but supports free conversion to and from these types from other libaries.</p>"},{"location":"reference/tasks/#docprompt.tasks.ocr","title":"<code>ocr</code>","text":""},{"location":"reference/tasks/#docprompt.tasks.ocr.gcp","title":"<code>gcp</code>","text":""},{"location":"reference/tasks/#docprompt.tasks.ocr.gcp.GoogleOcrProvider","title":"<code>GoogleOcrProvider</code>","text":"<p>               Bases: <code>AbstractTaskProvider[OcrPageResult]</code></p> Source code in <code>docprompt/tasks/ocr/gcp.py</code> <pre><code>class GoogleOcrProvider(AbstractTaskProvider[OcrPageResult]):\n    name = \"Google Document AI\"\n    capabilities = [\n        CAPABILITIES.PAGE_TEXT_OCR.value,\n        CAPABILITIES.PAGE_LAYOUT_OCR.value,\n        CAPABILITIES.PAGE_RASTERIZATION.value,\n    ]\n\n    max_bytes_per_request = (\n        1024 * 1024 * 20\n    )  # 20MB is the max size for a single sync request\n    max_page_count = 15\n\n    def __init__(\n        self,\n        project_id: str,\n        processor_id: str,\n        *,\n        service_account_info: Optional[dict] = None,\n        service_account_file: Optional[str] = None,\n        location: str = \"us\",\n        max_workers: int = multiprocessing.cpu_count() * 2,\n        exclude_bounding_poly: bool = False,\n        return_images: bool = False,\n    ):\n        if service_account_info is None and service_account_file is None:\n            raise ValueError(\n                \"You must provide either service_account_info or service_account_file\"\n            )\n        if service_account_info is not None and service_account_file is not None:\n            raise ValueError(\n                \"You must provide either service_account_info or service_account_file, not both\"\n            )\n\n        self.project_id = project_id\n        self.processor_id = processor_id\n        self.location = location\n\n        self.max_workers = max_workers\n\n        self.service_account_info = service_account_info\n        self.service_account_file = service_account_file\n\n        self.exclude_bounding_poly = exclude_bounding_poly\n        self.return_images = return_images\n\n        try:\n            from google.cloud import documentai\n\n            self.documentai = documentai\n        except ImportError:\n            raise ImportError(\n                \"Please install 'google-cloud-documentai' to use the GoogleCloudVisionTextExtractionProvider\"\n            )\n\n    @classmethod\n    def from_service_account_file(\n        cls,\n        project_id: str,\n        processor_id: str,\n        service_account_file: str,\n    ):\n        return cls(\n            project_id,\n            processor_id,\n            service_account_file=service_account_file,\n        )\n\n    def get_documentai_client(self, client_option_kwargs: dict = {}, **kwargs):\n        from google.api_core.client_options import ClientOptions\n\n        opts = ClientOptions(\n            **{\n                \"api_endpoint\": \"us-documentai.googleapis.com\",\n                **client_option_kwargs,\n            }\n        )\n\n        base_service_client_kwargs = {\n            **kwargs,\n            \"client_options\": opts,\n        }\n\n        if self.service_account_info is not None:\n            return self.documentai.DocumentProcessorServiceClient.from_service_account_info(\n                info=self.service_account_info,\n                **base_service_client_kwargs,\n            )\n        elif self.service_account_file is not None:\n            with service_account_file_read_lock:\n                return self.documentai.DocumentProcessorServiceClient.from_service_account_file(\n                    filename=self.service_account_file,\n                    **base_service_client_kwargs,\n                )\n        else:\n            raise ValueError(\"Missing account info and service file path.\")\n\n    def _process_document_sync(self, document: Document):\n        \"\"\"\n        Split the document into chunks of 15 pages or less, and process each chunk\n        synchronously.\n        \"\"\"\n        client = self.get_documentai_client()\n        processor_name = client.processor_path(\n            project=self.project_id,\n            location=self.location,\n            processor=self.processor_id,\n        )\n\n        documents: List[\"documentai.Document\"] = []\n\n        file_bytes = document.get_bytes()\n\n        @default_retry_decorator\n        def process_byte_chunk(split_bytes: bytes) -&gt; \"documentai.Document\":\n            raw_document = self.documentai.RawDocument(\n                content=split_bytes,\n                mime_type=\"application/pdf\",\n            )\n\n            field_mask = (\n                \"text,pages.layout,pages.words,pages.lines,pages.tokens,pages.blocks\"\n            )\n\n            if self.return_images:\n                field_mask += \",pages.image\"\n\n            request = self.documentai.ProcessRequest(\n                name=processor_name, raw_document=raw_document, field_mask=field_mask\n            )\n\n            result = client.process_document(request=request)\n\n            return result.document\n\n        with tqdm.tqdm(\n            total=len(file_bytes), unit=\"B\", unit_scale=True, desc=\"Processing document\"\n        ) as pbar:\n            for split_bytes in pdf_split_iter_with_max_bytes(\n                file_bytes,\n                max_page_count=self.max_page_count,\n                max_bytes=self.max_bytes_per_request,\n            ):\n                document = process_byte_chunk(split_bytes)\n\n                documents.append(document)\n\n                pbar.update(len(split_bytes))\n\n        return gcp_documents_to_result(\n            documents,\n            self.name,\n            document_name=document.name,\n            file_hash=document.document_hash,\n            exclude_bounding_poly=self.exclude_bounding_poly,\n            return_images=self.return_images,\n        )\n\n    def _process_document_concurrent(\n        self,\n        document: Document,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        include_raster: bool = False,\n    ):\n        # Process page chunks concurrently\n        client = self.get_documentai_client()\n        processor_name = client.processor_path(\n            project=self.project_id,\n            location=self.location,\n            processor=self.processor_id,\n        )\n\n        file_bytes = document.file_bytes\n\n        if document.bytes_per_page &gt; 1024 * 1024 * 2:\n            logger.info(\"Document has few pages but is large, compressing first\")\n            file_bytes = document.to_compressed_bytes()\n\n        logger.info(\"Splitting document into chunks...\")\n        document_byte_splits = list(\n            pdf_split_iter_with_max_bytes(\n                file_bytes,\n                max_page_count=self.max_page_count,\n                max_bytes=self.max_bytes_per_request,\n            )\n        )\n\n        max_workers = min(len(document_byte_splits), self.max_workers)\n\n        @default_retry_decorator\n        def process_byte_chunk(split_bytes: bytes):\n            raw_document = self.documentai.RawDocument(\n                content=split_bytes,\n                mime_type=\"application/pdf\",\n            )\n\n            field_mask = (\n                \"text,pages.layout,pages.words,pages.lines,pages.tokens,pages.blocks\"\n            )\n\n            if self.return_images:\n                field_mask += \",pages.image\"\n\n            request = self.documentai.ProcessRequest(\n                name=processor_name, raw_document=raw_document, field_mask=field_mask\n            )\n\n            result = client.process_document(request=request)\n\n            document = result.document\n\n            return document\n\n        logger.info(f\"Processing {len(document_byte_splits)} chunks...\")\n        with tqdm.tqdm(\n            total=len(document_byte_splits), desc=\"Processing document\"\n        ) as pbar:\n            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n                future_to_index = {\n                    executor.submit(process_byte_chunk, split): index\n                    for index, split in enumerate(document_byte_splits)\n                }\n\n                documents: List[\"documentai.Document\"] = [None] * len(  # type: ignore\n                    document_byte_splits\n                )\n\n                for future in as_completed(future_to_index):\n                    index = future_to_index[future]\n                    documents[index] = future.result()\n                    pbar.update(1)\n\n        logger.info(\"Recombining OCR results...\")\n        return gcp_documents_to_result(\n            documents,\n            self.name,\n            document_name=document.name,\n            file_hash=document.document_hash,\n            exclude_bounding_poly=self.exclude_bounding_poly,\n            return_images=self.return_images,\n        )\n\n    def process_document_pages(\n        self,\n        document: Document,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        **kwargs,\n    ) -&gt; Dict[int, OcrPageResult]:\n        return self._process_document_concurrent(document, start=start, stop=stop)\n\n    def contribute_to_document_node(\n        self, document_node: \"DocumentNode\", results: Dict[int, OcrPageResult]\n    ) -&gt; None:\n        for page_number, result in results.items():\n            document_node.page_nodes[page_number - 1].ocr_results.results[self.name] = (\n                result\n            )\n</code></pre>"},{"location":"reference/tasks/#docprompt.tasks.ocr.gcp.text_from_layout","title":"<code>text_from_layout(layout, document_text, offset=0)</code>","text":"<p>Offset is used to account for the fact that text references are relative to the entire document.</p> Source code in <code>docprompt/tasks/ocr/gcp.py</code> <pre><code>def text_from_layout(\n    layout: Union[\"documentai.Document.Page.Layout\", \"documentai.Document.Page.Token\"],\n    document_text: str,\n    offset: int = 0,\n) -&gt; str:\n    \"\"\"\n    Offset is used to account for the fact that text references\n    are relative to the entire document.\n    \"\"\"\n    working_text = \"\"\n\n    for segment in sorted(layout.text_anchor.text_segments, key=lambda x: x.end_index):\n        start = getattr(segment, \"start_index\", 0)\n        end = segment.end_index\n\n        working_text += document_text[start - offset : end - offset]\n\n    return working_text\n</code></pre>"},{"location":"reference/tasks/#docprompt.tasks.ocr.result","title":"<code>result</code>","text":""},{"location":"reference/tasks/#docprompt.tasks.table_extraction","title":"<code>table_extraction</code>","text":""},{"location":"reference/tasks/#docprompt.tasks.table_extraction.base","title":"<code>base</code>","text":""},{"location":"reference/tasks/#docprompt.tasks.table_extraction.schema","title":"<code>schema</code>","text":""},{"location":"reference/tasks/base/","title":"base","text":""},{"location":"reference/tasks/base/#docprompt.tasks.base.AbstractLanguageModelTaskProvider","title":"<code>AbstractLanguageModelTaskProvider</code>","text":"<p>               Bases: <code>AbstractTaskProvider</code></p> <p>Provides additional methods for language model specific tasks</p> Source code in <code>docprompt/tasks/base.py</code> <pre><code>class AbstractLanguageModelTaskProvider(AbstractTaskProvider):\n    \"\"\"\n    Provides additional methods for language model specific tasks\n    \"\"\"\n\n    def __init__(self, language_model: Any, *, model_name: Optional[str] = None):\n        self.language_model = language_model\n        self.model_type = validate_language_model(language_model)\n\n        self.model_name = model_name\n\n        self._validate_kwargs()\n\n    def _validate_kwargs(self):\n        \"\"\"\n        Validates the kwargs for the language model\n        \"\"\"\n        if self.model_type == \"openai\" and self.model_name is None:\n            raise ValueError(\"model_name must be provided for OpenAI language models\")\n</code></pre>"},{"location":"reference/tasks/base/#docprompt.tasks.base.AbstractTaskProvider","title":"<code>AbstractTaskProvider</code>","text":"<p>               Bases: <code>Generic[PageTaskResult]</code></p> <p>A task provider performs a specific, repeatable task on a document or its pages</p> Source code in <code>docprompt/tasks/base.py</code> <pre><code>class AbstractTaskProvider(Generic[PageTaskResult]):\n    \"\"\"\n    A task provider performs a specific, repeatable task on a document or its pages\n    \"\"\"\n\n    name: str\n    capabilities: List[str]\n\n    def process_document_pages(\n        self,\n        document: Document,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        **kwargs,\n    ) -&gt; Dict[int, PageTaskResult]:\n        raise NotImplementedError\n\n    def contribute_to_document_node(\n        self,\n        document_node: \"DocumentNode\",\n        results: Dict[int, PageTaskResult],\n    ) -&gt; None:\n        \"\"\"\n        Adds the results of this task to the document node and/or its page nodes\n        \"\"\"\n        pass\n\n    def process_document_node(\n        self,\n        document_node: \"DocumentNode\",\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        contribute_to_document: bool = True,\n        **kwargs,\n    ) -&gt; Dict[int, PageTaskResult]:\n        results = self.process_document_pages(\n            document_node.document, start=start, stop=stop, **kwargs\n        )\n\n        if contribute_to_document:\n            self.contribute_to_document_node(document_node, results)\n\n        return results\n</code></pre>"},{"location":"reference/tasks/base/#docprompt.tasks.base.AbstractTaskProvider.contribute_to_document_node","title":"<code>contribute_to_document_node(document_node, results)</code>","text":"<p>Adds the results of this task to the document node and/or its page nodes</p> Source code in <code>docprompt/tasks/base.py</code> <pre><code>def contribute_to_document_node(\n    self,\n    document_node: \"DocumentNode\",\n    results: Dict[int, PageTaskResult],\n) -&gt; None:\n    \"\"\"\n    Adds the results of this task to the document node and/or its page nodes\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/tasks/base/#docprompt.tasks.base.CAPABILITIES","title":"<code>CAPABILITIES</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Represents a capability that a provider can fulfill</p> Source code in <code>docprompt/tasks/base.py</code> <pre><code>class CAPABILITIES(Enum):\n    \"\"\"\n    Represents a capability that a provider can fulfill\n    \"\"\"\n\n    PAGE_RASTERIZATION = \"page-rasterization\"\n    PAGE_LAYOUT_OCR = \"page-layout-ocr\"\n    PAGE_TEXT_OCR = \"page-text-ocr\"\n    PAGE_CLASSIFICATION = \"page-classification\"\n    PAGE_SEGMENTATION = \"page-segmentation\"\n    PAGE_VQA = \"page-vqa\"\n    PAGE_TABLE_IDENTIFICATION = \"page-table-identification\"\n    PAGE_TABLE_EXTRACTION = \"page-table-extraction\"\n</code></pre>"},{"location":"reference/tasks/base/#docprompt.tasks.base.ResultContainer","title":"<code>ResultContainer</code>","text":"<p>               Bases: <code>BaseModel</code>, <code>Generic[PageOrDocumentTaskResult]</code></p> <p>Represents a container for results of a task</p> Source code in <code>docprompt/tasks/base.py</code> <pre><code>class ResultContainer(BaseModel, Generic[PageOrDocumentTaskResult]):\n    \"\"\"\n    Represents a container for results of a task\n    \"\"\"\n\n    results: Dict[str, PageOrDocumentTaskResult] = Field(\n        description=\"The results of the task, keyed by provider\", default_factory=dict\n    )\n\n    @property\n    def result(self):\n        return next(iter(self.results.values()), None)\n</code></pre>"},{"location":"reference/tasks/base/#docprompt.tasks.base.attempt_import","title":"<code>attempt_import(name)</code>","text":"<p>Attempts to import a module or class by name</p> Source code in <code>docprompt/tasks/base.py</code> <pre><code>def attempt_import(name: str):\n    \"\"\"\n    Attempts to import a module or class by name\n    \"\"\"\n    package, obj = name.rsplit(\".\", 1)\n\n    try:\n        module = importlib.import_module(package)\n    except ImportError:\n        return None\n\n    return getattr(module, obj, None)\n</code></pre>"},{"location":"reference/tasks/message/","title":"message","text":"<p>The core primatives for any language model interfacing. Docprompt uses these for the prompt garden, but supports free conversion to and from these types from other libaries.</p>"},{"location":"reference/tasks/classification/","title":"classification","text":""},{"location":"reference/tasks/ocr/","title":"Index","text":""},{"location":"reference/tasks/ocr/#docprompt.tasks.ocr.gcp","title":"<code>gcp</code>","text":""},{"location":"reference/tasks/ocr/#docprompt.tasks.ocr.gcp.GoogleOcrProvider","title":"<code>GoogleOcrProvider</code>","text":"<p>               Bases: <code>AbstractTaskProvider[OcrPageResult]</code></p> Source code in <code>docprompt/tasks/ocr/gcp.py</code> <pre><code>class GoogleOcrProvider(AbstractTaskProvider[OcrPageResult]):\n    name = \"Google Document AI\"\n    capabilities = [\n        CAPABILITIES.PAGE_TEXT_OCR.value,\n        CAPABILITIES.PAGE_LAYOUT_OCR.value,\n        CAPABILITIES.PAGE_RASTERIZATION.value,\n    ]\n\n    max_bytes_per_request = (\n        1024 * 1024 * 20\n    )  # 20MB is the max size for a single sync request\n    max_page_count = 15\n\n    def __init__(\n        self,\n        project_id: str,\n        processor_id: str,\n        *,\n        service_account_info: Optional[dict] = None,\n        service_account_file: Optional[str] = None,\n        location: str = \"us\",\n        max_workers: int = multiprocessing.cpu_count() * 2,\n        exclude_bounding_poly: bool = False,\n        return_images: bool = False,\n    ):\n        if service_account_info is None and service_account_file is None:\n            raise ValueError(\n                \"You must provide either service_account_info or service_account_file\"\n            )\n        if service_account_info is not None and service_account_file is not None:\n            raise ValueError(\n                \"You must provide either service_account_info or service_account_file, not both\"\n            )\n\n        self.project_id = project_id\n        self.processor_id = processor_id\n        self.location = location\n\n        self.max_workers = max_workers\n\n        self.service_account_info = service_account_info\n        self.service_account_file = service_account_file\n\n        self.exclude_bounding_poly = exclude_bounding_poly\n        self.return_images = return_images\n\n        try:\n            from google.cloud import documentai\n\n            self.documentai = documentai\n        except ImportError:\n            raise ImportError(\n                \"Please install 'google-cloud-documentai' to use the GoogleCloudVisionTextExtractionProvider\"\n            )\n\n    @classmethod\n    def from_service_account_file(\n        cls,\n        project_id: str,\n        processor_id: str,\n        service_account_file: str,\n    ):\n        return cls(\n            project_id,\n            processor_id,\n            service_account_file=service_account_file,\n        )\n\n    def get_documentai_client(self, client_option_kwargs: dict = {}, **kwargs):\n        from google.api_core.client_options import ClientOptions\n\n        opts = ClientOptions(\n            **{\n                \"api_endpoint\": \"us-documentai.googleapis.com\",\n                **client_option_kwargs,\n            }\n        )\n\n        base_service_client_kwargs = {\n            **kwargs,\n            \"client_options\": opts,\n        }\n\n        if self.service_account_info is not None:\n            return self.documentai.DocumentProcessorServiceClient.from_service_account_info(\n                info=self.service_account_info,\n                **base_service_client_kwargs,\n            )\n        elif self.service_account_file is not None:\n            with service_account_file_read_lock:\n                return self.documentai.DocumentProcessorServiceClient.from_service_account_file(\n                    filename=self.service_account_file,\n                    **base_service_client_kwargs,\n                )\n        else:\n            raise ValueError(\"Missing account info and service file path.\")\n\n    def _process_document_sync(self, document: Document):\n        \"\"\"\n        Split the document into chunks of 15 pages or less, and process each chunk\n        synchronously.\n        \"\"\"\n        client = self.get_documentai_client()\n        processor_name = client.processor_path(\n            project=self.project_id,\n            location=self.location,\n            processor=self.processor_id,\n        )\n\n        documents: List[\"documentai.Document\"] = []\n\n        file_bytes = document.get_bytes()\n\n        @default_retry_decorator\n        def process_byte_chunk(split_bytes: bytes) -&gt; \"documentai.Document\":\n            raw_document = self.documentai.RawDocument(\n                content=split_bytes,\n                mime_type=\"application/pdf\",\n            )\n\n            field_mask = (\n                \"text,pages.layout,pages.words,pages.lines,pages.tokens,pages.blocks\"\n            )\n\n            if self.return_images:\n                field_mask += \",pages.image\"\n\n            request = self.documentai.ProcessRequest(\n                name=processor_name, raw_document=raw_document, field_mask=field_mask\n            )\n\n            result = client.process_document(request=request)\n\n            return result.document\n\n        with tqdm.tqdm(\n            total=len(file_bytes), unit=\"B\", unit_scale=True, desc=\"Processing document\"\n        ) as pbar:\n            for split_bytes in pdf_split_iter_with_max_bytes(\n                file_bytes,\n                max_page_count=self.max_page_count,\n                max_bytes=self.max_bytes_per_request,\n            ):\n                document = process_byte_chunk(split_bytes)\n\n                documents.append(document)\n\n                pbar.update(len(split_bytes))\n\n        return gcp_documents_to_result(\n            documents,\n            self.name,\n            document_name=document.name,\n            file_hash=document.document_hash,\n            exclude_bounding_poly=self.exclude_bounding_poly,\n            return_images=self.return_images,\n        )\n\n    def _process_document_concurrent(\n        self,\n        document: Document,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        include_raster: bool = False,\n    ):\n        # Process page chunks concurrently\n        client = self.get_documentai_client()\n        processor_name = client.processor_path(\n            project=self.project_id,\n            location=self.location,\n            processor=self.processor_id,\n        )\n\n        file_bytes = document.file_bytes\n\n        if document.bytes_per_page &gt; 1024 * 1024 * 2:\n            logger.info(\"Document has few pages but is large, compressing first\")\n            file_bytes = document.to_compressed_bytes()\n\n        logger.info(\"Splitting document into chunks...\")\n        document_byte_splits = list(\n            pdf_split_iter_with_max_bytes(\n                file_bytes,\n                max_page_count=self.max_page_count,\n                max_bytes=self.max_bytes_per_request,\n            )\n        )\n\n        max_workers = min(len(document_byte_splits), self.max_workers)\n\n        @default_retry_decorator\n        def process_byte_chunk(split_bytes: bytes):\n            raw_document = self.documentai.RawDocument(\n                content=split_bytes,\n                mime_type=\"application/pdf\",\n            )\n\n            field_mask = (\n                \"text,pages.layout,pages.words,pages.lines,pages.tokens,pages.blocks\"\n            )\n\n            if self.return_images:\n                field_mask += \",pages.image\"\n\n            request = self.documentai.ProcessRequest(\n                name=processor_name, raw_document=raw_document, field_mask=field_mask\n            )\n\n            result = client.process_document(request=request)\n\n            document = result.document\n\n            return document\n\n        logger.info(f\"Processing {len(document_byte_splits)} chunks...\")\n        with tqdm.tqdm(\n            total=len(document_byte_splits), desc=\"Processing document\"\n        ) as pbar:\n            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n                future_to_index = {\n                    executor.submit(process_byte_chunk, split): index\n                    for index, split in enumerate(document_byte_splits)\n                }\n\n                documents: List[\"documentai.Document\"] = [None] * len(  # type: ignore\n                    document_byte_splits\n                )\n\n                for future in as_completed(future_to_index):\n                    index = future_to_index[future]\n                    documents[index] = future.result()\n                    pbar.update(1)\n\n        logger.info(\"Recombining OCR results...\")\n        return gcp_documents_to_result(\n            documents,\n            self.name,\n            document_name=document.name,\n            file_hash=document.document_hash,\n            exclude_bounding_poly=self.exclude_bounding_poly,\n            return_images=self.return_images,\n        )\n\n    def process_document_pages(\n        self,\n        document: Document,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        **kwargs,\n    ) -&gt; Dict[int, OcrPageResult]:\n        return self._process_document_concurrent(document, start=start, stop=stop)\n\n    def contribute_to_document_node(\n        self, document_node: \"DocumentNode\", results: Dict[int, OcrPageResult]\n    ) -&gt; None:\n        for page_number, result in results.items():\n            document_node.page_nodes[page_number - 1].ocr_results.results[self.name] = (\n                result\n            )\n</code></pre>"},{"location":"reference/tasks/ocr/#docprompt.tasks.ocr.gcp.text_from_layout","title":"<code>text_from_layout(layout, document_text, offset=0)</code>","text":"<p>Offset is used to account for the fact that text references are relative to the entire document.</p> Source code in <code>docprompt/tasks/ocr/gcp.py</code> <pre><code>def text_from_layout(\n    layout: Union[\"documentai.Document.Page.Layout\", \"documentai.Document.Page.Token\"],\n    document_text: str,\n    offset: int = 0,\n) -&gt; str:\n    \"\"\"\n    Offset is used to account for the fact that text references\n    are relative to the entire document.\n    \"\"\"\n    working_text = \"\"\n\n    for segment in sorted(layout.text_anchor.text_segments, key=lambda x: x.end_index):\n        start = getattr(segment, \"start_index\", 0)\n        end = segment.end_index\n\n        working_text += document_text[start - offset : end - offset]\n\n    return working_text\n</code></pre>"},{"location":"reference/tasks/ocr/#docprompt.tasks.ocr.result","title":"<code>result</code>","text":""},{"location":"reference/tasks/ocr/gcp/","title":"gcp","text":""},{"location":"reference/tasks/ocr/gcp/#docprompt.tasks.ocr.gcp.GoogleOcrProvider","title":"<code>GoogleOcrProvider</code>","text":"<p>               Bases: <code>AbstractTaskProvider[OcrPageResult]</code></p> Source code in <code>docprompt/tasks/ocr/gcp.py</code> <pre><code>class GoogleOcrProvider(AbstractTaskProvider[OcrPageResult]):\n    name = \"Google Document AI\"\n    capabilities = [\n        CAPABILITIES.PAGE_TEXT_OCR.value,\n        CAPABILITIES.PAGE_LAYOUT_OCR.value,\n        CAPABILITIES.PAGE_RASTERIZATION.value,\n    ]\n\n    max_bytes_per_request = (\n        1024 * 1024 * 20\n    )  # 20MB is the max size for a single sync request\n    max_page_count = 15\n\n    def __init__(\n        self,\n        project_id: str,\n        processor_id: str,\n        *,\n        service_account_info: Optional[dict] = None,\n        service_account_file: Optional[str] = None,\n        location: str = \"us\",\n        max_workers: int = multiprocessing.cpu_count() * 2,\n        exclude_bounding_poly: bool = False,\n        return_images: bool = False,\n    ):\n        if service_account_info is None and service_account_file is None:\n            raise ValueError(\n                \"You must provide either service_account_info or service_account_file\"\n            )\n        if service_account_info is not None and service_account_file is not None:\n            raise ValueError(\n                \"You must provide either service_account_info or service_account_file, not both\"\n            )\n\n        self.project_id = project_id\n        self.processor_id = processor_id\n        self.location = location\n\n        self.max_workers = max_workers\n\n        self.service_account_info = service_account_info\n        self.service_account_file = service_account_file\n\n        self.exclude_bounding_poly = exclude_bounding_poly\n        self.return_images = return_images\n\n        try:\n            from google.cloud import documentai\n\n            self.documentai = documentai\n        except ImportError:\n            raise ImportError(\n                \"Please install 'google-cloud-documentai' to use the GoogleCloudVisionTextExtractionProvider\"\n            )\n\n    @classmethod\n    def from_service_account_file(\n        cls,\n        project_id: str,\n        processor_id: str,\n        service_account_file: str,\n    ):\n        return cls(\n            project_id,\n            processor_id,\n            service_account_file=service_account_file,\n        )\n\n    def get_documentai_client(self, client_option_kwargs: dict = {}, **kwargs):\n        from google.api_core.client_options import ClientOptions\n\n        opts = ClientOptions(\n            **{\n                \"api_endpoint\": \"us-documentai.googleapis.com\",\n                **client_option_kwargs,\n            }\n        )\n\n        base_service_client_kwargs = {\n            **kwargs,\n            \"client_options\": opts,\n        }\n\n        if self.service_account_info is not None:\n            return self.documentai.DocumentProcessorServiceClient.from_service_account_info(\n                info=self.service_account_info,\n                **base_service_client_kwargs,\n            )\n        elif self.service_account_file is not None:\n            with service_account_file_read_lock:\n                return self.documentai.DocumentProcessorServiceClient.from_service_account_file(\n                    filename=self.service_account_file,\n                    **base_service_client_kwargs,\n                )\n        else:\n            raise ValueError(\"Missing account info and service file path.\")\n\n    def _process_document_sync(self, document: Document):\n        \"\"\"\n        Split the document into chunks of 15 pages or less, and process each chunk\n        synchronously.\n        \"\"\"\n        client = self.get_documentai_client()\n        processor_name = client.processor_path(\n            project=self.project_id,\n            location=self.location,\n            processor=self.processor_id,\n        )\n\n        documents: List[\"documentai.Document\"] = []\n\n        file_bytes = document.get_bytes()\n\n        @default_retry_decorator\n        def process_byte_chunk(split_bytes: bytes) -&gt; \"documentai.Document\":\n            raw_document = self.documentai.RawDocument(\n                content=split_bytes,\n                mime_type=\"application/pdf\",\n            )\n\n            field_mask = (\n                \"text,pages.layout,pages.words,pages.lines,pages.tokens,pages.blocks\"\n            )\n\n            if self.return_images:\n                field_mask += \",pages.image\"\n\n            request = self.documentai.ProcessRequest(\n                name=processor_name, raw_document=raw_document, field_mask=field_mask\n            )\n\n            result = client.process_document(request=request)\n\n            return result.document\n\n        with tqdm.tqdm(\n            total=len(file_bytes), unit=\"B\", unit_scale=True, desc=\"Processing document\"\n        ) as pbar:\n            for split_bytes in pdf_split_iter_with_max_bytes(\n                file_bytes,\n                max_page_count=self.max_page_count,\n                max_bytes=self.max_bytes_per_request,\n            ):\n                document = process_byte_chunk(split_bytes)\n\n                documents.append(document)\n\n                pbar.update(len(split_bytes))\n\n        return gcp_documents_to_result(\n            documents,\n            self.name,\n            document_name=document.name,\n            file_hash=document.document_hash,\n            exclude_bounding_poly=self.exclude_bounding_poly,\n            return_images=self.return_images,\n        )\n\n    def _process_document_concurrent(\n        self,\n        document: Document,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        include_raster: bool = False,\n    ):\n        # Process page chunks concurrently\n        client = self.get_documentai_client()\n        processor_name = client.processor_path(\n            project=self.project_id,\n            location=self.location,\n            processor=self.processor_id,\n        )\n\n        file_bytes = document.file_bytes\n\n        if document.bytes_per_page &gt; 1024 * 1024 * 2:\n            logger.info(\"Document has few pages but is large, compressing first\")\n            file_bytes = document.to_compressed_bytes()\n\n        logger.info(\"Splitting document into chunks...\")\n        document_byte_splits = list(\n            pdf_split_iter_with_max_bytes(\n                file_bytes,\n                max_page_count=self.max_page_count,\n                max_bytes=self.max_bytes_per_request,\n            )\n        )\n\n        max_workers = min(len(document_byte_splits), self.max_workers)\n\n        @default_retry_decorator\n        def process_byte_chunk(split_bytes: bytes):\n            raw_document = self.documentai.RawDocument(\n                content=split_bytes,\n                mime_type=\"application/pdf\",\n            )\n\n            field_mask = (\n                \"text,pages.layout,pages.words,pages.lines,pages.tokens,pages.blocks\"\n            )\n\n            if self.return_images:\n                field_mask += \",pages.image\"\n\n            request = self.documentai.ProcessRequest(\n                name=processor_name, raw_document=raw_document, field_mask=field_mask\n            )\n\n            result = client.process_document(request=request)\n\n            document = result.document\n\n            return document\n\n        logger.info(f\"Processing {len(document_byte_splits)} chunks...\")\n        with tqdm.tqdm(\n            total=len(document_byte_splits), desc=\"Processing document\"\n        ) as pbar:\n            with ThreadPoolExecutor(max_workers=max_workers) as executor:\n                future_to_index = {\n                    executor.submit(process_byte_chunk, split): index\n                    for index, split in enumerate(document_byte_splits)\n                }\n\n                documents: List[\"documentai.Document\"] = [None] * len(  # type: ignore\n                    document_byte_splits\n                )\n\n                for future in as_completed(future_to_index):\n                    index = future_to_index[future]\n                    documents[index] = future.result()\n                    pbar.update(1)\n\n        logger.info(\"Recombining OCR results...\")\n        return gcp_documents_to_result(\n            documents,\n            self.name,\n            document_name=document.name,\n            file_hash=document.document_hash,\n            exclude_bounding_poly=self.exclude_bounding_poly,\n            return_images=self.return_images,\n        )\n\n    def process_document_pages(\n        self,\n        document: Document,\n        start: Optional[int] = None,\n        stop: Optional[int] = None,\n        **kwargs,\n    ) -&gt; Dict[int, OcrPageResult]:\n        return self._process_document_concurrent(document, start=start, stop=stop)\n\n    def contribute_to_document_node(\n        self, document_node: \"DocumentNode\", results: Dict[int, OcrPageResult]\n    ) -&gt; None:\n        for page_number, result in results.items():\n            document_node.page_nodes[page_number - 1].ocr_results.results[self.name] = (\n                result\n            )\n</code></pre>"},{"location":"reference/tasks/ocr/gcp/#docprompt.tasks.ocr.gcp.text_from_layout","title":"<code>text_from_layout(layout, document_text, offset=0)</code>","text":"<p>Offset is used to account for the fact that text references are relative to the entire document.</p> Source code in <code>docprompt/tasks/ocr/gcp.py</code> <pre><code>def text_from_layout(\n    layout: Union[\"documentai.Document.Page.Layout\", \"documentai.Document.Page.Token\"],\n    document_text: str,\n    offset: int = 0,\n) -&gt; str:\n    \"\"\"\n    Offset is used to account for the fact that text references\n    are relative to the entire document.\n    \"\"\"\n    working_text = \"\"\n\n    for segment in sorted(layout.text_anchor.text_segments, key=lambda x: x.end_index):\n        start = getattr(segment, \"start_index\", 0)\n        end = segment.end_index\n\n        working_text += document_text[start - offset : end - offset]\n\n    return working_text\n</code></pre>"},{"location":"reference/tasks/ocr/result/","title":"result","text":""},{"location":"reference/tasks/table_extraction/","title":"Index","text":""},{"location":"reference/tasks/table_extraction/#docprompt.tasks.table_extraction.base","title":"<code>base</code>","text":""},{"location":"reference/tasks/table_extraction/#docprompt.tasks.table_extraction.schema","title":"<code>schema</code>","text":""},{"location":"reference/tasks/table_extraction/base/","title":"base","text":""},{"location":"reference/tasks/table_extraction/schema/","title":"schema","text":""},{"location":"reference/utils/","title":"Index","text":""},{"location":"reference/utils/#docprompt.utils.extract_dates_from_text","title":"<code>extract_dates_from_text(input_string, *, date_formats=default_date_formats)</code>","text":"<p>Extract dates from a string using a set of predefined regex patterns.</p> <p>Returns a list of tuples, where the first element is the date object and the second is the full date string.</p> Source code in <code>docprompt/utils/date_extraction.py</code> <pre><code>def extract_dates_from_text(\n    input_string: str, *, date_formats: DateFormatsType = default_date_formats\n) -&gt; List[Tuple[date, str]]:\n    \"\"\"\n    Extract dates from a string using a set of predefined regex patterns.\n\n    Returns a list of tuples, where the first element is the date object and the second is the full date string.\n    \"\"\"\n    extracted_dates = []\n\n    for regex, date_format in date_formats:\n        matches = regex.findall(input_string)\n\n        for match_obj in matches:\n            # Extract the full date from the match\n            full_date = match_obj[0]  # First group captures the entire date\n\n            if \"%d\" in date_format:\n                parse_date = re.sub(r\"(st|nd|rd|th)\", \"\", full_date)\n            else:\n                parse_date = full_date\n\n            parse_date = re.sub(r\"\\s+\", \" \", parse_date).strip()\n            parse_date = re.sub(\n                r\"\\s{1,},\", \",\", parse_date\n            ).strip()  # Commas shouldnt have spaces before them\n\n            # Convert to datetime object\n            try:\n                date_obj = datetime.strptime(parse_date, date_format)\n            except ValueError as e:\n                print(f\"Error parsing date '{full_date}': {e}\")\n                continue\n\n            extracted_dates.append((date_obj.date(), full_date))\n\n    return extracted_dates\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.get_page_count","title":"<code>get_page_count(fd)</code>","text":"<p>Determines the number of pages in a PDF</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def get_page_count(fd: Union[Path, PathLike, bytes]) -&gt; int:\n    \"\"\"\n    Determines the number of pages in a PDF\n    \"\"\"\n    if not isinstance(fd, bytes):\n        with open(fd, \"rb\") as f:\n            fd = f.read()\n\n    with get_pdfium_document(fd) as pdf:\n        return len(pdf)\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.hash_from_bytes","title":"<code>hash_from_bytes(byte_data, hash_func=hashlib.md5, threshold=1024 * 1024 * 128)</code>","text":"<p>Gets a hash from bytes. If the bytes are larger than the threshold, the hash is computed in chunks to avoid memory issues. The default hash function is MD5 with a threshold of 128MB which is optimal for most machines and use cases.</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def hash_from_bytes(\n    byte_data: bytes, hash_func=hashlib.md5, threshold=1024 * 1024 * 128\n) -&gt; str:\n    \"\"\"\n    Gets a hash from bytes. If the bytes are larger than the threshold, the hash is computed in chunks\n    to avoid memory issues. The default hash function is MD5 with a threshold of 128MB which is optimal\n    for most machines and use cases.\n    \"\"\"\n    hash = hash_func()\n\n    if len(byte_data) &gt; threshold:\n        stream = BytesIO(byte_data)\n        b = bytearray(128 * 1024)\n        mv = memoryview(b)\n\n        while n := stream.readinto(mv):\n            hash.update(mv[:n])\n    else:\n        hash.update(byte_data)\n\n    return hash.hexdigest()\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.is_pdf","title":"<code>is_pdf(fd)</code>","text":"<p>Determines if a file is a PDF</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def is_pdf(fd: Union[Path, PathLike, bytes]) -&gt; bool:\n    \"\"\"\n    Determines if a file is a PDF\n    \"\"\"\n    if isinstance(fd, (bytes, str)):\n        mime = filetype.guess_mime(fd)\n    else:\n        with open(fd, \"rb\") as f:\n            # We only need the first 1024 bytes to determine if it's a PDF\n            mime = filetype.guess_mime(f.read(1024))\n\n    return mime == \"application/pdf\"\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.load_document","title":"<code>load_document(fp, *, file_name=None)</code>","text":"<p>Loads a document from a file path</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def load_document(\n    fp: Union[Path, PathLike, bytes],\n    *,\n    file_name: Optional[str] = None,\n) -&gt; PdfDocument:\n    \"\"\"\n    Loads a document from a file path\n    \"\"\"\n    if isinstance(fp, bytes):\n        file_bytes = fp\n        file_name = file_name or determine_pdf_name_from_bytes(file_bytes)\n    else:\n        file_name = name_from_path(fp) if file_name is None else file_name\n\n        file_bytes = read_pdf_bytes_from_path(fp)\n\n    if not is_pdf(file_bytes):\n        raise ValueError(\"File is not a PDF\")\n\n    return PdfDocument(\n        name=unquote(file_name), file_path=str(fp), file_bytes=file_bytes\n    )\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.load_documents","title":"<code>load_documents(fps, *, max_threads=12)</code>","text":"<p>Loads multiple documents from file paths, using a thread pool</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def load_documents(\n    fps: List[Union[Path, PathLike, bytes]],\n    *,\n    max_threads: int = 12,\n):\n    \"\"\"\n    Loads multiple documents from file paths, using a thread pool\n    \"\"\"\n    futures = []\n\n    thread_count = min(max_threads, len(fps))\n\n    with ThreadPoolExecutor(max_workers=thread_count) as executor:\n        for fp in fps:\n            futures.append(executor.submit(load_document, fp))\n\n    results = []\n\n    for future in as_completed(futures):\n        results.append(future.result())\n\n    return results\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.date_extraction","title":"<code>date_extraction</code>","text":""},{"location":"reference/utils/#docprompt.utils.date_extraction.extract_dates_from_text","title":"<code>extract_dates_from_text(input_string, *, date_formats=default_date_formats)</code>","text":"<p>Extract dates from a string using a set of predefined regex patterns.</p> <p>Returns a list of tuples, where the first element is the date object and the second is the full date string.</p> Source code in <code>docprompt/utils/date_extraction.py</code> <pre><code>def extract_dates_from_text(\n    input_string: str, *, date_formats: DateFormatsType = default_date_formats\n) -&gt; List[Tuple[date, str]]:\n    \"\"\"\n    Extract dates from a string using a set of predefined regex patterns.\n\n    Returns a list of tuples, where the first element is the date object and the second is the full date string.\n    \"\"\"\n    extracted_dates = []\n\n    for regex, date_format in date_formats:\n        matches = regex.findall(input_string)\n\n        for match_obj in matches:\n            # Extract the full date from the match\n            full_date = match_obj[0]  # First group captures the entire date\n\n            if \"%d\" in date_format:\n                parse_date = re.sub(r\"(st|nd|rd|th)\", \"\", full_date)\n            else:\n                parse_date = full_date\n\n            parse_date = re.sub(r\"\\s+\", \" \", parse_date).strip()\n            parse_date = re.sub(\n                r\"\\s{1,},\", \",\", parse_date\n            ).strip()  # Commas shouldnt have spaces before them\n\n            # Convert to datetime object\n            try:\n                date_obj = datetime.strptime(parse_date, date_format)\n            except ValueError as e:\n                print(f\"Error parsing date '{full_date}': {e}\")\n                continue\n\n            extracted_dates.append((date_obj.date(), full_date))\n\n    return extracted_dates\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.masking","title":"<code>masking</code>","text":""},{"location":"reference/utils/#docprompt.utils.masking.image","title":"<code>image</code>","text":""},{"location":"reference/utils/#docprompt.utils.masking.image.mask_image_from_bounding_boxes","title":"<code>mask_image_from_bounding_boxes(image, *bounding_boxes, mask_color='#000000')</code>","text":"<p>Create a copy of the image with the positions of the bounding boxes masked.</p> Source code in <code>docprompt/utils/masking/image.py</code> <pre><code>def mask_image_from_bounding_boxes(\n    image: Image.Image,\n    *bounding_boxes: NormBBox,\n    mask_color: str = \"#000000\",\n):\n    \"\"\"\n    Create a copy of the image with the positions of the bounding boxes masked.\n    \"\"\"\n\n    width, height = image.size\n\n    mask = Image.new(\"RGBA\", (width, height), (0, 0, 0, 0))\n\n    for bbox in bounding_boxes:\n        mask.paste(\n            Image.new(\"RGBA\", (bbox.width, bbox.height), mask_color),\n            (int(bbox.x0 * width), int(bbox.top * height)),\n        )\n\n    return Image.alpha_composite(image, mask)\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.splitter","title":"<code>splitter</code>","text":""},{"location":"reference/utils/#docprompt.utils.splitter.pdf_split_iter_fast","title":"<code>pdf_split_iter_fast(file_bytes, max_page_count)</code>","text":"<p>Splits a PDF into batches of pages up to <code>max_page_count</code> pages quickly.</p> Source code in <code>docprompt/utils/splitter.py</code> <pre><code>def pdf_split_iter_fast(file_bytes: bytes, max_page_count: int) -&gt; Iterator[bytes]:\n    \"\"\"\n    Splits a PDF into batches of pages up to `max_page_count` pages quickly.\n    \"\"\"\n    with get_pdfium_document(file_bytes) as src_pdf:\n        current_page = 0\n        total_pages = len(src_pdf)\n\n        while current_page &lt; total_pages:\n            # Determine the last page for the current batch\n            last_page = min(current_page + max_page_count, total_pages)\n\n            with writable_temp_pdf() as dst_pdf:\n                # Append pages to the batch\n                dst_pdf.import_pages(src_pdf, list(range(current_page, last_page)))\n\n                # Save the batch PDF to a bytes buffer\n                pdf_bytes_buffer = io.BytesIO()\n                dst_pdf.save(pdf_bytes_buffer)\n                pdf_bytes_buffer.seek(0)  # Reset buffer pointer to the beginning\n\n            # Yield the bytes of the batch PDF\n            yield pdf_bytes_buffer.getvalue()\n\n            # Update the current page for the next batch\n            current_page += max_page_count\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.splitter.pdf_split_iter_with_max_bytes","title":"<code>pdf_split_iter_with_max_bytes(file_bytes, max_page_count, max_bytes)</code>","text":"<p>Splits a PDF into batches of pages up to <code>max_page_count</code> pages and <code>max_bytes</code> bytes.</p> Source code in <code>docprompt/utils/splitter.py</code> <pre><code>def pdf_split_iter_with_max_bytes(\n    file_bytes: bytes, max_page_count: int, max_bytes: int\n) -&gt; Iterator[bytes]:\n    \"\"\"\n    Splits a PDF into batches of pages up to `max_page_count` pages and `max_bytes` bytes.\n    \"\"\"\n    for batch_bytes in pdf_split_iter_fast(file_bytes, max_page_count):\n        if len(batch_bytes) &lt;= max_bytes:\n            yield batch_bytes\n        else:\n            # If batch size is greater than max_bytes, reduce the number of pages\n            pages_in_batch = max_page_count\n            while len(batch_bytes) &gt; max_bytes and pages_in_batch &gt; 1:\n                pages_in_batch -= 1\n                batch_bytes = next(pdf_split_iter_fast(file_bytes, pages_in_batch))\n\n            if len(batch_bytes) &gt; max_bytes and pages_in_batch == 1:\n                # If a single page is still too large, compress it\n                with tempfile.NamedTemporaryFile(suffix=\".pdf\") as f:\n                    f.write(batch_bytes)\n                    f.flush()\n                    compressed_bytes = compress_pdf_to_bytes(f.name)\n                yield compressed_bytes\n            else:\n                yield batch_bytes\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.splitter.split_pdf_to_bytes","title":"<code>split_pdf_to_bytes(file_bytes, *, start_page=None, stop_page=None)</code>","text":"<p>Splits a PDF into a list of bytes.</p> Source code in <code>docprompt/utils/splitter.py</code> <pre><code>def split_pdf_to_bytes(\n    file_bytes: bytes,\n    *,\n    start_page: Optional[int] = None,\n    stop_page: Optional[int] = None,\n):\n    \"\"\"\n    Splits a PDF into a list of bytes.\n    \"\"\"\n    if start_page is None:\n        start_page = 0\n    if stop_page is None:\n        stop_page = get_page_count(file_bytes)\n\n    if stop_page &lt;= start_page:\n        raise ValueError(\"stop_page must be greater than start_page\")\n\n    # Load the PDF from bytes\n    with get_pdfium_document(file_bytes) as src_pdf:\n        # Create a new PDF for the current batch\n        dst_pdf = pdfium.PdfDocument.new()\n\n        # Append pages to the batch\n        dst_pdf.import_pages(src_pdf, list(range(start_page, stop_page)))\n\n        # Save the batch PDF to a bytes buffer\n        pdf_bytes_buffer = io.BytesIO()\n        dst_pdf.save(pdf_bytes_buffer)\n        pdf_bytes_buffer.seek(0)  # Reset buffer pointer to the beginning\n\n        # Yield the bytes of the batch PDF\n        return pdf_bytes_buffer.getvalue()\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.util","title":"<code>util</code>","text":""},{"location":"reference/utils/#docprompt.utils.util.determine_pdf_name_from_bytes","title":"<code>determine_pdf_name_from_bytes(file_bytes)</code>","text":"<p>Attempts to determine the name of a PDF by exaimining metadata</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def determine_pdf_name_from_bytes(file_bytes: bytes) -&gt; str:\n    \"\"\"\n    Attempts to determine the name of a PDF by exaimining metadata\n    \"\"\"\n    with get_pdfium_document(file_bytes) as pdf:\n        metadata_dict = pdf.get_metadata_dict(skip_empty=True)\n\n    name = None\n\n    if metadata_dict:\n        name = (\n            metadata_dict.get(\"Title\")\n            or metadata_dict.get(\"Subject\")\n            or metadata_dict.get(\"Author\")\n        )\n\n    if name:\n        return f\"{name.strip()}.pdf\"\n\n    return f\"document-{hash_from_bytes(file_bytes)}.pdf\"\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.util.get_page_count","title":"<code>get_page_count(fd)</code>","text":"<p>Determines the number of pages in a PDF</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def get_page_count(fd: Union[Path, PathLike, bytes]) -&gt; int:\n    \"\"\"\n    Determines the number of pages in a PDF\n    \"\"\"\n    if not isinstance(fd, bytes):\n        with open(fd, \"rb\") as f:\n            fd = f.read()\n\n    with get_pdfium_document(fd) as pdf:\n        return len(pdf)\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.util.hash_from_bytes","title":"<code>hash_from_bytes(byte_data, hash_func=hashlib.md5, threshold=1024 * 1024 * 128)</code>","text":"<p>Gets a hash from bytes. If the bytes are larger than the threshold, the hash is computed in chunks to avoid memory issues. The default hash function is MD5 with a threshold of 128MB which is optimal for most machines and use cases.</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def hash_from_bytes(\n    byte_data: bytes, hash_func=hashlib.md5, threshold=1024 * 1024 * 128\n) -&gt; str:\n    \"\"\"\n    Gets a hash from bytes. If the bytes are larger than the threshold, the hash is computed in chunks\n    to avoid memory issues. The default hash function is MD5 with a threshold of 128MB which is optimal\n    for most machines and use cases.\n    \"\"\"\n    hash = hash_func()\n\n    if len(byte_data) &gt; threshold:\n        stream = BytesIO(byte_data)\n        b = bytearray(128 * 1024)\n        mv = memoryview(b)\n\n        while n := stream.readinto(mv):\n            hash.update(mv[:n])\n    else:\n        hash.update(byte_data)\n\n    return hash.hexdigest()\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.util.is_pdf","title":"<code>is_pdf(fd)</code>","text":"<p>Determines if a file is a PDF</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def is_pdf(fd: Union[Path, PathLike, bytes]) -&gt; bool:\n    \"\"\"\n    Determines if a file is a PDF\n    \"\"\"\n    if isinstance(fd, (bytes, str)):\n        mime = filetype.guess_mime(fd)\n    else:\n        with open(fd, \"rb\") as f:\n            # We only need the first 1024 bytes to determine if it's a PDF\n            mime = filetype.guess_mime(f.read(1024))\n\n    return mime == \"application/pdf\"\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.util.load_document","title":"<code>load_document(fp, *, file_name=None)</code>","text":"<p>Loads a document from a file path</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def load_document(\n    fp: Union[Path, PathLike, bytes],\n    *,\n    file_name: Optional[str] = None,\n) -&gt; PdfDocument:\n    \"\"\"\n    Loads a document from a file path\n    \"\"\"\n    if isinstance(fp, bytes):\n        file_bytes = fp\n        file_name = file_name or determine_pdf_name_from_bytes(file_bytes)\n    else:\n        file_name = name_from_path(fp) if file_name is None else file_name\n\n        file_bytes = read_pdf_bytes_from_path(fp)\n\n    if not is_pdf(file_bytes):\n        raise ValueError(\"File is not a PDF\")\n\n    return PdfDocument(\n        name=unquote(file_name), file_path=str(fp), file_bytes=file_bytes\n    )\n</code></pre>"},{"location":"reference/utils/#docprompt.utils.util.load_documents","title":"<code>load_documents(fps, *, max_threads=12)</code>","text":"<p>Loads multiple documents from file paths, using a thread pool</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def load_documents(\n    fps: List[Union[Path, PathLike, bytes]],\n    *,\n    max_threads: int = 12,\n):\n    \"\"\"\n    Loads multiple documents from file paths, using a thread pool\n    \"\"\"\n    futures = []\n\n    thread_count = min(max_threads, len(fps))\n\n    with ThreadPoolExecutor(max_workers=thread_count) as executor:\n        for fp in fps:\n            futures.append(executor.submit(load_document, fp))\n\n    results = []\n\n    for future in as_completed(futures):\n        results.append(future.result())\n\n    return results\n</code></pre>"},{"location":"reference/utils/compressor/","title":"compressor","text":""},{"location":"reference/utils/date_extraction/","title":"date_extraction","text":""},{"location":"reference/utils/date_extraction/#docprompt.utils.date_extraction.extract_dates_from_text","title":"<code>extract_dates_from_text(input_string, *, date_formats=default_date_formats)</code>","text":"<p>Extract dates from a string using a set of predefined regex patterns.</p> <p>Returns a list of tuples, where the first element is the date object and the second is the full date string.</p> Source code in <code>docprompt/utils/date_extraction.py</code> <pre><code>def extract_dates_from_text(\n    input_string: str, *, date_formats: DateFormatsType = default_date_formats\n) -&gt; List[Tuple[date, str]]:\n    \"\"\"\n    Extract dates from a string using a set of predefined regex patterns.\n\n    Returns a list of tuples, where the first element is the date object and the second is the full date string.\n    \"\"\"\n    extracted_dates = []\n\n    for regex, date_format in date_formats:\n        matches = regex.findall(input_string)\n\n        for match_obj in matches:\n            # Extract the full date from the match\n            full_date = match_obj[0]  # First group captures the entire date\n\n            if \"%d\" in date_format:\n                parse_date = re.sub(r\"(st|nd|rd|th)\", \"\", full_date)\n            else:\n                parse_date = full_date\n\n            parse_date = re.sub(r\"\\s+\", \" \", parse_date).strip()\n            parse_date = re.sub(\n                r\"\\s{1,},\", \",\", parse_date\n            ).strip()  # Commas shouldnt have spaces before them\n\n            # Convert to datetime object\n            try:\n                date_obj = datetime.strptime(parse_date, date_format)\n            except ValueError as e:\n                print(f\"Error parsing date '{full_date}': {e}\")\n                continue\n\n            extracted_dates.append((date_obj.date(), full_date))\n\n    return extracted_dates\n</code></pre>"},{"location":"reference/utils/splitter/","title":"splitter","text":""},{"location":"reference/utils/splitter/#docprompt.utils.splitter.pdf_split_iter_fast","title":"<code>pdf_split_iter_fast(file_bytes, max_page_count)</code>","text":"<p>Splits a PDF into batches of pages up to <code>max_page_count</code> pages quickly.</p> Source code in <code>docprompt/utils/splitter.py</code> <pre><code>def pdf_split_iter_fast(file_bytes: bytes, max_page_count: int) -&gt; Iterator[bytes]:\n    \"\"\"\n    Splits a PDF into batches of pages up to `max_page_count` pages quickly.\n    \"\"\"\n    with get_pdfium_document(file_bytes) as src_pdf:\n        current_page = 0\n        total_pages = len(src_pdf)\n\n        while current_page &lt; total_pages:\n            # Determine the last page for the current batch\n            last_page = min(current_page + max_page_count, total_pages)\n\n            with writable_temp_pdf() as dst_pdf:\n                # Append pages to the batch\n                dst_pdf.import_pages(src_pdf, list(range(current_page, last_page)))\n\n                # Save the batch PDF to a bytes buffer\n                pdf_bytes_buffer = io.BytesIO()\n                dst_pdf.save(pdf_bytes_buffer)\n                pdf_bytes_buffer.seek(0)  # Reset buffer pointer to the beginning\n\n            # Yield the bytes of the batch PDF\n            yield pdf_bytes_buffer.getvalue()\n\n            # Update the current page for the next batch\n            current_page += max_page_count\n</code></pre>"},{"location":"reference/utils/splitter/#docprompt.utils.splitter.pdf_split_iter_with_max_bytes","title":"<code>pdf_split_iter_with_max_bytes(file_bytes, max_page_count, max_bytes)</code>","text":"<p>Splits a PDF into batches of pages up to <code>max_page_count</code> pages and <code>max_bytes</code> bytes.</p> Source code in <code>docprompt/utils/splitter.py</code> <pre><code>def pdf_split_iter_with_max_bytes(\n    file_bytes: bytes, max_page_count: int, max_bytes: int\n) -&gt; Iterator[bytes]:\n    \"\"\"\n    Splits a PDF into batches of pages up to `max_page_count` pages and `max_bytes` bytes.\n    \"\"\"\n    for batch_bytes in pdf_split_iter_fast(file_bytes, max_page_count):\n        if len(batch_bytes) &lt;= max_bytes:\n            yield batch_bytes\n        else:\n            # If batch size is greater than max_bytes, reduce the number of pages\n            pages_in_batch = max_page_count\n            while len(batch_bytes) &gt; max_bytes and pages_in_batch &gt; 1:\n                pages_in_batch -= 1\n                batch_bytes = next(pdf_split_iter_fast(file_bytes, pages_in_batch))\n\n            if len(batch_bytes) &gt; max_bytes and pages_in_batch == 1:\n                # If a single page is still too large, compress it\n                with tempfile.NamedTemporaryFile(suffix=\".pdf\") as f:\n                    f.write(batch_bytes)\n                    f.flush()\n                    compressed_bytes = compress_pdf_to_bytes(f.name)\n                yield compressed_bytes\n            else:\n                yield batch_bytes\n</code></pre>"},{"location":"reference/utils/splitter/#docprompt.utils.splitter.split_pdf_to_bytes","title":"<code>split_pdf_to_bytes(file_bytes, *, start_page=None, stop_page=None)</code>","text":"<p>Splits a PDF into a list of bytes.</p> Source code in <code>docprompt/utils/splitter.py</code> <pre><code>def split_pdf_to_bytes(\n    file_bytes: bytes,\n    *,\n    start_page: Optional[int] = None,\n    stop_page: Optional[int] = None,\n):\n    \"\"\"\n    Splits a PDF into a list of bytes.\n    \"\"\"\n    if start_page is None:\n        start_page = 0\n    if stop_page is None:\n        stop_page = get_page_count(file_bytes)\n\n    if stop_page &lt;= start_page:\n        raise ValueError(\"stop_page must be greater than start_page\")\n\n    # Load the PDF from bytes\n    with get_pdfium_document(file_bytes) as src_pdf:\n        # Create a new PDF for the current batch\n        dst_pdf = pdfium.PdfDocument.new()\n\n        # Append pages to the batch\n        dst_pdf.import_pages(src_pdf, list(range(start_page, stop_page)))\n\n        # Save the batch PDF to a bytes buffer\n        pdf_bytes_buffer = io.BytesIO()\n        dst_pdf.save(pdf_bytes_buffer)\n        pdf_bytes_buffer.seek(0)  # Reset buffer pointer to the beginning\n\n        # Yield the bytes of the batch PDF\n        return pdf_bytes_buffer.getvalue()\n</code></pre>"},{"location":"reference/utils/util/","title":"util","text":""},{"location":"reference/utils/util/#docprompt.utils.util.determine_pdf_name_from_bytes","title":"<code>determine_pdf_name_from_bytes(file_bytes)</code>","text":"<p>Attempts to determine the name of a PDF by exaimining metadata</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def determine_pdf_name_from_bytes(file_bytes: bytes) -&gt; str:\n    \"\"\"\n    Attempts to determine the name of a PDF by exaimining metadata\n    \"\"\"\n    with get_pdfium_document(file_bytes) as pdf:\n        metadata_dict = pdf.get_metadata_dict(skip_empty=True)\n\n    name = None\n\n    if metadata_dict:\n        name = (\n            metadata_dict.get(\"Title\")\n            or metadata_dict.get(\"Subject\")\n            or metadata_dict.get(\"Author\")\n        )\n\n    if name:\n        return f\"{name.strip()}.pdf\"\n\n    return f\"document-{hash_from_bytes(file_bytes)}.pdf\"\n</code></pre>"},{"location":"reference/utils/util/#docprompt.utils.util.get_page_count","title":"<code>get_page_count(fd)</code>","text":"<p>Determines the number of pages in a PDF</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def get_page_count(fd: Union[Path, PathLike, bytes]) -&gt; int:\n    \"\"\"\n    Determines the number of pages in a PDF\n    \"\"\"\n    if not isinstance(fd, bytes):\n        with open(fd, \"rb\") as f:\n            fd = f.read()\n\n    with get_pdfium_document(fd) as pdf:\n        return len(pdf)\n</code></pre>"},{"location":"reference/utils/util/#docprompt.utils.util.hash_from_bytes","title":"<code>hash_from_bytes(byte_data, hash_func=hashlib.md5, threshold=1024 * 1024 * 128)</code>","text":"<p>Gets a hash from bytes. If the bytes are larger than the threshold, the hash is computed in chunks to avoid memory issues. The default hash function is MD5 with a threshold of 128MB which is optimal for most machines and use cases.</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def hash_from_bytes(\n    byte_data: bytes, hash_func=hashlib.md5, threshold=1024 * 1024 * 128\n) -&gt; str:\n    \"\"\"\n    Gets a hash from bytes. If the bytes are larger than the threshold, the hash is computed in chunks\n    to avoid memory issues. The default hash function is MD5 with a threshold of 128MB which is optimal\n    for most machines and use cases.\n    \"\"\"\n    hash = hash_func()\n\n    if len(byte_data) &gt; threshold:\n        stream = BytesIO(byte_data)\n        b = bytearray(128 * 1024)\n        mv = memoryview(b)\n\n        while n := stream.readinto(mv):\n            hash.update(mv[:n])\n    else:\n        hash.update(byte_data)\n\n    return hash.hexdigest()\n</code></pre>"},{"location":"reference/utils/util/#docprompt.utils.util.is_pdf","title":"<code>is_pdf(fd)</code>","text":"<p>Determines if a file is a PDF</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def is_pdf(fd: Union[Path, PathLike, bytes]) -&gt; bool:\n    \"\"\"\n    Determines if a file is a PDF\n    \"\"\"\n    if isinstance(fd, (bytes, str)):\n        mime = filetype.guess_mime(fd)\n    else:\n        with open(fd, \"rb\") as f:\n            # We only need the first 1024 bytes to determine if it's a PDF\n            mime = filetype.guess_mime(f.read(1024))\n\n    return mime == \"application/pdf\"\n</code></pre>"},{"location":"reference/utils/util/#docprompt.utils.util.load_document","title":"<code>load_document(fp, *, file_name=None)</code>","text":"<p>Loads a document from a file path</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def load_document(\n    fp: Union[Path, PathLike, bytes],\n    *,\n    file_name: Optional[str] = None,\n) -&gt; PdfDocument:\n    \"\"\"\n    Loads a document from a file path\n    \"\"\"\n    if isinstance(fp, bytes):\n        file_bytes = fp\n        file_name = file_name or determine_pdf_name_from_bytes(file_bytes)\n    else:\n        file_name = name_from_path(fp) if file_name is None else file_name\n\n        file_bytes = read_pdf_bytes_from_path(fp)\n\n    if not is_pdf(file_bytes):\n        raise ValueError(\"File is not a PDF\")\n\n    return PdfDocument(\n        name=unquote(file_name), file_path=str(fp), file_bytes=file_bytes\n    )\n</code></pre>"},{"location":"reference/utils/util/#docprompt.utils.util.load_documents","title":"<code>load_documents(fps, *, max_threads=12)</code>","text":"<p>Loads multiple documents from file paths, using a thread pool</p> Source code in <code>docprompt/utils/util.py</code> <pre><code>def load_documents(\n    fps: List[Union[Path, PathLike, bytes]],\n    *,\n    max_threads: int = 12,\n):\n    \"\"\"\n    Loads multiple documents from file paths, using a thread pool\n    \"\"\"\n    futures = []\n\n    thread_count = min(max_threads, len(fps))\n\n    with ThreadPoolExecutor(max_workers=thread_count) as executor:\n        for fp in fps:\n            futures.append(executor.submit(load_document, fp))\n\n    results = []\n\n    for future in as_completed(futures):\n        results.append(future.result())\n\n    return results\n</code></pre>"},{"location":"reference/utils/masking/","title":"Index","text":""},{"location":"reference/utils/masking/#docprompt.utils.masking.image","title":"<code>image</code>","text":""},{"location":"reference/utils/masking/#docprompt.utils.masking.image.mask_image_from_bounding_boxes","title":"<code>mask_image_from_bounding_boxes(image, *bounding_boxes, mask_color='#000000')</code>","text":"<p>Create a copy of the image with the positions of the bounding boxes masked.</p> Source code in <code>docprompt/utils/masking/image.py</code> <pre><code>def mask_image_from_bounding_boxes(\n    image: Image.Image,\n    *bounding_boxes: NormBBox,\n    mask_color: str = \"#000000\",\n):\n    \"\"\"\n    Create a copy of the image with the positions of the bounding boxes masked.\n    \"\"\"\n\n    width, height = image.size\n\n    mask = Image.new(\"RGBA\", (width, height), (0, 0, 0, 0))\n\n    for bbox in bounding_boxes:\n        mask.paste(\n            Image.new(\"RGBA\", (bbox.width, bbox.height), mask_color),\n            (int(bbox.x0 * width), int(bbox.top * height)),\n        )\n\n    return Image.alpha_composite(image, mask)\n</code></pre>"},{"location":"reference/utils/masking/image/","title":"image","text":""},{"location":"reference/utils/masking/image/#docprompt.utils.masking.image.mask_image_from_bounding_boxes","title":"<code>mask_image_from_bounding_boxes(image, *bounding_boxes, mask_color='#000000')</code>","text":"<p>Create a copy of the image with the positions of the bounding boxes masked.</p> Source code in <code>docprompt/utils/masking/image.py</code> <pre><code>def mask_image_from_bounding_boxes(\n    image: Image.Image,\n    *bounding_boxes: NormBBox,\n    mask_color: str = \"#000000\",\n):\n    \"\"\"\n    Create a copy of the image with the positions of the bounding boxes masked.\n    \"\"\"\n\n    width, height = image.size\n\n    mask = Image.new(\"RGBA\", (width, height), (0, 0, 0, 0))\n\n    for bbox in bounding_boxes:\n        mask.paste(\n            Image.new(\"RGBA\", (bbox.width, bbox.height), mask_color),\n            (int(bbox.x0 * width), int(bbox.top * height)),\n        )\n\n    return Image.alpha_composite(image, mask)\n</code></pre>"}]}